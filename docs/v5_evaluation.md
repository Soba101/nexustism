# finetune_model_v5.ipynb Evaluation

## Overview of Changes from `v4` to `v5`

The `finetune_model_v5.ipynb` notebook represents a significant advancement and refactoring from its predecessor, `v4`. It transitions from a functional script to a more robust, configurable, and production-oriented machine learning pipeline, focusing on enhanced data quality, comprehensive configuration, and detailed evaluation.

### Key Enhancements and Changes

1. **Enhanced Imports and Reproducibility Setup:**
    * **More Comprehensive Imports:** Additional libraries like `pickle`, `warnings`, `collections`, `typing`, `tqdm`, `seaborn`, `nn`, `AdamW`, `CosineAnnealingLR`, `OneCycleLR`, `Pooling`, `StratifiedKFold`, `TfidfVectorizer`, `KMeans`, `word_tokenize`, `WordNetLemmatizer`, `pearsonr`, `spearmanr`, and `joblib` have been added, indicating a broader scope of features.
    * **NLTK Downloads:** Automated download of all necessary NLTK resources (`punkt`, `stopwords`, `wordnet`, `averaged_perceptron_tagger`, `omw-1.4`) ensures a smoother setup.
    * **Consistent Logging:** Improved logging configuration directs output to both a file (`training_v5.log`) and standard output, enhancing traceability.
    * **Full Reproducibility:** A dedicated `set_seeds` function now configures random seeds across `random`, `numpy`, and `torch` (including CUDA), with an option for `torch.backends.cudnn.deterministic` for highly reproducible GPU operations.
    * **Warning Suppression:** `UserWarning`s are suppressed, and `TOKENIZERS_PARALLELISM` is explicitly set to 'false' to manage tokenization behavior.

2. **Advanced Configuration (`CONFIG` dictionary):**
    * The `CONFIG` dictionary has been significantly expanded to centralize almost all hyperparameters and operational settings.
    * New parameters include `target_pairs` (50,000, 5x increase), `positive_ratio`, `augmentation_ratio`, `quality_threshold`, `max_learning_rate` (for scheduling), `weight_decay`, increased `max_seq_length` (384), more sensitive `early_stopping_patience` and `min_delta`, `save_steps`, and explicit weights for multiple loss functions (`mnr_loss_weight`, `triplet_loss_weight`, `cosine_loss_weight`).
    * Specific thresholds for `semantic_similarity_min/max`, `hard_negative_similarity_min/max`, and `jaccard_positive_min/negative_range` are now configurable.

3. **Sophisticated Data Loading and Preprocessing:**
    * **`load_and_clean_data` function:** This new function encapsulates robust data loading and cleaning, including:
        * Explicit checking for required columns.
        * Improved handling of missing text fields.
        * More aggressive cleaning of `combined_text` (regex to remove extra spaces).
        * Filtering of empty or very short texts based on `min_length`.
        * Creation of categorical mappings (`category_id`, `subcategory_id`).
        * Calculation of text statistics (`text_length`, `word_count`) for data analysis.

4. **Advanced Text Similarity Utilities (`TextSimilarityCalculator` class):**
    * A dedicated class handles text preprocessing (lemmatization, stopword removal) and similarity calculations.
    * It provides:
        * `jaccard_similarity`: Calculates Jaccard similarity.
        * `tfidf_similarity`: Uses a fitted TF-IDF vectorizer to compute cosine similarity between texts. This is a powerful addition for semantic matching.
        * `fit_tfidf`: Method to fit the TF-IDF vectorizer on the corpus, ensuring consistent vectorization.

5. **"Smart" Pair Generation & Training Pipeline (Major Overhaul):**
    * **Target-Driven Generation:** The pipeline now targets a specific number of total, positive, and negative pairs based on `CONFIG['target_pairs']` and `CONFIG['positive_ratio']`.
    * **Quality-Filtered Positive Pairs:** Instead of random combinations, positive pairs within the same `Category` and `Subcategory` are now selected based on their `tfidf_similarity` score, ensuring a minimum "quality" or relevance (`quality_threshold`).
    * **Dynamic Hard Negative Mining:** Hard negatives are generated by selecting pairs from *different* categories but where their `tfidf_similarity` falls within a "confusing" range. This forces the model to learn finer distinctions. It includes robust retry logic and a fallback to random negatives.
    * **Data Augmentation Integration:** The augmentation process is applied to positive pairs, using `nlpaug` for synonym replacement if available.

6. **Advanced Training and Evaluation Architecture:**
    * **Optimized Training Configuration:** The `model.fit` arguments now directly reflect the comprehensive `CONFIG` parameters, including new `optimizer_params` for `weight_decay` and `lr`.
    * **`ComprehensiveEvaluator` Class:**
        * This new class streamlines the evaluation process.
        * It computes embeddings, calculates cosine similarities, and derives a full suite of metrics: Pearson and Spearman correlation, ROC AUC, PR AUC, and identifies the optimal classification threshold.
        * It integrates visualization creation directly, generating plots for similarity distribution, ROC curves, and Precision-Recall curves.

7. **Relationship Classifier Re-integration:**
    * The optional relationship classifier, present in `v4`, has been added back as a new cell at the end of the notebook.
    * The code is adapted to the `v5` structure, using the new `CONFIG` and loading the newly fine-tuned `v5` model to generate embeddings.
    * It correctly uses `joblib` and `imblearn.over_sampling.SMOTE` for training and saving the classifier.

## Evaluation

The `v5` notebook is a substantial improvement, transforming the project into a more professional and robust machine learning pipeline.

### Strengths

* **Robustness and Reproducibility:** The dedicated `set_seeds` function, comprehensive configuration, and structured logging significantly improve the reliability of experiments.
* **High-Quality Data Generation:** Intelligent selection of positive and hard negative pairs using TF-IDF similarity should lead to a much more effective training dataset and a more accurate model.
* **Flexibility and Tunability:** Centralizing all key parameters in `CONFIG` makes experimentation and future adjustments much easier.
* **Comprehensive Evaluation Framework:** The `ComprehensiveEvaluator` provides immediate, rich feedback on model performance, which is invaluable for development.
* **Modular and Clean Code:** The use of dedicated functions and classes (`TextSimilarityCalculator`, `ComprehensiveEvaluator`) improves the notebook's readability and maintainability.

### Areas for Further Development

* **Multi-Loss Implementation:** The `CONFIG` file contains weights for a multi-loss setup, but the training loop currently only implements `MultipleNegativesRankingLoss`. Activating and combining `TripletLoss` and `CosineSimilarityLoss` would be a valuable next step.
* **Performance at Scale:** The pair generation logic, while "smarter," could be slow on very large datasets due to the need to calculate similarities. For scaling up further, methods like Approximate Nearest Neighbor (ANN) could be explored for more efficient candidate selection.

Overall, `v5` is a well-structured and powerful iteration that sets a strong foundation for achieving high accuracy and building a production-ready system.

### Current Training Results (Latest Run)

The initial training run using the `v5` pipeline demonstrated promising results and rapid convergence:

* **Rapid Progress:** The model achieved a Spearman correlation of **0.7516** within the first full epoch (717 steps). This is a significant improvement in training speed, as previous iterations required multiple epochs to reach similar performance levels.
* **Metric Comparison (Epoch 1.0 vs. Best Historical Baseline - Spearman ~0.78):**
  * **Spearman Correlation:** Reached **0.7516**, closely approaching the previous best historical benchmark of ~0.78 (from Model 1, which took 9 epochs). This indicates strong initial learning.
  * **ROC AUC:** Improved to **0.9369** (compared to ~0.92 previously).
  * **F1 Optimal:** Showed a substantial increase to **0.8442** (compared to ~0.68 previously), indicating better precision and recall at the optimal threshold.
* **Early Plateau:** After the initial rapid improvement, subsequent steps within the first two epochs showed slight fluctuations or a plateau in Spearman correlation (e.g., dipping to 0.73-0.74), suggesting the model quickly extracted most of the available signal from the current text features.

### Conclusion on Current Performance

The `v5` training pipeline is highly effective in terms of speed and initial performance. The rapid ascent to a 0.75 Spearman correlation in just one epoch is a testament to the improved data generation and configuration. However, the observed plateau strongly suggests that the model is now **bottlenecked by the limited feature set** (only `Short Description` + `Description`). To surpass the current performance ceiling and achieve higher correlations, the integration of richer, contextual features as proposed in `v6_implement.md` (e.g., `Service`, `Assignment group`, `Category`) is critical. This will provide the model with the necessary information to disambiguate similar-sounding but technically distinct incidents.

## finetune_model_v5.ipynb Evaluation (Training Run Nov 30, 2025)

### 1. Benchmark Performance Metrics

The `v5` model ("Smart Sampling" with `Short Description` + `Description` only) was evaluated during its initial training run.

| Metric | Best Score (v5) | Baseline (Model 1 - v4) | Improvement |
| :--- | :--- | :--- | :--- |
| **Spearman Correlation** | **0.7516** (Epoch 1.0) | 0.7828 (Epoch 9.0) | ðŸŸ¡ -4.0% (but 9x faster) |
| **ROC AUC** | **0.9369** | ~0.9200 | ðŸŸ¢ +1.8% |
| **F1 Optimal** | **0.8442** | ~0.6840 | ðŸš€ +23.4% |
| **Precision-Recall AUC** | **0.9381** | ~0.6840 | ðŸš€ +37.1% |
| **Time to Convergence** | **1 Epoch** | 9 Epochs | ðŸš€ 9x Faster |

### 2. Model Accuracy & Observations

* **Rapid Convergence:** The model learned 95% of its peak performance within the first **100 steps** (Spearman 0.43 â†’ 0.70). This validates the "Smart Pair Generation" strategy (TF-IDF filtering), which eliminated low-value training pairs.
* **High Precision/Recall:** The massive jump in F1 and PR AUC indicates the model is excellent at binary classification (Similar vs. Not Similar). It rarely makes catastrophic errors (e.g., ranking a totally unrelated ticket as highly similar).
* **The "Glass Ceiling":** Despite the rapid start, the Spearman correlation plateaued hard at **~0.75** after just 1 epoch. Continued training (up to Epoch 2.5) saw scores oscillate and regress slightly (to 0.72).

### 3. Error Analysis (Why the Plateau?)

The plateau indicates a **Feature Bottleneck**. The model extracted all available signal from the short text fields. It began failing on "Hard Negatives" that are linguistically identical but technically distinct.

* **Example of Confusion:**
  * *Ticket A:* "Login failed. User gets timeout." (Service: **SAP**)
  * *Ticket B:* "Login failed. User gets timeout." (Service: **VPN**)
  * *Model View:* Without the Service field, these look 100% identical. The model pushes them together.
  * *Ground Truth:* These are different issues (Network vs. Application). They should be further apart.

### 4. Resource Utilization

* **Training Speed:** Highly efficient. 1 epoch (~700 steps) completed in approx. 20 minutes on MPS (Mac GPU).
* **Memory:** Batch size of 64 was stable.
* **Data Efficiency:** 50,000 "smart" pairs outperformed larger, random datasets from previous iterations.

### 5. Configuration Settings (v5 Final)

* **Model:** `sentence-transformers/all-mpnet-base-v2`
* **Max Seq Length:** 384
* **Batch Size:** 64
* **Learning Rate:** 2e-5 (Warmup 10%)
* **Loss:** `MultipleNegativesRankingLoss`
* **Pair Generation:**
  * Positive Ratio: 0.4
  * Positives: Same Category + TF-IDF > 0.3
  * Negatives: Diff Category + TF-IDF (0.15 - 0.45) [Hard Mining]

### 6. Actionable Improvements (Transition to v6)

The evaluation confirms that **algorithm tuning is finished**. We cannot squeeze more performance out of the current text inputs.

1. **Implement Contextual Prefixing (v6):**
    * **Action:** Inject structured fields (`Service`, `Group`, `Category`) into the input string.
    * **Goal:** Break the 0.75 Spearman ceiling by resolving the "Login failed" ambiguity.
2. **Exclude Resolution Notes:**
    * **Action:** Ensure training data represents the *problem* state (incoming ticket), not the *solved* state.
    * **Goal:** Prevent data leakage and improve real-world retrieval accuracy.

**Status:** v5 experiment concluded. Proceeding to v6.
