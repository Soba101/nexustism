{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tune SentenceTransformer Models for ITSM Tickets (v5)\n",
    "\n",
    "## Overview\n",
    "This notebook represents the `v5` iteration of the ITSM similarity model pipeline. It transitions from a functional script to a robust, configurable machine learning pipeline.\n",
    "\n",
    "### Key Enhancements\n",
    "1. **Comprehensive Configuration**: Centralized `CONFIG` for all hyperparameters.\n",
    "2. **Smart Data Generation**: TF-IDF based filtering for high-quality positives and dynamic hard negative mining.\n",
    "3. **Advanced Evaluation**: Real-time tracking of Spearman correlation, ROC AUC, and F1 scores.\n",
    "4. **Reproducibility**: Full seeding of Random, NumPy, and PyTorch.\n",
    "5. **Relationship Classifier**: Integrated training of the secondary classifier.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current protobuf version: 3.20.3\n",
      "‚úÖ Protobuf version is compatible\n"
     ]
    }
   ],
   "source": [
    "# Fix protobuf version conflict\n",
    "# This error occurs when protobuf version is incompatible with TensorFlow/other libraries\n",
    "# The CUDA warnings are harmless and can be ignored\n",
    "import sys\n",
    "import subprocess\n",
    "import warnings\n",
    "\n",
    "def fix_protobuf():\n",
    "    \"\"\"Fix protobuf version conflicts by installing compatible version.\"\"\"\n",
    "    try:\n",
    "        import google.protobuf\n",
    "        protobuf_version = google.protobuf.__version__\n",
    "        print(f\"Current protobuf version: {protobuf_version}\")\n",
    "        \n",
    "        # Check if version is too new (4.x+ causes issues)\n",
    "        major_version = int(protobuf_version.split('.')[0])\n",
    "        if major_version >= 4:\n",
    "            print(\"‚ö†Ô∏è  Protobuf version 4.x detected. Downgrading to 3.20.3 for compatibility...\")\n",
    "            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"protobuf==3.20.3\", \"--quiet\"])\n",
    "            print(\"‚úÖ Protobuf downgraded. Please restart the kernel and re-run this cell.\")\n",
    "            return False\n",
    "        else:\n",
    "            print(\"‚úÖ Protobuf version is compatible\")\n",
    "            return True\n",
    "    except ImportError:\n",
    "        print(\"Installing protobuf 3.20.3...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"protobuf==3.20.3\", \"--quiet\"])\n",
    "        print(\"‚úÖ Protobuf installed. Please restart the kernel and re-run this cell.\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è  Could not check protobuf version: {e}\")\n",
    "        print(\"You may need to manually install: pip install protobuf==3.20.3\")\n",
    "        return True  # Continue anyway\n",
    "\n",
    "# Suppress CUDA registration warnings (these are harmless)\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # Suppress TensorFlow warnings\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "\n",
    "# Try to fix protobuf\n",
    "protobuf_ok = fix_protobuf()\n",
    "if not protobuf_ok:\n",
    "    print(\"\\n‚ö†Ô∏è  IMPORTANT: Please restart the kernel (Kernel -> Restart Kernel) and re-run all cells.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/itsm/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[nltk_data] Downloading package punkt to /Users/don/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to /Users/don/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package wordnet to /Users/don/nltk_data...\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/don/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
      "[nltk_data] Downloading package omw-1.4 to /Users/don/nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Seeds set to 42\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import logging\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import (\n",
    "    classification_report, roc_auc_score, average_precision_score, \n",
    "    precision_recall_curve, roc_curve, f1_score\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "import joblib\n",
    "\n",
    "from sentence_transformers import SentenceTransformer, InputExample, losses\n",
    "from sentence_transformers.evaluation import SentenceEvaluator\n",
    "\n",
    "# --- Setup & Reproducibility ---\n",
    "\n",
    "# NLTK Downloads\n",
    "try:\n",
    "    nltk.data.find('tokenizers/punkt')\n",
    "except LookupError:\n",
    "    nltk.download('punkt')\n",
    "    nltk.download('stopwords')\n",
    "    nltk.download('wordnet')\n",
    "    nltk.download('averaged_perceptron_tagger')\n",
    "    nltk.download('omw-1.4')\n",
    "\n",
    "# Logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler(\"training_v5.log\"),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    " )\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Suppress non-critical warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "def set_seeds(seed=42):\n",
    "    \"\"\"Set seeds for reproducibility across all libraries.\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "    print(f\"‚úÖ Seeds set to {seed}\")\n",
    "\n",
    "set_seeds(42)\n",
    "\n",
    "# Check Imbalanced-Learn for Relationship Classifier\n",
    "try:\n",
    "    from imblearn.over_sampling import SMOTE\n",
    "    IMBLEARN_AVAILABLE = True\n",
    "except ImportError:\n",
    "    print('‚ö†Ô∏è imbalanced-learn not installed. Relationship classifier will skip SMOTE.')\n",
    "    IMBLEARN_AVAILABLE = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Output directory set to: /Users/don/Documents/University/Current_Classes/Capstone/nexustism/models/all-mpnet-finetuned-v5\n"
     ]
    }
   ],
   "source": [
    "CONFIG = {\n",
    "    # Paths\n",
    "    'base_model': 'sentence-transformers/all-mpnet-base-v2',\n",
    "    'output_dir': 'models/all-mpnet-finetuned-v5',\n",
    "    'source_data': 'data/dummy_data_promax.csv',\n",
    "    'relationship_data': 'data/relationship_pairs.json',\n",
    "    \n",
    "    # Training Hyperparameters\n",
    "    'epochs': 20,\n",
    "    'batch_size': 64,\n",
    "    'learning_rate': 2e-5,\n",
    "    'max_learning_rate': 5e-5,\n",
    "    'weight_decay': 0.01,\n",
    "    'warmup_ratio': 0.1,\n",
    "    'max_seq_length': 384,  # Increased for detailed ticket descriptions\n",
    "    \n",
    "    # Data Generation Strategy\n",
    "    'target_pairs': 50000,  # Total training pairs to generate\n",
    "    'positive_ratio': 0.4,  # 40% positives, 60% negatives\n",
    "    'augmentation_ratio': 0.2,\n",
    "    'eval_split': 0.15,\n",
    "    \n",
    "    # Quality Filtering Thresholds\n",
    "    'quality_threshold': 0.3,      # Minimum TF-IDF similarity for 'good' positive pairs\n",
    "    'hard_negative_min': 0.15,     # Min similarity for hard negatives\n",
    "    'hard_negative_max': 0.45,     # Max similarity for hard negatives (confusing zone)\n",
    "    \n",
    "    # Early Stopping\n",
    "    'early_stopping_patience': 7,\n",
    "    'min_delta': 0.005,\n",
    "    'eval_steps': 100,\n",
    "    \n",
    "    # Loss Weights (Future use for Multi-Loss)\n",
    "    'mnr_loss_weight': 1.0,\n",
    "    'triplet_loss_weight': 0.5,\n",
    "    'cosine_loss_weight': 0.2}\n",
    "\n",
    "# Create Output Directory\n",
    "output_path = os.path.join(os.getcwd(), CONFIG['output_dir'])\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "print(f\"üìÇ Output directory set to: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Data path resolved to: /Users/don/Documents/University/Current_Classes/Capstone/nexustism/data/dummy_data_promax.csv\n"
     ]
    }
   ],
   "source": [
    "# Fix path resolution for data files\n",
    "# This ensures paths work regardless of the current working directory\n",
    "def resolve_data_path(filepath):\n",
    "    \"\"\"\n",
    "    Resolve a relative file path to an absolute path.\n",
    "    Tries multiple locations to find the file.\n",
    "    \"\"\"\n",
    "    # If already absolute, return as-is\n",
    "    if os.path.isabs(filepath):\n",
    "        if os.path.exists(filepath):\n",
    "            return filepath\n",
    "        else:\n",
    "            raise FileNotFoundError(f\"Absolute path not found: {filepath}\")\n",
    "    \n",
    "    # Try the path as-is first (relative to current directory)\n",
    "    if os.path.exists(filepath):\n",
    "        return os.path.abspath(filepath)\n",
    "    \n",
    "    # Try relative to workspace root (nexustism directory)\n",
    "    cwd = os.getcwd()\n",
    "    \n",
    "    # Find nexustism in the current path\n",
    "    if 'nexustism' in cwd:\n",
    "        parts = cwd.split(os.sep)\n",
    "        if 'nexustism' in parts:\n",
    "            idx = parts.index('nexustism')\n",
    "            workspace_root = os.sep.join(parts[:idx+1])\n",
    "            potential_path = os.path.join(workspace_root, filepath)\n",
    "            if os.path.exists(potential_path):\n",
    "                return os.path.abspath(potential_path)\n",
    "    \n",
    "    # If still not found, try relative to current directory as absolute\n",
    "    abs_path = os.path.abspath(filepath)\n",
    "    if os.path.exists(abs_path):\n",
    "        return abs_path\n",
    "    \n",
    "    # Last resort: return the path for a clearer error message\n",
    "    raise FileNotFoundError(\n",
    "        f\"Data file not found: {filepath}\\n\"\n",
    "        f\"Current working directory: {cwd}\\n\"\n",
    "        f\"Tried: {filepath}, {os.path.abspath(filepath)}\\n\"\n",
    "        f\"Please ensure the file exists or update CONFIG['source_data'] with the correct path.\"\n",
    "    )\n",
    "\n",
    "# Update CONFIG to use resolved path\n",
    "CONFIG['source_data'] = resolve_data_path(CONFIG['source_data'])\n",
    "print(f\"‚úÖ Data path resolved to: {CONFIG['source_data']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Loading and Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-30 14:50:46,973 - INFO - Loading data from /Users/don/Documents/University/Current_Classes/Capstone/nexustism/data/dummy_data_promax.csv\n",
      "2025-11-30 14:50:47,138 - INFO - Data loaded: 10000 rows, 7 categories\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded 10000 incidents (dropped 0 short/empty)\n",
      "   Unique Categories: 7\n",
      "   Unique Subcategories: 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number</th>\n",
       "      <th>Short Description</th>\n",
       "      <th>Description</th>\n",
       "      <th>Opened by</th>\n",
       "      <th>Company</th>\n",
       "      <th>ITSM Department</th>\n",
       "      <th>Created</th>\n",
       "      <th>Urgency</th>\n",
       "      <th>Impact</th>\n",
       "      <th>Priority</th>\n",
       "      <th>...</th>\n",
       "      <th>Manday Effort (hrs)</th>\n",
       "      <th>Ticket Type</th>\n",
       "      <th>AMS Domain</th>\n",
       "      <th>AMS System Type</th>\n",
       "      <th>AMS Category Type</th>\n",
       "      <th>AMS Service Type</th>\n",
       "      <th>AMS Business Related</th>\n",
       "      <th>AMS IT Related</th>\n",
       "      <th>text</th>\n",
       "      <th>category_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INC9000000</td>\n",
       "      <td>Request: Adjust Configuration/Program bug conf...</td>\n",
       "      <td>I encountered an issue where Request: Adjust C...</td>\n",
       "      <td>Siti Yamada</td>\n",
       "      <td>PASDL</td>\n",
       "      <td>PIDSAP</td>\n",
       "      <td>25-05-25 5:15</td>\n",
       "      <td>1 - High</td>\n",
       "      <td>1 - High</td>\n",
       "      <td>1 - Critical</td>\n",
       "      <td>...</td>\n",
       "      <td>0.26</td>\n",
       "      <td>Inquiry</td>\n",
       "      <td>PASDL</td>\n",
       "      <td>S4HANA</td>\n",
       "      <td>Security</td>\n",
       "      <td>BZ-B12-Master Data (Wrong Maintenance)</td>\n",
       "      <td>Business-Related</td>\n",
       "      <td>IT-Related</td>\n",
       "      <td>Request: Adjust Configuration/Program bug conf...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>INC9000001</td>\n",
       "      <td>Request: Adjust Configuration/Integration conf...</td>\n",
       "      <td>I encountered an issue where Request: Adjust C...</td>\n",
       "      <td>Arif Ghosh</td>\n",
       "      <td>PA</td>\n",
       "      <td>AFG</td>\n",
       "      <td>20-06-24 17:47</td>\n",
       "      <td>3 - Low</td>\n",
       "      <td>3 - Low</td>\n",
       "      <td>1 - Critical</td>\n",
       "      <td>...</td>\n",
       "      <td>1.78</td>\n",
       "      <td>Issue</td>\n",
       "      <td>PASDL</td>\n",
       "      <td>SharePoint</td>\n",
       "      <td>Security</td>\n",
       "      <td>SD Billing</td>\n",
       "      <td>Business-Related</td>\n",
       "      <td>Non-IT</td>\n",
       "      <td>Request: Adjust Configuration/Integration conf...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INC9000002</td>\n",
       "      <td>Error in Mulesoft/EAI (FICO - Finance &amp; Contro...</td>\n",
       "      <td>There appears to be a problem related to Error...</td>\n",
       "      <td>Alex Hidayat</td>\n",
       "      <td>PASDL</td>\n",
       "      <td>PISCAP</td>\n",
       "      <td>30-11-24 5:41</td>\n",
       "      <td>2 - Medium</td>\n",
       "      <td>3 - Low</td>\n",
       "      <td>1 - Critical</td>\n",
       "      <td>...</td>\n",
       "      <td>2.50</td>\n",
       "      <td>Issue</td>\n",
       "      <td>PV</td>\n",
       "      <td>Non-Genesis</td>\n",
       "      <td>Business-Related</td>\n",
       "      <td>MM Purchasing</td>\n",
       "      <td>Non-Business</td>\n",
       "      <td>IT-Related</td>\n",
       "      <td>Error in Mulesoft/EAI (FICO - Finance &amp; Contro...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows √ó 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Number                                  Short Description  \\\n",
       "0  INC9000000  Request: Adjust Configuration/Program bug conf...   \n",
       "1  INC9000001  Request: Adjust Configuration/Integration conf...   \n",
       "2  INC9000002  Error in Mulesoft/EAI (FICO - Finance & Contro...   \n",
       "\n",
       "                                         Description     Opened by Company  \\\n",
       "0  I encountered an issue where Request: Adjust C...   Siti Yamada   PASDL   \n",
       "1  I encountered an issue where Request: Adjust C...    Arif Ghosh      PA   \n",
       "2  There appears to be a problem related to Error...  Alex Hidayat   PASDL   \n",
       "\n",
       "  ITSM Department         Created     Urgency    Impact      Priority  ...  \\\n",
       "0          PIDSAP   25-05-25 5:15    1 - High  1 - High  1 - Critical  ...   \n",
       "1             AFG  20-06-24 17:47     3 - Low   3 - Low  1 - Critical  ...   \n",
       "2          PISCAP   30-11-24 5:41  2 - Medium   3 - Low  1 - Critical  ...   \n",
       "\n",
       "  Manday Effort (hrs) Ticket Type AMS Domain AMS System Type  \\\n",
       "0                0.26     Inquiry      PASDL          S4HANA   \n",
       "1                1.78       Issue      PASDL      SharePoint   \n",
       "2                2.50       Issue         PV     Non-Genesis   \n",
       "\n",
       "  AMS Category Type                        AMS Service Type  \\\n",
       "0          Security  BZ-B12-Master Data (Wrong Maintenance)   \n",
       "1          Security                              SD Billing   \n",
       "2  Business-Related                           MM Purchasing   \n",
       "\n",
       "  AMS Business Related AMS IT Related  \\\n",
       "0     Business-Related     IT-Related   \n",
       "1     Business-Related         Non-IT   \n",
       "2         Non-Business     IT-Related   \n",
       "\n",
       "                                                text category_id  \n",
       "0  Request: Adjust Configuration/Program bug conf...          12  \n",
       "1  Request: Adjust Configuration/Integration conf...          10  \n",
       "2  Error in Mulesoft/EAI (FICO - Finance & Contro...          13  \n",
       "\n",
       "[3 rows x 33 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_and_clean_data(filepath, min_length=10):\n",
    "    \"\"\"\n",
    "    Loads data, checks columns, and performs cleaning.\n",
    "    \n",
    "    Args:\n",
    "        filepath: Path to CSV file\n",
    "        min_length: Minimum text length to keep\n",
    "        \n",
    "    Returns:\n",
    "        Cleaned DataFrame with 'text' and 'category_id' columns\n",
    "    \"\"\"\n",
    "    if not os.path.exists(filepath):\n",
    "        raise FileNotFoundError(f\"Data file not found: {filepath}\")\n",
    "    \n",
    "    logger.info(f\"Loading data from {filepath}\")\n",
    "    df = pd.read_csv(filepath)\n",
    "    \n",
    "    # Validate required columns\n",
    "    required_cols = [\"Number\", \"Short Description\", \"Description\", \"Category\", \"Subcategory\"]\n",
    "    missing = [c for c in required_cols if c not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing required columns: {missing}\")\n",
    "    \n",
    "    # Fill NA and Clean Text\n",
    "    for col in [\"Short Description\", \"Description\"]:\n",
    "        df[col] = df[col].fillna(\"\").astype(str).str.strip()\n",
    "        \n",
    "    for col in [\"Category\", \"Subcategory\"]:\n",
    "        df[col] = df[col].fillna(\"Unknown\").astype(str).str.strip()\n",
    "        \n",
    "    # Combined Text\n",
    "    df[\"text\"] = (df[\"Short Description\"] + \" \" + df[\"Description\"]).str.strip()\n",
    "    # Remove excessive whitespace\n",
    "    df[\"text\"] = df[\"text\"].str.replace(r'\\s+', ' ', regex=True)\n",
    "    \n",
    "    # Filter empty or too short\n",
    "    initial_count = len(df)\n",
    "    df = df[df[\"text\"].str.len() >= min_length].copy()\n",
    "    dropped = initial_count - len(df)\n",
    "    \n",
    "    if dropped > 0:\n",
    "        logger.warning(f\"Dropped {dropped} rows with text shorter than {min_length} characters\")\n",
    "    \n",
    "    # Encode Categories\n",
    "    df['category_id'] = df.groupby(['Category', 'Subcategory']).ngroup()\n",
    "    \n",
    "    print(f\"‚úÖ Loaded {len(df)} incidents (dropped {dropped} short/empty)\")\n",
    "    print(f\"   Unique Categories: {df['Category'].nunique()}\")\n",
    "    print(f\"   Unique Subcategories: {df['Subcategory'].nunique()}\")\n",
    "    logger.info(f\"Data loaded: {len(df)} rows, {df['Category'].nunique()} categories\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Load Data\n",
    "df_incidents = load_and_clean_data(CONFIG['source_data'])\n",
    "df_incidents.head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Text Similarity Utilities\n",
    "We use TF-IDF similarity to find \"quality\" pairs (related but not identical) and \"hard negatives\" (different category but lexically similar).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-30 14:50:47,152 - INFO - Fitting TF-IDF vectorizer...\n",
      "2025-11-30 14:50:47,257 - INFO - TF-IDF fit complete. Matrix shape: (10000, 101)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ TF-IDF fit complete.\n"
     ]
    }
   ],
   "source": [
    "class TextSimilarityCalculator:\n",
    "    \"\"\"\n",
    "    Calculates TF-IDF based text similarity for pair generation.\n",
    "    Uses batch operations for efficiency.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.vectorizer = TfidfVectorizer(stop_words='english', max_features=10000)\n",
    "        self.tfidf_matrix = None\n",
    "\n",
    "    def fit_tfidf(self, texts):\n",
    "        \"\"\"Fit TF-IDF vectorizer on the corpus.\"\"\"\n",
    "        logger.info(\"Fitting TF-IDF vectorizer...\")\n",
    "        self.tfidf_matrix = self.vectorizer.fit_transform(texts)\n",
    "        logger.info(f\"TF-IDF fit complete. Matrix shape: {self.tfidf_matrix.shape}\")\n",
    "        print(\"‚úÖ TF-IDF fit complete.\")\n",
    "\n",
    "    def get_tfidf_similarity(self, idx1, idx2):\n",
    "        \"\"\"Compute cosine similarity between two sparse vectors (single pair).\"\"\"\n",
    "        if self.tfidf_matrix is None:\n",
    "            raise ValueError(\"Run fit_tfidf first\")\n",
    "        # Compute cosine similarity between two sparse vectors\n",
    "        return (self.tfidf_matrix[idx1] * self.tfidf_matrix[idx2].T).toarray()[0][0]\n",
    "    \n",
    "    def get_batch_similarities(self, indices1, indices2):\n",
    "        \"\"\"\n",
    "        Compute TF-IDF similarities for multiple pairs at once (much faster).\n",
    "        Args:\n",
    "            indices1: List/array of first indices\n",
    "            indices2: List/array of second indices (same length as indices1)\n",
    "        Returns:\n",
    "            Array of similarity scores\n",
    "        \"\"\"\n",
    "        if self.tfidf_matrix is None:\n",
    "            raise ValueError(\"Run fit_tfidf first\")\n",
    "        # Batch compute cosine similarities\n",
    "        vec1 = self.tfidf_matrix[indices1]\n",
    "        vec2 = self.tfidf_matrix[indices2]\n",
    "        # Compute dot product for each pair (cosine similarity for normalized vectors)\n",
    "        similarities = np.array([(vec1[i] * vec2[i].T).toarray()[0][0] for i in range(len(indices1))])\n",
    "        return similarities\n",
    "\n",
    "sim_calculator = TextSimilarityCalculator()\n",
    "sim_calculator.fit_tfidf(df_incidents['text'].tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Smart Pair Generation\n",
    "Generating positive pairs (same subcategory + semantic overlap) and hard negatives (different category + lexical overlap).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-30 14:50:47,271 - INFO - Generating 20000 positive and 30000 negative pairs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 20000 positive and 30000 negative pairs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Positives: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20000/20000 [00:04<00:00, 4345.71it/s]\n",
      "Negatives: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 30000/30000 [00:08<00:00, 3524.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Generated 20000 positive and 30000 negative pairs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def generate_smart_pairs(df, target_count, pos_ratio=0.4):\n",
    "    \"\"\"\n",
    "    Generate positive and negative training pairs using TF-IDF similarity.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame with incidents\n",
    "        target_count: Total number of pairs to generate\n",
    "        pos_ratio: Ratio of positive pairs (default 0.4)\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (positive_pairs, negative_pairs) where each is a list of (idx1, idx2, similarity_score)\n",
    "    \"\"\"\n",
    "    positive_target = int(target_count * pos_ratio)\n",
    "    negative_target = target_count - positive_target\n",
    "    \n",
    "    positives = []\n",
    "    negatives = []\n",
    "    \n",
    "    # Group by Category/Subcategory\n",
    "    groups = df.groupby('category_id')\n",
    "    group_indices = {k: v.index.tolist() for k, v in groups}\n",
    "    all_indices = df.index.tolist()\n",
    "    \n",
    "    logger.info(f\"Generating {positive_target} positive and {negative_target} negative pairs...\")\n",
    "    print(f\"Generating {positive_target} positive and {negative_target} negative pairs...\")\n",
    "    \n",
    "    # --- 1. Positive Pairs ---\n",
    "    # Strategy: Sample pairs from same group, check TF-IDF score to ensure they aren't duplicates or too vague\n",
    "    pbar = tqdm(total=positive_target, desc=\"Positives\")\n",
    "    attempts = 0\n",
    "    while len(positives) < positive_target and attempts < positive_target * 5:\n",
    "        attempts += 1\n",
    "        # Pick random group\n",
    "        gid = random.choice(list(group_indices.keys()))\n",
    "        g_idxs = group_indices[gid]\n",
    "        if len(g_idxs) < 2: continue\n",
    "        \n",
    "        i1, i2 = random.sample(g_idxs, 2)\n",
    "        \n",
    "        # Convert DataFrame index to integer location for TF-IDF\n",
    "        loc1 = df.index.get_loc(i1)\n",
    "        loc2 = df.index.get_loc(i2)\n",
    "        \n",
    "        sim = sim_calculator.get_tfidf_similarity(loc1, loc2)\n",
    "        \n",
    "        # Accept if similarity is decent (avoiding identicals if sim=1.0, though duplicates happen)\n",
    "        if sim > CONFIG['quality_threshold']:\n",
    "            positives.append((i1, i2, sim))\n",
    "            pbar.update(1)\n",
    "            \n",
    "    pbar.close()\n",
    "    \n",
    "    # --- 2. Hard Negative Pairs ---\n",
    "    # Strategy: Different categories but high TF-IDF overlap (confusing examples)\n",
    "    pbar = tqdm(total=negative_target, desc=\"Negatives\")\n",
    "    attempts = 0\n",
    "    while len(negatives) < negative_target:\n",
    "        attempts += 1\n",
    "        \n",
    "        # Random sampling\n",
    "        i1, i2 = random.sample(all_indices, 2)\n",
    "        \n",
    "        # Must be different categories\n",
    "        if df.at[i1, 'Category'] == df.at[i2, 'Category']:\n",
    "            continue\n",
    "            \n",
    "        loc1 = df.index.get_loc(i1)\n",
    "        loc2 = df.index.get_loc(i2)\n",
    "        sim = sim_calculator.get_tfidf_similarity(loc1, loc2)\n",
    "        \n",
    "        # Hard Negative Criteria\n",
    "        is_hard = CONFIG['hard_negative_min'] < sim < CONFIG['hard_negative_max']\n",
    "        \n",
    "        # Accept if hard negative OR we are struggling to find hard ones (fallback to random after many attempts)\n",
    "        if is_hard or attempts > negative_target * 10:\n",
    "            negatives.append((i1, i2, sim))\n",
    "            pbar.update(1)\n",
    "            if attempts > negative_target * 10:\n",
    "                # Reset attempts to avoid infinite fallback loop\n",
    "                attempts = 0 \n",
    "\n",
    "    pbar.close()\n",
    "    \n",
    "    # Validate results\n",
    "    if len(positives) < positive_target * 0.9:\n",
    "        logger.warning(f\"‚ö†Ô∏è Only generated {len(positives)}/{positive_target} positive pairs ({len(positives)/positive_target*100:.1f}%)\")\n",
    "    if len(negatives) < negative_target * 0.9:\n",
    "        logger.warning(f\"‚ö†Ô∏è Only generated {len(negatives)}/{negative_target} negative pairs ({len(negatives)/negative_target*100:.1f}%)\")\n",
    "    \n",
    "    print(f\"‚úÖ Generated {len(positives)} positive and {len(negatives)} negative pairs\")\n",
    "    \n",
    "    return positives, negatives\n",
    "\n",
    "pos_pairs_idxs, neg_pairs_idxs = generate_smart_pairs(df_incidents, CONFIG['target_pairs'], CONFIG['positive_ratio'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Data Augmentation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Training Samples: 45860\n",
      "‚úÖ Evaluation Samples: 8094\n",
      "   Train/Eval ratio: 5.67:1\n"
     ]
    }
   ],
   "source": [
    "def simple_augment(text):\n",
    "    \"\"\"\n",
    "    Simple text augmentation: randomly swap or delete words.\n",
    "    \n",
    "    Args:\n",
    "        text: Input text string\n",
    "        \n",
    "    Returns:\n",
    "        Augmented text string\n",
    "    \"\"\"\n",
    "    words = text.split()\n",
    "    if len(words) < 5: \n",
    "        return text\n",
    "    \n",
    "    if random.random() > 0.5:\n",
    "        # Swap adjacent words\n",
    "        idx = random.randint(0, len(words)-2)\n",
    "        words[idx], words[idx+1] = words[idx+1], words[idx]\n",
    "    else:\n",
    "        # Delete a random word\n",
    "        idx = random.randint(0, len(words)-1)\n",
    "        words.pop(idx)\n",
    "    return \" \".join(words)\n",
    "\n",
    "train_examples = []\n",
    "\n",
    "# --- Positives to InputExamples ---\n",
    "for i1, i2, score in pos_pairs_idxs:\n",
    "    t1 = df_incidents.at[i1, 'text']\n",
    "    t2 = df_incidents.at[i2, 'text']\n",
    "    \n",
    "    # Standard Pair\n",
    "    train_examples.append(InputExample(texts=[t1, t2], label=1.0))\n",
    "    \n",
    "    # Augmentation (only for subset)\n",
    "    if random.random() < CONFIG['augmentation_ratio']:\n",
    "        train_examples.append(InputExample(texts=[simple_augment(t1), t2], label=1.0))\n",
    "\n",
    "# --- Negatives to InputExamples ---\n",
    "for i1, i2, score in neg_pairs_idxs:\n",
    "    t1 = df_incidents.at[i1, 'text']\n",
    "    t2 = df_incidents.at[i2, 'text']\n",
    "    train_examples.append(InputExample(texts=[t1, t2], label=0.0))\n",
    "\n",
    "# Shuffle\n",
    "random.shuffle(train_examples)\n",
    "\n",
    "# Split Train/Eval using sklearn for proper stratified split\n",
    "# Note: We can't use stratified split directly on InputExamples, but sklearn's train_test_split\n",
    "# ensures proper randomization with seed\n",
    "train_data, eval_data = train_test_split(\n",
    "    train_examples,\n",
    "    test_size=CONFIG['eval_split'],\n",
    "    random_state=42,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Training Samples: {len(train_data)}\")\n",
    "print(f\"‚úÖ Evaluation Samples: {len(eval_data)}\")\n",
    "print(f\"   Train/Eval ratio: {len(train_data)/len(eval_data):.2f}:1\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Model Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-30 14:51:00,728 - INFO - Use pytorch device_name: mps\n",
      "2025-11-30 14:51:00,729 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-mpnet-base-v2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded: sentence-transformers/all-mpnet-base-v2\n",
      "Max Seq Length: 384\n",
      "Device: cpu\n",
      "DataLoader: 0 workers, pin_memory=False\n"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer(CONFIG['base_model'])\n",
    "model.max_seq_length = CONFIG['max_seq_length']\n",
    "\n",
    "# --- Loss Function ---\n",
    "# MultipleNegativesRankingLoss is standard for semantic search.\n",
    "# It treats other samples in the batch as negatives.\n",
    "train_loss = losses.MultipleNegativesRankingLoss(model)\n",
    "\n",
    "# --- DataLoader Configuration ---\n",
    "# Note: num_workers must be 0 for sentence-transformers InputExample objects\n",
    "# due to multiprocessing/pickling issues. pin_memory still helps with GPU transfer.\n",
    "num_workers = 0  # Must be 0 - sentence-transformers InputExample objects aren't picklable\n",
    "pin_memory = torch.cuda.is_available()  # Faster GPU transfer when using CUDA\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_data, \n",
    "    shuffle=True, \n",
    "    batch_size=CONFIG['batch_size'],\n",
    "    num_workers=num_workers,  # Set to 0 to avoid pickling errors\n",
    "    pin_memory=pin_memory,    # Faster GPU transfer (still works with num_workers=0)\n",
    "    prefetch_factor=None      # Not used when num_workers=0\n",
    ")\n",
    "\n",
    "# Check device\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Model loaded: {CONFIG['base_model']}\")\n",
    "print(f\"Max Seq Length: {model.max_seq_length}\")\n",
    "print(f\"Device: {device}\")\n",
    "print(f\"DataLoader: {num_workers} workers, pin_memory={pin_memory}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Evaluation Setup & Custom Callbacks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Evaluator initialized with 8094 evaluation examples\n"
     ]
    }
   ],
   "source": [
    "class ComprehensiveEvaluator(SentenceEvaluator):\n",
    "    \"\"\"\n",
    "    Custom evaluator to track multiple metrics: Spearman, Pearson, ROC AUC, PR AUC, and F1.\n",
    "    \n",
    "    This evaluator computes comprehensive metrics during training to monitor model performance.\n",
    "    It calculates correlation metrics (Spearman, Pearson) and classification metrics (ROC AUC, \n",
    "    PR AUC, F1) by finding the optimal threshold for binary classification.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, examples, batch_size=32, name='', show_progress_bar=False):\n",
    "        \"\"\"\n",
    "        Initialize the evaluator.\n",
    "        \n",
    "        Args:\n",
    "            examples: List of InputExample objects with (text1, text2, label) pairs\n",
    "            batch_size: Batch size for encoding embeddings\n",
    "            name: Name identifier for this evaluator\n",
    "            show_progress_bar: Whether to show progress bar during encoding\n",
    "        \"\"\"\n",
    "        self.examples = examples\n",
    "        self.batch_size = batch_size\n",
    "        self.name = name\n",
    "        self.show_progress_bar = show_progress_bar\n",
    "        \n",
    "        # Extract texts and labels from examples for efficient evaluation\n",
    "        self.texts1 = [ex.texts[0] for ex in examples]\n",
    "        self.texts2 = [ex.texts[1] for ex in examples]\n",
    "        self.labels = [ex.label for ex in examples]\n",
    "\n",
    "    def __call__(self, model, output_path: str = None, epoch: int = -1, steps: int = -1) -> float:\n",
    "        \"\"\"\n",
    "        Evaluate the model and compute all metrics.\n",
    "        \n",
    "        Args:\n",
    "            model: The SentenceTransformer model to evaluate\n",
    "            output_path: Directory path to save metrics CSV file\n",
    "            epoch: Current epoch number\n",
    "            steps: Current training step number\n",
    "            \n",
    "        Returns:\n",
    "            Spearman correlation coefficient (used as primary metric for model selection)\n",
    "        \"\"\"\n",
    "        # Set model to evaluation mode\n",
    "        model.eval()\n",
    "        \n",
    "        # Encode both text sequences into embeddings\n",
    "        # convert_to_numpy=True for efficient computation with NumPy\n",
    "        emb1 = model.encode(self.texts1, batch_size=self.batch_size, \n",
    "                           show_progress_bar=self.show_progress_bar, convert_to_numpy=True)\n",
    "        emb2 = model.encode(self.texts2, batch_size=self.batch_size, \n",
    "                           show_progress_bar=self.show_progress_bar, convert_to_numpy=True)\n",
    "        \n",
    "        # Calculate cosine similarity between embeddings\n",
    "        # Improved numerical stability: normalize embeddings first, then compute dot product\n",
    "        # This avoids potential division by zero and improves precision\n",
    "        emb1_norm = emb1 / (np.linalg.norm(emb1, axis=1, keepdims=True) + 1e-8)\n",
    "        emb2_norm = emb2 / (np.linalg.norm(emb2, axis=1, keepdims=True) + 1e-8)\n",
    "        cosine_scores = np.sum(emb1_norm * emb2_norm, axis=1)\n",
    "        \n",
    "        # Correlation metrics: measure how well similarity scores correlate with labels\n",
    "        eval_pearson, _ = pearsonr(self.labels, cosine_scores)\n",
    "        eval_spearman, _ = spearmanr(self.labels, cosine_scores)\n",
    "        \n",
    "        # Classification metrics: treat similarity as probability and find optimal threshold\n",
    "        try:\n",
    "            # ROC AUC: Area under ROC curve (measures ranking quality)\n",
    "            roc_auc = roc_auc_score(self.labels, cosine_scores)\n",
    "            # PR AUC: Area under Precision-Recall curve (better for imbalanced data)\n",
    "            pr_auc = average_precision_score(self.labels, cosine_scores)\n",
    "            \n",
    "            # F1 Score: Find optimal threshold that maximizes F1\n",
    "            # We search over precision-recall curve to find best threshold\n",
    "            precision, recall, thresholds = precision_recall_curve(self.labels, cosine_scores)\n",
    "            \n",
    "            # Calculate F1 for each threshold\n",
    "            # F1 = 2 * (precision * recall) / (precision + recall)\n",
    "            f1_scores = 2 * (precision * recall) / (precision + recall + 1e-8)\n",
    "            \n",
    "            # Find threshold that maximizes F1\n",
    "            best_f1_idx = np.argmax(f1_scores)\n",
    "            best_f1 = f1_scores[best_f1_idx]\n",
    "            optimal_threshold = thresholds[best_f1_idx] if best_f1_idx < len(thresholds) else 0.5\n",
    "            \n",
    "            # Also compute F1 at default 0.5 threshold for comparison\n",
    "            pred_binary = (cosine_scores >= 0.5).astype(int)\n",
    "            f1_at_05 = f1_score(self.labels, pred_binary)\n",
    "            \n",
    "        except ValueError as e:\n",
    "            # Handle edge cases (e.g., all labels are same class)\n",
    "            roc_auc = 0.0\n",
    "            pr_auc = 0.0\n",
    "            best_f1 = 0.0\n",
    "            f1_at_05 = 0.0\n",
    "            optimal_threshold = 0.5\n",
    "            logger.warning(f\"Error computing classification metrics: {e}\")\n",
    "\n",
    "        # Log all metrics for monitoring\n",
    "        logger.info(\n",
    "            f'Epoch {epoch}, Steps {steps}: '\n",
    "            f'Spearman={eval_spearman:.4f}, Pearson={eval_pearson:.4f}, '\n",
    "            f'ROC_AUC={roc_auc:.4f}, PR_AUC={pr_auc:.4f}, '\n",
    "            f'F1_optimal={best_f1:.4f}, F1@0.5={f1_at_05:.4f}, '\n",
    "            f'Threshold={optimal_threshold:.4f}'\n",
    "        )\n",
    "        \n",
    "        # Save detailed metrics to CSV for later analysis\n",
    "        if output_path:\n",
    "            csv_path = os.path.join(output_path, 'eval_metrics.csv')\n",
    "            file_exists = os.path.isfile(csv_path)\n",
    "            try:\n",
    "                with open(csv_path, mode='a', newline='') as f:\n",
    "                    # Include all metrics in CSV header\n",
    "                    header = 'epoch,steps,spearman,pearson,roc_auc,pr_auc,f1_optimal,f1_at_05,optimal_threshold\\n'\n",
    "                    if not file_exists: \n",
    "                        f.write(header)\n",
    "                    # Write metrics row\n",
    "                    f.write(\n",
    "                        f'{epoch},{steps},'\n",
    "                        f'{eval_spearman:.4f},{eval_pearson:.4f},'\n",
    "                        f'{roc_auc:.4f},{pr_auc:.4f},'\n",
    "                        f'{best_f1:.4f},{f1_at_05:.4f},'\n",
    "                        f'{optimal_threshold:.4f}\\n'\n",
    "                    )\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"Failed to save metrics to CSV: {e}\")\n",
    "\n",
    "        # Return Spearman correlation as primary metric\n",
    "        # SentenceTransformers uses this for model selection (save_best_model)\n",
    "        return eval_spearman\n",
    "\n",
    "# Initialize Evaluator\n",
    "# Check if eval_data exists (created in Cell 11 - Data Augmentation section)\n",
    "# If not, user needs to run Cell 11 first to generate the evaluation data\n",
    "if 'eval_data' not in globals() or eval_data is None:\n",
    "    raise NameError(\n",
    "        \"eval_data is not defined. Please run Cell 11 (Data Augmentation section) first.\\n\"\n",
    "        \"Cell 11 creates both train_data and eval_data by splitting the training examples.\"\n",
    "    )\n",
    "\n",
    "evaluator = ComprehensiveEvaluator(eval_data, batch_size=CONFIG['batch_size'], name='dev')\n",
    "print(f\"‚úÖ Evaluator initialized with {len(eval_data)} evaluation examples\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-30 14:51:04,759 - INFO - üìù Training metadata saved to models/all-mpnet-finetuned-v5_20251130_1451/training_metadata.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting training... Saving to models/all-mpnet-finetuned-v5_20251130_1451\n",
      "   Training on 45860 examples, evaluating on 8094 examples\n",
      "   Epochs: 20, Batch size: 64, LR: 2e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='14340' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [    6/14340 06:34 < 392:29:38, 0.01 it/s, Epoch 0.01/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define Output Path\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M')\n",
    "save_path = f\"{CONFIG['output_dir']}_{timestamp}\"\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "# Save training metadata for reproducibility\n",
    "training_metadata = {\n",
    "    'base_model': CONFIG['base_model'],\n",
    "    'source_data': CONFIG['source_data'],\n",
    "    'training_date': datetime.now().isoformat(),\n",
    "    'epochs': CONFIG['epochs'],\n",
    "    'batch_size': CONFIG['batch_size'],\n",
    "    'learning_rate': CONFIG['learning_rate'],\n",
    "    'weight_decay': CONFIG['weight_decay'],\n",
    "    'warmup_ratio': CONFIG['warmup_ratio'],\n",
    "    'max_seq_length': CONFIG['max_seq_length'],\n",
    "    'eval_split': CONFIG['eval_split'],\n",
    "    'num_train_examples': len(train_data),\n",
    "    'num_eval_examples': len(eval_data),\n",
    "    'num_positive_pairs': len(pos_pairs_idxs),\n",
    "    'num_negative_pairs': len(neg_pairs_idxs),\n",
    "    'target_pairs': CONFIG['target_pairs'],\n",
    "    'positive_ratio': CONFIG['positive_ratio'],\n",
    "    'augmentation_ratio': CONFIG['augmentation_ratio'],\n",
    "    'quality_threshold': CONFIG['quality_threshold'],\n",
    "    'hard_negative_min': CONFIG['hard_negative_min'],\n",
    "    'hard_negative_max': CONFIG['hard_negative_max']\n",
    "}\n",
    "\n",
    "metadata_path = os.path.join(save_path, 'training_metadata.json')\n",
    "with open(metadata_path, 'w') as f:\n",
    "    json.dump(training_metadata, f, indent=2)\n",
    "logger.info(f\"üìù Training metadata saved to {metadata_path}\")\n",
    "\n",
    "# Train\n",
    "print(f'üöÄ Starting training... Saving to {save_path}')\n",
    "print(f'   Training on {len(train_data)} examples, evaluating on {len(eval_data)} examples')\n",
    "print(f'   Epochs: {CONFIG[\"epochs\"]}, Batch size: {CONFIG[\"batch_size\"]}, LR: {CONFIG[\"learning_rate\"]}')\n",
    "\n",
    "model.fit(\n",
    "    train_objectives=[(train_dataloader, train_loss)],\n",
    "    evaluator=evaluator,\n",
    "    epochs=CONFIG['epochs'],\n",
    "    warmup_steps=int(len(train_dataloader) * CONFIG['epochs'] * CONFIG['warmup_ratio']),\n",
    "    optimizer_params={'lr': CONFIG['learning_rate'], 'weight_decay': CONFIG['weight_decay']},\n",
    "    output_path=save_path,\n",
    "    evaluation_steps=CONFIG['eval_steps'],\n",
    "    save_best_model=True,\n",
    "    show_progress_bar=True\n",
    ")\n",
    "\n",
    "print('‚úÖ Training complete.')\n",
    "logger.info(f\"‚úÖ Model saved to {save_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Final Evaluation & Visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload Best Model\n",
    "logger.info(f\"Loading best model from {save_path}\")\n",
    "best_model = SentenceTransformer(save_path)\n",
    "\n",
    "# Encode Eval Data\n",
    "eval_texts1 = [ex.texts[0] for ex in eval_data]\n",
    "eval_texts2 = [ex.texts[1] for ex in eval_data]\n",
    "eval_labels = [ex.label for ex in eval_data]\n",
    "\n",
    "logger.info(f\"Encoding {len(eval_texts1)} evaluation pairs...\")\n",
    "embeddings1 = best_model.encode(eval_texts1, batch_size=CONFIG['batch_size'], show_progress_bar=True)\n",
    "embeddings2 = best_model.encode(eval_texts2, batch_size=CONFIG['batch_size'], show_progress_bar=True)\n",
    "\n",
    "# Calculate proper cosine similarity (normalized)\n",
    "# This matches the calculation in ComprehensiveEvaluator\n",
    "cosine_scores = np.sum(embeddings1 * embeddings2, axis=1) / (np.linalg.norm(embeddings1, axis=1) * np.linalg.norm(embeddings2, axis=1))\n",
    "\n",
    "# Calculate final metrics\n",
    "final_spearman, _ = spearmanr(eval_labels, cosine_scores)\n",
    "final_pearson, _ = pearsonr(eval_labels, cosine_scores)\n",
    "final_roc_auc = roc_auc_score(eval_labels, cosine_scores)\n",
    "final_pr_auc = average_precision_score(eval_labels, cosine_scores)\n",
    "\n",
    "print(f\"\\nüìä Final Evaluation Metrics:\")\n",
    "print(f\"   Spearman Correlation: {final_spearman:.4f}\")\n",
    "print(f\"   Pearson Correlation: {final_pearson:.4f}\")\n",
    "print(f\"   ROC AUC: {final_roc_auc:.4f}\")\n",
    "print(f\"   PR AUC: {final_pr_auc:.4f}\")\n",
    "logger.info(f\"Final metrics - Spearman: {final_spearman:.4f}, ROC AUC: {final_roc_auc:.4f}\")\n",
    "\n",
    "# --- Plots ---\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# 1. Distribution\n",
    "sns.histplot(cosine_scores[np.array(eval_labels)==1], color='green', label='Positive', kde=True, ax=axes[0])\n",
    "sns.histplot(cosine_scores[np.array(eval_labels)==0], color='red', label='Negative', kde=True, ax=axes[0])\n",
    "axes[0].set_title('Cosine Similarity Distribution')\n",
    "axes[0].legend()\n",
    "\n",
    "# 2. ROC Curve\n",
    "fpr, tpr, _ = roc_curve(eval_labels, cosine_scores)\n",
    "roc_auc = roc_auc_score(eval_labels, cosine_scores)\n",
    "axes[1].plot(fpr, tpr, label=f'AUC = {roc_auc:.3f}')\n",
    "axes[1].plot([0, 1], [0, 1], 'k--')\n",
    "axes[1].set_title('ROC Curve')\n",
    "axes[1].legend()\n",
    "\n",
    "# 3. Precision-Recall\n",
    "precision, recall, _ = precision_recall_curve(eval_labels, cosine_scores)\n",
    "pr_auc = average_precision_score(eval_labels, cosine_scores)\n",
    "axes[2].plot(recall, precision, label=f'PR AUC = {pr_auc:.3f}')\n",
    "axes[2].set_title('Precision-Recall Curve')\n",
    "axes[2].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Relationship Classifier (Optional)\n",
    "Trains a secondary classifier to predict relationship types (duplicate, causal, related).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if IMBLEARN_AVAILABLE and os.path.exists(CONFIG['relationship_data']):\n",
    "    print('üß† Training Relationship Classifier...')\n",
    "    with open(CONFIG['relationship_data'], 'r') as f:\n",
    "        rel_data = json.load(f)\n",
    "    \n",
    "    rel_df = pd.DataFrame(rel_data)\n",
    "    # Filter valid labels\n",
    "    valid_labels = ['duplicate', 'causal', 'related', 'none']\n",
    "    rel_df = rel_df[rel_df['label'].isin(valid_labels)]\n",
    "    \n",
    "    # Encode features using fine-tuned model\n",
    "    text_a = rel_df['text_a'].tolist()\n",
    "    text_b = rel_df['text_b'].tolist()\n",
    "    \n",
    "    emb_a = best_model.encode(text_a)\n",
    "    emb_b = best_model.encode(text_b)\n",
    "    \n",
    "    # Feature Engineering: (u, v, |u-v|, u*v)\n",
    "    X = np.hstack([emb_a, emb_b, np.abs(emb_a - emb_b), emb_a * emb_b])\n",
    "    y = rel_df['label']\n",
    "    \n",
    "    # SMOTE Balancing\n",
    "    smote = SMOTE(k_neighbors=2, random_state=42)\n",
    "    X_res, y_res = smote.fit_resample(X, y)\n",
    "    \n",
    "    # Train Classifier\n",
    "    clf = LogisticRegression(max_iter=1000, multi_class='multinomial')\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.2, random_state=42)\n",
    "    \n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluation\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    # Save\n",
    "    joblib.dump(clf, os.path.join(save_path, 'relationship_classifier.joblib'))\n",
    "    print('‚úÖ Relationship classifier saved.')\n",
    "else:\n",
    "    print('‚ö†Ô∏è Skipping relationship classifier (missing data or imbalanced-learn).')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "itsm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
