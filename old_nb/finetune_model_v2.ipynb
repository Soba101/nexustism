{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4adba107",
   "metadata": {
    "id": "4adba107"
   },
   "source": [
    "## 0. Install Required Dependencies\n",
    "\n",
    "**Run this cell first if you encounter import errors**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "faa849f2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "faa849f2",
    "outputId": "78c4c45d-cd51-4ba3-bec0-520f99b5344a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing accelerate>=0.26.0...\n",
      "Installing datasets...\n",
      "‚úÖ All dependencies installed! Please restart the kernel (Kernel > Restart Kernel) and then run all cells.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import subprocess\n",
    "\n",
    "# Install required dependencies\n",
    "dependencies = ['accelerate>=0.26.0', 'datasets']\n",
    "\n",
    "for dep in dependencies:\n",
    "    print(f\"Installing {dep}...\")\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", dep])\n",
    "\n",
    "print(\"‚úÖ All dependencies installed! Please restart the kernel (Kernel > Restart Kernel) and then run all cells.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672a0899",
   "metadata": {
    "id": "672a0899"
   },
   "source": [
    "# Fine-tune SentenceTransformer Models for ITSM Tickets\n",
    "This notebook fine-tunes the **all-mpnet-base-v2** embedding model (and can be adapted for others) using contrastive learning with pseudo-labeled training data from your ITSM tickets.\n",
    "## Approach\n",
    "- **Positive pairs**: Tickets from the same category (assumed similar)\n",
    "- **Negative pairs**: Tickets from different categories (assumed dissimilar)\n",
    "- **Loss function**: Cosine Similarity Loss (contrastive learning)\n",
    "- **Base model**: sentence-transformers/all-mpnet-base-v2 (768-dim embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00153186",
   "metadata": {
    "id": "00153186"
   },
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f590a0ad",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f590a0ad",
    "outputId": "5554a3e6-a1ed-4eab-f280-fc1c17c5141c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/itsm/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Imports successful\n",
      "PyTorch version: 2.9.1\n",
      "Device: CPU\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, os.path.join(os.path.dirname(os.getcwd()), '..'))\n",
    "\n",
    "import json\n",
    "import torch\n",
    "from datetime import datetime\n",
    "import logging\n",
    "from datasets import DatasetDict  # <-- Added here\n",
    "\n",
    "# Import sentence-transformers\n",
    "from sentence_transformers import SentenceTransformer, InputExample, losses\n",
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "print(\"‚úÖ Imports successful\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"Device: {'CUDA' if torch.cuda.is_available() else 'CPU'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482a6716",
   "metadata": {
    "id": "482a6716"
   },
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be35e250",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "be35e250",
    "outputId": "4685ada4-fa38-4775-bc49-0360c01da576"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration:\n",
      "  base_model: sentence-transformers/all-mpnet-base-v2\n",
      "  source_data: ../data/servicenow_incidents_full.json\n",
      "  output_dir: models/all-mpnet-finetuned\n",
      "  epochs: 12\n",
      "  batch_size: 32\n",
      "  learning_rate: 2e-05\n",
      "  warmup_steps: 100\n",
      "  eval_split: 0.1\n"
     ]
    }
   ],
   "source": [
    "# Training configuration\n",
    "CONFIG = {\n",
    "    'base_model': 'sentence-transformers/all-mpnet-base-v2',\n",
    "    'source_data': '../data/servicenow_incidents_full.json',  # Source incidents\n",
    "    'output_dir': 'models/all-mpnet-finetuned',\n",
    "    'epochs': 12,  # Start lean to avoid overfitting; increase once eval is stable\n",
    "    'batch_size': 32,\n",
    "    'learning_rate': 2e-5,\n",
    "    'warmup_steps': 100,\n",
    "    'eval_split': 0.1  # 10% for evaluation\n",
    "}\n",
    "\n",
    "print(\"Configuration:\")\n",
    "for key, value in CONFIG.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa23f90",
   "metadata": {
    "id": "2aa23f90"
   },
   "source": [
    "## 3. Load Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bee61213",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bee61213",
    "outputId": "8d9eed4b-0c66-4f7b-abf8-9585b420e89f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading incidents from: data/servicenow_incidents_full.json\n",
      "Loaded 76 incidents\n",
      "\n",
      "Categories found: 5\n",
      "  Inquiry / Help: 41 incidents\n",
      "  Network: 6 incidents\n",
      "  Hardware: 10 incidents\n",
      "  Software: 13 incidents\n",
      "  Database: 2 incidents\n",
      "\n",
      "üìä Generated Training Pairs:\n",
      "  Positive pairs: 291\n",
      "  Negative pairs: 118\n",
      "  Total pairs: 409\n",
      "\n",
      "‚úÖ Training pairs saved to: /Users/don/Documents/University/Current Classes/Capstone/let me try again/data/training_pairs.json\n"
     ]
    }
   ],
   "source": [
    "# Generate training pairs from ServiceNow incidents\n",
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "# Load ServiceNow incidents\n",
    "incidents_file = \"data/servicenow_incidents_full.json\"\n",
    "print(f\"Loading incidents from: {incidents_file}\")\n",
    "\n",
    "with open(incidents_file, 'r') as f:\n",
    "    incidents = json.load(f)\n",
    "\n",
    "print(f\"Loaded {len(incidents)} incidents\")\n",
    "\n",
    "# Group incidents by category\n",
    "category_groups = defaultdict(list)\n",
    "for incident in incidents:\n",
    "    category = incident.get('category', 'Unknown')\n",
    "    if category and category != '':\n",
    "        # Create text representation combining short_description and description\n",
    "        text = f\"{incident.get('short_description', '')}. {incident.get('description', '')}\"\n",
    "        category_groups[category].append({\n",
    "            'id': incident.get('incident_number', incident.get('sys_id', '')),\n",
    "            'text': text.strip(),\n",
    "            'category': category\n",
    "        })\n",
    "\n",
    "print(f\"\\nCategories found: {len(category_groups)}\")\n",
    "for cat, items in category_groups.items():\n",
    "    print(f\"  {cat}: {len(items)} incidents\")\n",
    "\n",
    "# Generate positive pairs (same category)\n",
    "positive_pairs = []\n",
    "for category, items in category_groups.items():\n",
    "    if len(items) >= 2:\n",
    "        # Create pairs within the same category\n",
    "        for i in range(len(items)):\n",
    "            for j in range(i + 1, min(i + 6, len(items))):  # Limit pairs per incident\n",
    "                positive_pairs.append({\n",
    "                    'ticket1_id': items[i]['id'],\n",
    "                    'ticket2_id': items[j]['id'],\n",
    "                    'text1': items[i]['text'],\n",
    "                    'text2': items[j]['text'],\n",
    "                    'category1': category,\n",
    "                    'category2': category\n",
    "                })\n",
    "\n",
    "# Generate negative pairs (different categories)\n",
    "negative_pairs = []\n",
    "categories = list(category_groups.keys())\n",
    "for i in range(len(categories)):\n",
    "    for j in range(i + 1, len(categories)):\n",
    "        cat1_items = category_groups[categories[i]]\n",
    "        cat2_items = category_groups[categories[j]]\n",
    "\n",
    "        # Sample random pairs between different categories\n",
    "        num_pairs = min(len(cat1_items) * 2, len(cat2_items) * 2, 50)\n",
    "        for _ in range(num_pairs):\n",
    "            item1 = random.choice(cat1_items)\n",
    "            item2 = random.choice(cat2_items)\n",
    "            negative_pairs.append({\n",
    "                'ticket1_id': item1['id'],\n",
    "                'ticket2_id': item2['id'],\n",
    "                'text1': item1['text'],\n",
    "                'text2': item2['text'],\n",
    "                'category1': item1['category'],\n",
    "                'category2': item2['category']\n",
    "            })\n",
    "\n",
    "print(f\"\\nüìä Generated Training Pairs:\")\n",
    "print(f\"  Positive pairs: {len(positive_pairs)}\")\n",
    "print(f\"  Negative pairs: {len(negative_pairs)}\")\n",
    "print(f\"  Total pairs: {len(positive_pairs) + len(negative_pairs)}\")\n",
    "\n",
    "# Save to training_pairs.json for future use\n",
    "training_data = {\n",
    "    'positive_pairs': positive_pairs,\n",
    "    'negative_pairs': negative_pairs,\n",
    "    'metadata': {\n",
    "        'num_incidents': len(incidents),\n",
    "        'num_categories': len(category_groups),\n",
    "        'generated_on': datetime.now().isoformat()\n",
    "    }\n",
    "}\n",
    "\n",
    "training_pairs_path = os.path.join(os.getcwd(), 'data', 'training_pairs.json')\n",
    "os.makedirs(os.path.dirname(training_pairs_path), exist_ok=True)\n",
    "with open(training_pairs_path, 'w') as f:\n",
    "    json.dump(training_data, f, indent=2)\n",
    "\n",
    "print(f\"\\n‚úÖ Training pairs saved to: {training_pairs_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a389121",
   "metadata": {},
   "source": [
    "# 3.1 Load & Clean Relationship Pairs‚Äù"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d790009b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d790009b",
    "outputId": "c4137875-44bd-4907-8684-9107273ad202"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Training Data Summary:\n",
      "  Positive pairs: 291\n",
      "  Negative pairs: 118\n",
      "  Total pairs: 409\n",
      "\n",
      "üìù Example Positive Pair (same category):\n",
      "  Category: Inquiry / Help\n",
      "  Ticket 1 (INC0010054): Equipment selection not saved for new location. During the onboarding process for an additional loca...\n",
      "  Ticket 2 (INC0010053): Merchant unable to submit e-signed agreement. A Sales Agent's access to configure service fees for a...\n",
      "\n",
      "üìù Example Negative Pair (different categories):\n",
      "  Category 1: Inquiry / Help\n",
      "  Category 2: Network\n",
      "  Ticket 1 (INC0000011): Need new Blackberry set up. I'm replacing my old phone with a Blackberry and require assistance to g...\n",
      "  Ticket 2 (INC0000049): Network storage unavailable. Receiving error message with \"network path not found.\"...\n"
     ]
    }
   ],
   "source": [
    "# The training pairs are already loaded from the previous cell\n",
    "# Just display a summary\n",
    "print(f\"\\nüìä Training Data Summary:\")\n",
    "print(f\"  Positive pairs: {len(positive_pairs)}\")\n",
    "print(f\"  Negative pairs: {len(negative_pairs)}\")\n",
    "print(f\"  Total pairs: {len(positive_pairs) + len(negative_pairs)}\")\n",
    "\n",
    "# Show example pairs\n",
    "if positive_pairs:\n",
    "    print(f\"\\nüìù Example Positive Pair (same category):\")\n",
    "    example = positive_pairs[0]\n",
    "    print(f\"  Category: {example['category1']}\")\n",
    "    print(f\"  Ticket 1 ({example['ticket1_id']}): {example['text1'][:100]}...\")\n",
    "    print(f\"  Ticket 2 ({example['ticket2_id']}): {example['text2'][:100]}...\")\n",
    "\n",
    "if negative_pairs:\n",
    "    print(f\"\\nüìù Example Negative Pair (different categories):\")\n",
    "    example = negative_pairs[0]\n",
    "    print(f\"  Category 1: {example['category1']}\")\n",
    "    print(f\"  Category 2: {example['category2']}\")\n",
    "    print(f\"  Ticket 1 ({example['ticket1_id']}): {example['text1'][:100]}...\")\n",
    "    print(f\"  Ticket 2 ({example['ticket2_id']}): {example['text2'][:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5c99e5",
   "metadata": {},
   "source": [
    "# 3.2 Build Pairwise Features & Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "982f6491",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "ea3e52cd528849f8bebc78c404347b8d",
      "794cded4974f4d0aa6c7508dbf21a2c9",
      "19b1bc33795a4a1e8ae597fd670292ae",
      "8586a1871c0c40c2b1da318574caac32",
      "e40feb21ae2c4871b9875dc156391a5d",
      "2312932583a945d8a29cdc2cc046f8a6",
      "0de5202e75df4fafa0abf487e3df4907",
      "d7cf42dcbeed4008ac0bbef80f29d114",
      "ce73740c718640f69fbc5ab01c26b6eb",
      "3c9b771af6484c15a99b486946e4defb",
      "2977bc6f50cb4a55915a5c0d347f3891"
     ]
    },
    "id": "982f6491",
    "outputId": "2f92c470-8402-4f34-b644-74bcd321b421"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-24 13:51:29,185 - INFO - Use pytorch device_name: mps\n",
      "2025-11-24 13:51:29,185 - INFO - Load pretrained SentenceTransformer: /Users/don/Documents/University/Current Classes/Capstone/let me try again/models/all-mpnet-finetuned\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: `output_path` was not defined. Using fallback: /Users/don/Documents/University/Current Classes/Capstone/let me try again/models/all-mpnet-finetuned\n",
      "OPENAI_API_KEY detected: set\n",
      "Loading: /Users/don/Documents/University/Current Classes/Capstone/let me try again/data/servicenow_incidents_full.json\n",
      "Loaded 76 incidents\n",
      "  incident_number                                  short_description\n",
      "0      INC0010054     Equipment selection not saved for new location\n",
      "1      INC0010053       Merchant unable to submit e-signed agreement\n",
      "2      INC0010052   Equipment Configuration Freeze on Legacy Browser\n",
      "3      INC0010051                   Error in Equipment Configuration\n",
      "4      INC0010050  Touchscreen malfunction on Merchant's device f...\n",
      "\n",
      "Loading embedding model from: /Users/don/Documents/University/Current Classes/Capstone/let me try again/models/all-mpnet-finetuned\n",
      "Encoding all incidents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00,  5.12it/s]\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing similarities...\n",
      "Candidate pairs: 191\n",
      "\n",
      "Labeling 191 pairs using LLM‚Ä¶\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-24 13:51:32,088 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:51:34,678 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:51:37,522 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:51:40,961 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:51:43,656 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚Üí 5/191 pairs labeled\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-24 13:51:45,608 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:51:47,952 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:51:51,201 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:51:54,461 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:51:56,886 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚Üí 10/191 pairs labeled\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-24 13:51:59,185 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:52:01,870 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:52:03,837 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:52:06,302 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:52:08,747 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚Üí 15/191 pairs labeled\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-24 13:52:10,836 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:52:13,491 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:52:15,768 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:52:17,943 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:52:20,081 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚Üí 20/191 pairs labeled\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-24 13:52:22,100 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:52:23,991 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:52:26,851 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:52:28,985 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:52:30,960 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚Üí 25/191 pairs labeled\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-24 13:52:33,131 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:52:35,130 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:52:37,639 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:52:40,212 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:52:42,068 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚Üí 30/191 pairs labeled\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-24 13:52:44,150 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:52:45,801 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:52:47,988 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:52:50,015 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:52:52,491 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚Üí 35/191 pairs labeled\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-24 13:52:54,395 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:52:56,378 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:52:58,255 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:53:00,434 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:53:03,049 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚Üí 40/191 pairs labeled\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-24 13:53:05,333 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:53:07,761 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:53:09,889 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:53:12,064 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:53:20,664 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚Üí 45/191 pairs labeled\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-24 13:53:22,265 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:53:24,668 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:53:26,710 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:53:29,053 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:53:31,552 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚Üí 50/191 pairs labeled\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-24 13:53:33,585 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:53:36,618 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:53:39,481 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:53:41,386 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:53:43,810 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚Üí 55/191 pairs labeled\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-24 13:53:46,307 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:53:48,826 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:53:50,865 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:53:56,036 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:53:57,810 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚Üí 60/191 pairs labeled\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-24 13:54:01,046 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:54:03,431 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:54:05,797 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:54:07,446 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:54:09,522 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚Üí 65/191 pairs labeled\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-24 13:54:12,084 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:54:14,616 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:54:16,790 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:54:18,841 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:54:21,323 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚Üí 70/191 pairs labeled\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-24 13:54:24,116 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:54:29,615 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:54:31,531 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:54:33,592 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:54:35,547 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚Üí 75/191 pairs labeled\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-24 13:54:37,708 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:54:39,554 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:54:41,951 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:54:43,801 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:54:45,777 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚Üí 80/191 pairs labeled\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-24 13:54:48,783 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:54:51,226 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:54:53,095 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:54:54,862 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:54:57,830 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚Üí 85/191 pairs labeled\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-24 13:54:59,652 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:55:01,868 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:55:05,071 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:55:07,206 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:55:09,215 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚Üí 90/191 pairs labeled\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-24 13:55:11,831 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:55:15,303 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:55:17,705 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:55:19,843 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:55:22,336 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚Üí 95/191 pairs labeled\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-24 13:55:24,374 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:55:26,582 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:55:28,375 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:55:30,196 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:55:32,378 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚Üí 100/191 pairs labeled\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-24 13:55:34,663 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:55:37,063 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:55:39,077 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:55:54,995 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:55:57,595 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚Üí 105/191 pairs labeled\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-24 13:55:59,878 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:56:02,311 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:56:04,437 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:56:06,937 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:56:09,166 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚Üí 110/191 pairs labeled\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-24 13:56:11,323 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:56:13,339 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:56:15,436 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:56:19,579 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:56:21,628 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚Üí 115/191 pairs labeled\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-24 13:56:23,682 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:56:28,942 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:56:31,154 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:56:34,771 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:56:36,679 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚Üí 120/191 pairs labeled\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-24 13:56:40,451 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:56:42,354 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:56:44,724 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:56:46,966 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:56:48,783 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚Üí 125/191 pairs labeled\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-24 13:56:51,038 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:56:53,478 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:56:55,520 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:56:57,742 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:57:00,155 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚Üí 130/191 pairs labeled\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-24 13:57:02,166 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:57:04,142 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:57:07,204 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:57:09,293 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:57:12,464 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚Üí 135/191 pairs labeled\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-24 13:57:15,037 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:57:17,051 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:57:19,085 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:57:21,164 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:57:23,399 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚Üí 140/191 pairs labeled\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-24 13:57:26,780 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:57:29,293 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:57:31,622 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:57:33,578 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:57:35,433 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚Üí 145/191 pairs labeled\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-24 13:57:37,792 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:57:39,921 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:57:42,297 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:57:44,240 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:57:46,150 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚Üí 150/191 pairs labeled\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-24 13:57:48,574 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:57:50,569 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:57:52,738 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:57:55,003 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:57:57,169 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚Üí 155/191 pairs labeled\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-24 13:57:59,321 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:58:01,785 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:58:03,941 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:58:06,093 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:58:08,646 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚Üí 160/191 pairs labeled\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-24 13:58:11,304 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:58:13,164 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:58:15,394 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:58:17,999 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:58:20,206 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚Üí 165/191 pairs labeled\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-24 13:58:22,347 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:58:24,530 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:58:26,740 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:58:29,155 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:58:31,347 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚Üí 170/191 pairs labeled\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-24 13:58:32,859 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:58:34,504 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:58:36,849 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:58:39,104 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:58:41,294 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚Üí 175/191 pairs labeled\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-24 13:58:43,546 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:58:45,883 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:58:47,574 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:58:49,424 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:58:51,460 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚Üí 180/191 pairs labeled\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-24 13:58:53,166 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:58:55,256 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:58:58,458 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:59:00,271 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:59:02,157 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚Üí 185/191 pairs labeled\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-24 13:59:04,764 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:59:06,514 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:59:08,581 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:59:11,023 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 13:59:12,917 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚Üí 190/191 pairs labeled\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-24 13:59:15,211 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved relationship pairs:\n",
      "CSV : data/relationship_pairs.csv\n",
      "JSON: data/relationship_pairs.json\n",
      "\n",
      "Sample:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticket_a_number</th>\n",
       "      <th>ticket_b_number</th>\n",
       "      <th>text_a</th>\n",
       "      <th>text_b</th>\n",
       "      <th>similarity</th>\n",
       "      <th>label</th>\n",
       "      <th>direction</th>\n",
       "      <th>explanation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INC0010054</td>\n",
       "      <td>INC0010050</td>\n",
       "      <td>Equipment selection not saved for new location...</td>\n",
       "      <td>Touchscreen malfunction on Merchant's device f...</td>\n",
       "      <td>0.924660</td>\n",
       "      <td>related</td>\n",
       "      <td>none</td>\n",
       "      <td>Ticket A describes an issue with equipment sel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>INC0010054</td>\n",
       "      <td>INC0010048</td>\n",
       "      <td>Equipment selection not saved for new location...</td>\n",
       "      <td>Access Rights Restriction\\n\\nMerchant reported...</td>\n",
       "      <td>0.926441</td>\n",
       "      <td>related</td>\n",
       "      <td>none</td>\n",
       "      <td>Ticket A describes an issue with equipment sel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INC0010054</td>\n",
       "      <td>INC0010046</td>\n",
       "      <td>Equipment selection not saved for new location...</td>\n",
       "      <td>Access Rights Restriction\\n\\nMerchant reported...</td>\n",
       "      <td>0.926441</td>\n",
       "      <td>related</td>\n",
       "      <td>none</td>\n",
       "      <td>Ticket A describes an issue with equipment sel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INC0010054</td>\n",
       "      <td>INC0010051</td>\n",
       "      <td>Equipment selection not saved for new location...</td>\n",
       "      <td>Error in Equipment Configuration\\n\\nSales Agen...</td>\n",
       "      <td>0.941556</td>\n",
       "      <td>related</td>\n",
       "      <td>none</td>\n",
       "      <td>Both tickets involve issues encountered by a S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>INC0010054</td>\n",
       "      <td>INC0010053</td>\n",
       "      <td>Equipment selection not saved for new location...</td>\n",
       "      <td>Merchant unable to submit e-signed agreement\\n...</td>\n",
       "      <td>0.951481</td>\n",
       "      <td>related</td>\n",
       "      <td>none</td>\n",
       "      <td>Ticket A describes an issue with equipment sel...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ticket_a_number ticket_b_number  \\\n",
       "0      INC0010054      INC0010050   \n",
       "1      INC0010054      INC0010048   \n",
       "2      INC0010054      INC0010046   \n",
       "3      INC0010054      INC0010051   \n",
       "4      INC0010054      INC0010053   \n",
       "\n",
       "                                              text_a  \\\n",
       "0  Equipment selection not saved for new location...   \n",
       "1  Equipment selection not saved for new location...   \n",
       "2  Equipment selection not saved for new location...   \n",
       "3  Equipment selection not saved for new location...   \n",
       "4  Equipment selection not saved for new location...   \n",
       "\n",
       "                                              text_b  similarity    label  \\\n",
       "0  Touchscreen malfunction on Merchant's device f...    0.924660  related   \n",
       "1  Access Rights Restriction\\n\\nMerchant reported...    0.926441  related   \n",
       "2  Access Rights Restriction\\n\\nMerchant reported...    0.926441  related   \n",
       "3  Error in Equipment Configuration\\n\\nSales Agen...    0.941556  related   \n",
       "4  Merchant unable to submit e-signed agreement\\n...    0.951481  related   \n",
       "\n",
       "  direction                                        explanation  \n",
       "0      none  Ticket A describes an issue with equipment sel...  \n",
       "1      none  Ticket A describes an issue with equipment sel...  \n",
       "2      none  Ticket A describes an issue with equipment sel...  \n",
       "3      none  Both tickets involve issues encountered by a S...  \n",
       "4      none  Ticket A describes an issue with equipment sel...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import re # Import regex module\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Guard against missing `output_path` (cells may be executed out of order)\n",
    "output_path = globals().get('output_path', None)\n",
    "if output_path is None:\n",
    "    default_dir = 'models/all-mpnet-finetuned'\n",
    "    if 'CONFIG' in globals() and isinstance(CONFIG, dict):\n",
    "        output_path = os.path.join(os.getcwd(), CONFIG.get('output_dir', default_dir))\n",
    "    else:\n",
    "        output_path = os.path.join(os.getcwd(), default_dir)\n",
    "    print(f\"Warning: `output_path` was not defined. Using fallback: {output_path}\")\n",
    "\n",
    "# ----------------------------\n",
    "# Paths\n",
    "# ----------------------------\n",
    "\n",
    "RAW_JSON_PATH = \"/Users/don/Documents/University/Current Classes/Capstone/let me try again/data/servicenow_incidents_full.json\"\n",
    "REL_OUT_CSV   = \"data/relationship_pairs.csv\"\n",
    "REL_OUT_JSON  = \"data/relationship_pairs.json\"\n",
    "\n",
    "MAX_TICKETS = 400       # cap to reduce cost ‚Äî adjust as needed\n",
    "TOP_K_NEIGHBORS = 5     # candidate neighbors per ticket\n",
    "SLEEP_BETWEEN_CALLS = 0.4\n",
    "\n",
    "LLM_MODEL_NAME = \"gpt-4o-mini\"  # or whichever model you use\n",
    "\n",
    "RELATION_PROMPT = \"\"\"\n",
    "You are an expert in IT Service Management (ITSM) and incident management.\n",
    "Your task is to analyze two incident tickets and determine the relationship between them.\n",
    "Based on the short descriptions and descriptions of the two tickets, classify their relationship into one of the following categories:\n",
    "\n",
    "- **duplicate**: Ticket B is a duplicate of Ticket A. They describe the exact same underlying issue, and one ticket could be closed in favor of the other.\n",
    "- **related**: Ticket A and Ticket B describe different but highly relevant issues. They might be part of the same larger problem, affect the same system, or require similar solutions, but neither is a direct duplicate of the other.\n",
    "- **causal**: Ticket B is a direct consequence or cause of Ticket A. For example, Ticket A was created because of an event described in Ticket B, or vice-versa. There is a clear cause-and-effect link.\n",
    "- **none**: There is no significant relationship between Ticket A and Ticket B based on the provided information.\n",
    "\n",
    "If you classify a relationship as 'causal', you must also indicate the 'direction' of the causality:\n",
    "- **A_causes_B**: Ticket A caused Ticket B.\n",
    "- **B_causes_A**: Ticket B caused Ticket A.\n",
    "- **mutually_causal**: A and B are mutually causative or part of a feedback loop.\n",
    "\n",
    "Provide your output as a JSON object with the following keys:\n",
    "- `label`: (string) One of \"duplicate\", \"related\", \"causal\", or \"none\".\n",
    "- `explanation`: (string) A brief, clear explanation for your classification.\n",
    "- `direction`: (string, required only if label is \"causal\") One of \"A_causes_B\", \"B_causes_A\", or \"mutually_causal\". If the label is not \"causal\", set this to \"none\".\n",
    "\n",
    "Here are the two incident tickets:\n",
    "\n",
    "---\n",
    "**Ticket A (ID: {ticket_a_id})**\n",
    "Created On: {ticket_a_created}\n",
    "Affected Application: {ticket_a_app}\n",
    "Short Description: {ticket_a_short}\n",
    "Description: {ticket_a_desc}\n",
    "\n",
    "---\n",
    "**Ticket B (ID: {ticket_b_id})**\n",
    "Created On: {ticket_b_created}\n",
    "Affected Application: {ticket_b_app}\n",
    "Short Description: {ticket_b_short}\n",
    "Description: {ticket_b_desc}\n",
    "\n",
    "---\n",
    "Example Output for 'duplicate':\n",
    "```json\n",
    "{{\n",
    "  \"label\": \"duplicate\",\n",
    "  \"explanation\": \"Both tickets describe the same login issue for the same application on the same day.\"\n",
    "}}\n",
    "```\n",
    "\n",
    "Example Output for 'related':\n",
    "```json\n",
    "{{\n",
    "  \"label\": \"related\",\n",
    "  \"explanation\": \"Ticket A reports a database connection error, and Ticket B reports an application outage. The application likely uses the database, suggesting they are related systems.\"\n",
    "}}\n",
    "```\n",
    "\n",
    "Example Output for 'causal' (A causes B):\n",
    "```json\n",
    "{{\n",
    "  \"label\": \"causal\",\n",
    "  \"explanation\": \"The network outage reported in Ticket A directly led to users being unable to access the application, as reported in Ticket B.\",\n",
    "  \"direction\": \"A_causes_B\"\n",
    "}}\n",
    "```\n",
    "\n",
    "Example Output for 'none':\n",
    "```json\n",
    "{{\n",
    "  \"label\": \"none\",\n",
    "  \"explanation\": \"The incidents describe unrelated issues affecting different systems and users.\"\n",
    "}}\n",
    "\"\"\"\n",
    "\n",
    "# Initialize OpenAI client\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not api_key:\n",
    "    raise RuntimeError(\"OPENAI_API_KEY is not set. Add it to your environment or .env before labeling.\")\n",
    "print(f\"OPENAI_API_KEY detected: {'set' if api_key else 'missing'}\")\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "# ----------------------------\n",
    "# 1. Load raw incidents JSON\n",
    "# ----------------------------\n",
    "\n",
    "print(\"Loading:\", RAW_JSON_PATH)\n",
    "with open(RAW_JSON_PATH, \"r\") as f:\n",
    "    raw_data = json.load(f)\n",
    "\n",
    "df = pd.DataFrame(raw_data)\n",
    "print(\"Loaded\", len(df), \"incidents\")\n",
    "\n",
    "# Trim\n",
    "if len(df) > MAX_TICKETS:\n",
    "    df = df.iloc[:MAX_TICKETS].copy()\n",
    "    print(f\"Trimmed to first {MAX_TICKETS} incidents.\")\n",
    "\n",
    "# Build unified text field\n",
    "df[\"text\"] = (\n",
    "    df[\"short_description\"].fillna(\"\") + \"\\n\\n\" +\n",
    "    df[\"description\"].fillna(\"\")\n",
    ")\n",
    "\n",
    "print(df[[\"incident_number\", \"short_description\"]].head())\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# 2. Encode ticket embeddings\n",
    "# ----------------------------\n",
    "\n",
    "print(\"\\nLoading embedding model from:\", output_path)\n",
    "try:\n",
    "    embedder = SentenceTransformer(output_path)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Fine-tuned model not found at {output_path}. Loading base model: {CONFIG['base_model']}\")\n",
    "    embedder = SentenceTransformer(CONFIG['base_model'])\n",
    "\n",
    "texts = df[\"text\"].astype(str).tolist()\n",
    "print(\"Encoding all incidents...\")\n",
    "emb = embedder.encode(\n",
    "    texts, batch_size=32,\n",
    "    convert_to_numpy=True,\n",
    "    normalize_embeddings=True,\n",
    "    show_progress_bar=True\n",
    ")\n",
    "\n",
    "# ----------------------------\n",
    "# 3. Build similarity matrix\n",
    "# ----------------------------\n",
    "\n",
    "print(\"\\nComputing similarities...\")\n",
    "sim = cosine_similarity(emb)\n",
    "\n",
    "candidate_pairs = []\n",
    "N = len(df)\n",
    "\n",
    "for i in range(N):\n",
    "    sims = sim[i].copy()\n",
    "    sims[i] = -1.0\n",
    "\n",
    "    top_idx = np.argsort(sims)[-TOP_K_NEIGHBORS:]\n",
    "    for j in top_idx:\n",
    "        if j <= i:\n",
    "            continue\n",
    "        candidate_pairs.append((i, j, float(sims[j])))\n",
    "\n",
    "print(\"Candidate pairs:\", len(candidate_pairs))\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# 4. Helper: build prompt\n",
    "# ----------------------------\n",
    "\n",
    "def build_prompt(a, b):\n",
    "    return RELATION_PROMPT.format(\n",
    "        ticket_a_id      = a.get(\"incident_number\", \"\"),\n",
    "        ticket_a_created = a.get(\"sys_created_on\", \"\"),\n",
    "        ticket_a_app      = a.get(\"cmdb_ci\", \"\"),\n",
    "        ticket_a_short   = a.get(\"short_description\", \"\"),\n",
    "        ticket_a_desc    = a.get(\"description\", \"\"),\n",
    "\n",
    "        ticket_b_id       = b.get(\"incident_number\", \"\"),\n",
    "        ticket_b_created = b.get(\"sys_created_on\", \"\"),\n",
    "        ticket_b_app     = b.get(\"cmdb_ci\", \"\"),\n",
    "        ticket_b_short   = b.get(\"short_description\", \"\"),\n",
    "        ticket_b_desc    = b.get(\"description\", \"\")\n",
    "    )\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# 5. LLM call helper\n",
    "# ----------------------------\n",
    "\n",
    "def call_llm(prompt):\n",
    "    try:\n",
    "        r = client.chat.completions.create(\n",
    "            model=LLM_MODEL_NAME,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0.0,\n",
    "        )\n",
    "        raw_text = r.choices[0].message.content.strip()\n",
    "\n",
    "        # Attempt to extract JSON from potentially markdown-formatted response\n",
    "        match = re.search(r\"```json\\s*(\\{.*\\})\\s*```\", raw_text, re.DOTALL)\n",
    "        if match:\n",
    "            json_text = match.group(1)\n",
    "        else:\n",
    "            json_text = raw_text # Assume it's direct JSON if no markdown block\n",
    "\n",
    "        return json.loads(json_text)\n",
    "    except json.JSONDecodeError as e:\n",
    "        # Log the raw response if JSON parsing fails for debugging\n",
    "        print(f\"JSONDecodeError: {e}. Raw LLM response: {raw_text}\")\n",
    "        return {\"label\": \"none\", \"explanation\": f\"JSON parsing failed: {e}. Raw response: {raw_text[:200]}...\", \"direction\": \"none\"}\n",
    "    except Exception as e:\n",
    "        return {\"label\": \"none\", \"explanation\": str(e), \"direction\": \"none\"}\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# 6. Label all pairs with LLM\n",
    "# ----------------------------\n",
    "\n",
    "labeled = []\n",
    "\n",
    "print(\"\\nLabeling\", len(candidate_pairs), \"pairs using LLM‚Ä¶\")\n",
    "for idx, (i, j, sim_val) in enumerate(candidate_pairs, start=1):\n",
    "    a = df.iloc[i].to_dict()\n",
    "    b = df.iloc[j].to_dict()\n",
    "\n",
    "    prompt = build_prompt(a, b)\n",
    "    result = call_llm(prompt)\n",
    "\n",
    "    labeled.append({\n",
    "        \"ticket_a_number\": a[\"incident_number\"],\n",
    "        \"ticket_b_number\": b[\"incident_number\"],\n",
    "        \"text_a\": a[\"text\"],\n",
    "        \"text_b\": b[\"text\"],\n",
    "        \"similarity\": sim_val,\n",
    "        \"label\": result.get(\"label\", \"none\"),\n",
    "        \"direction\": result.get(\"direction\", \"none\"),\n",
    "        \"explanation\": result.get(\"explanation\", \"\")\n",
    "    })\n",
    "\n",
    "    if idx % 5 == 0:\n",
    "        print(f\"  ‚Üí {idx}/{len(candidate_pairs)} pairs labeled\")\n",
    "\n",
    "    time.sleep(SLEEP_BETWEEN_CALLS)\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# 7. Save results\n",
    "# ----------------------------\n",
    "\n",
    "df_rel = pd.DataFrame(labeled)\n",
    "\n",
    "os.makedirs(os.path.dirname(REL_OUT_CSV), exist_ok=True)\n",
    "\n",
    "df_rel.to_csv(REL_OUT_CSV, index=False)\n",
    "with open(REL_OUT_JSON, \"w\") as f:\n",
    "    json.dump(labeled, f, indent=2)\n",
    "\n",
    "print(\"\\nSaved relationship pairs:\")\n",
    "print(\"CSV :\", REL_OUT_CSV)\n",
    "print(\"JSON:\", REL_OUT_JSON)\n",
    "\n",
    "print(\"\\nSample:\")\n",
    "display(df_rel.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49763bb1",
   "metadata": {},
   "source": [
    "# 3.3 Train & Evaluate Relationship Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b1aed54",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "8b3d7b24b087432682b44ae6cef3a3ce",
      "4e6b2e86a5a8444794cc5d9a1d9c5018",
      "199de119dadb44f7be8a7431a1b2e709",
      "42529c8e544b49f798376868fd73572d",
      "c77fca65e3544eb7b5869f736beac15a",
      "4de4b6870e044f04b64470e4c9493fcb",
      "2b3b283caeb1470bb9cc1633a0d05b23",
      "85ba094b1185451d9bebc742adbb5bc6",
      "c197f198c52649159fe566ebad95539b",
      "b8517535cc884703afa13218be917b3f",
      "87b2196551b74795bbd9049298368d3f",
      "0ecc021e7dd74acea508dae1db3ab898",
      "d16fa1eb7ccc4b3888327c86b28a8e4f",
      "13e58dde4ab948e78122de8088b43900",
      "d4d7517accf74f4d88207e13b11b65ec",
      "0be5334754174fc09c62b11e5276ef8a",
      "d2c6b19cc77e4e78828568054179a04d",
      "13b121e738ce448ab0cb9502dff5035f",
      "259df11505db4c71b755e17180d7b13a",
      "a4bea1d0b70e42b9b943e83d97e5f275",
      "3080c85f9fec4fd3ab3aa7c45003b44d",
      "8ecc8622888b457fb4d4381b6e17de1c"
     ]
    },
    "id": "5b1aed54",
    "outputId": "8682358d-f56f-4fbe-b02c-b5393a308641"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading fine-tuned SentenceTransformer model from: /Users/don/Documents/University/Current Classes/Capstone/let me try again/models/all-mpnet-finetuned\n",
      "Loading relationship pairs from: data/relationship_pairs.json\n",
      "Loaded relationship dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticket_a_number</th>\n",
       "      <th>ticket_b_number</th>\n",
       "      <th>text_a</th>\n",
       "      <th>text_b</th>\n",
       "      <th>similarity</th>\n",
       "      <th>label</th>\n",
       "      <th>direction</th>\n",
       "      <th>explanation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INC0010054</td>\n",
       "      <td>INC0010050</td>\n",
       "      <td>Equipment selection not saved for new location...</td>\n",
       "      <td>Touchscreen malfunction on Merchant's device f...</td>\n",
       "      <td>0.924660</td>\n",
       "      <td>related</td>\n",
       "      <td>none</td>\n",
       "      <td>Ticket A describes an issue with equipment sel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>INC0010054</td>\n",
       "      <td>INC0010048</td>\n",
       "      <td>Equipment selection not saved for new location...</td>\n",
       "      <td>Access Rights Restriction\\n\\nMerchant reported...</td>\n",
       "      <td>0.926441</td>\n",
       "      <td>related</td>\n",
       "      <td>none</td>\n",
       "      <td>Ticket A describes an issue with equipment sel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INC0010054</td>\n",
       "      <td>INC0010046</td>\n",
       "      <td>Equipment selection not saved for new location...</td>\n",
       "      <td>Access Rights Restriction\\n\\nMerchant reported...</td>\n",
       "      <td>0.926441</td>\n",
       "      <td>related</td>\n",
       "      <td>none</td>\n",
       "      <td>Ticket A describes an issue with equipment sel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INC0010054</td>\n",
       "      <td>INC0010051</td>\n",
       "      <td>Equipment selection not saved for new location...</td>\n",
       "      <td>Error in Equipment Configuration\\n\\nSales Agen...</td>\n",
       "      <td>0.941556</td>\n",
       "      <td>related</td>\n",
       "      <td>none</td>\n",
       "      <td>Both tickets involve issues encountered by a S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>INC0010054</td>\n",
       "      <td>INC0010053</td>\n",
       "      <td>Equipment selection not saved for new location...</td>\n",
       "      <td>Merchant unable to submit e-signed agreement\\n...</td>\n",
       "      <td>0.951481</td>\n",
       "      <td>related</td>\n",
       "      <td>none</td>\n",
       "      <td>Ticket A describes an issue with equipment sel...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ticket_a_number ticket_b_number  \\\n",
       "0      INC0010054      INC0010050   \n",
       "1      INC0010054      INC0010048   \n",
       "2      INC0010054      INC0010046   \n",
       "3      INC0010054      INC0010051   \n",
       "4      INC0010054      INC0010053   \n",
       "\n",
       "                                              text_a  \\\n",
       "0  Equipment selection not saved for new location...   \n",
       "1  Equipment selection not saved for new location...   \n",
       "2  Equipment selection not saved for new location...   \n",
       "3  Equipment selection not saved for new location...   \n",
       "4  Equipment selection not saved for new location...   \n",
       "\n",
       "                                              text_b  similarity    label  \\\n",
       "0  Touchscreen malfunction on Merchant's device f...    0.924660  related   \n",
       "1  Access Rights Restriction\\n\\nMerchant reported...    0.926441  related   \n",
       "2  Access Rights Restriction\\n\\nMerchant reported...    0.926441  related   \n",
       "3  Error in Equipment Configuration\\n\\nSales Agen...    0.941556  related   \n",
       "4  Merchant unable to submit e-signed agreement\\n...    0.951481  related   \n",
       "\n",
       "  direction                                        explanation  \n",
       "0      none  Ticket A describes an issue with equipment sel...  \n",
       "1      none  Ticket A describes an issue with equipment sel...  \n",
       "2      none  Ticket A describes an issue with equipment sel...  \n",
       "3      none  Both tickets involve issues encountered by a S...  \n",
       "4      none  Ticket A describes an issue with equipment sel...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid dataset size: 191\n",
      "Encoding text_a...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:00<00:00,  7.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding text_b...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:00<00:00,  9.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature matrix: (191, 3072)\n",
      "Training samples: 152\n",
      "Validation samples: 39\n",
      "Training classifier...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Relationship Classifier Report ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   duplicate       0.00      0.00      0.00         0\n",
      "     related       0.25      0.38      0.30         8\n",
      "      causal       0.00      0.00      0.00         0\n",
      "        none       0.81      0.68      0.74        31\n",
      "\n",
      "   micro avg       0.62      0.62      0.62        39\n",
      "   macro avg       0.26      0.26      0.26        39\n",
      "weighted avg       0.69      0.62      0.65        39\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 0  0  0  0]\n",
      " [ 0  3  0  5]\n",
      " [ 0  0  0  0]\n",
      " [ 1  9  0 21]]\n",
      "Saved classifier to: /Users/don/Documents/University/Current Classes/Capstone/let me try again/models/all-mpnet-finetuned/relationship_classifier/relationship_classifier.joblib\n",
      "Saved label mapping to: /Users/don/Documents/University/Current Classes/Capstone/let me try again/models/all-mpnet-finetuned/relationship_classifier/label_mapping.json\n",
      "\n",
      "Example Prediction:\n",
      "Prediction: causal\n",
      "Probabilities: {'duplicate': 0.050332360284642226, 'related': 0.444880954655723, 'causal': 0.5047866850596348}\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# Relationship Classification from relationship_pair.json\n",
    "# ============================================\n",
    "\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import joblib\n",
    "\n",
    "# -------------------------------\n",
    "# 1. Load fine-tuned embedding model\n",
    "# -------------------------------\n",
    "\n",
    "# Guard: ensure `output_path` is defined (not all notebook runs execute previous cells)\n",
    "output_path = globals().get('output_path', None)\n",
    "if output_path is None:\n",
    "    # Try to build from CONFIG if available, otherwise fall back to known default\n",
    "    default_dir = 'models/all-mpnet-finetuned'\n",
    "    if 'CONFIG' in globals() and isinstance(CONFIG, dict):\n",
    "        output_path = os.path.join(os.getcwd(), CONFIG.get('output_dir', default_dir))\n",
    "    else:\n",
    "        output_path = os.path.join(os.getcwd(), default_dir)\n",
    "    print(f\"Warning: `output_path` was not defined. Using fallback: {output_path}\")\n",
    "else:\n",
    "    print(f\"Loading fine-tuned SentenceTransformer model from: {output_path}\")\n",
    "\n",
    "try:\n",
    "    relationship_embedder = SentenceTransformer(output_path)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Fine-tuned model not found at {output_path}. Loading base model: {CONFIG['base_model']}\")\n",
    "    relationship_embedder = SentenceTransformer(CONFIG['base_model'])\n",
    "\n",
    "# -------------------------------\n",
    "# 2. Load relationship_pair.json\n",
    "# -------------------------------\n",
    "\n",
    "json_path = \"data/relationship_pairs.json\"   # TODO: update path if needed\n",
    "\n",
    "print(\"Loading relationship pairs from:\", json_path)\n",
    "\n",
    "with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Expected JSON structure:\n",
    "# [\n",
    "#   {\n",
    "#       \"text_a\": \"...\",\n",
    "#       \"text_b\": \"...\",\n",
    "#       \"label\": \"duplicate\" | \"related\" | \"causal\" | \"none\"\n",
    "#   },\n",
    "#   ...\n",
    "# ]\n",
    "\n",
    "df_pairs = pd.DataFrame(data)\n",
    "\n",
    "print(\"Loaded relationship dataset:\")\n",
    "display(df_pairs.head())\n",
    "\n",
    "# -------------------------------\n",
    "# 3. Clean labels\n",
    "# -------------------------------\n",
    "\n",
    "valid_labels = [\"duplicate\", \"related\", \"causal\", \"none\"]\n",
    "df_pairs = df_pairs[df_pairs[\"label\"].isin(valid_labels)].reset_index(drop=True)\n",
    "\n",
    "texts_a = df_pairs[\"text_a\"].astype(str).tolist()\n",
    "texts_b = df_pairs[\"text_b\"].astype(str).tolist()\n",
    "y_labels = df_pairs[\"label\"].tolist()\n",
    "\n",
    "print(f\"Valid dataset size: {len(df_pairs)}\")\n",
    "\n",
    "# -------------------------------\n",
    "# 4. Encode ticket texts using SentenceTransformer\n",
    "# -------------------------------\n",
    "\n",
    "print(\"Encoding text_a...\")\n",
    "emb_a = relationship_embedder.encode(\n",
    "    texts_a,\n",
    "    batch_size=32,\n",
    "    convert_to_numpy=True,\n",
    "    normalize_embeddings=True,\n",
    "    show_progress_bar=True\n",
    ")\n",
    "\n",
    "print(\"Encoding text_b...\")\n",
    "emb_b = relationship_embedder.encode(\n",
    "    texts_b,\n",
    "    batch_size=32,\n",
    "    convert_to_numpy=True,\n",
    "    normalize_embeddings=True,\n",
    "    show_progress_bar=True\n",
    ")\n",
    "\n",
    "# -------------------------------\n",
    "# 5. Build pairwise features\n",
    "# -------------------------------\n",
    "\n",
    "def build_pair_features(emb_a, emb_b):\n",
    "    diff = np.abs(emb_a - emb_b)\n",
    "    prod = emb_a * emb_b\n",
    "    return np.hstack([emb_a, emb_b, diff, prod])\n",
    "\n",
    "X = build_pair_features(emb_a, emb_b)\n",
    "\n",
    "label2id = {lbl: i for i, lbl in enumerate(valid_labels)}\n",
    "id2label = {i: lbl for lbl, i in label2id.items()}\n",
    "\n",
    "y = np.array([label2id[lbl] for lbl in y_labels])\n",
    "\n",
    "print(\"Feature matrix:\", X.shape)\n",
    "\n",
    "# -------------------------------\n",
    "# 6. Train/validation split\n",
    "# -------------------------------\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"Training samples:\", len(y_train))\n",
    "print(\"Validation samples:\", len(y_val))\n",
    "\n",
    "# -------------------------------\n",
    "# 7. Train classifier (Logistic Regression)\n",
    "# -------------------------------\n",
    "\n",
    "clf = LogisticRegression(\n",
    "    max_iter=200,\n",
    "    multi_class=\"multinomial\",\n",
    "    solver=\"lbfgs\",\n",
    "    n_jobs=-1,\n",
    "    class_weight=\"balanced\"\n",
    ")\n",
    "\n",
    "print(\"Training classifier...\")\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# -------------------------------\n",
    "# 8. Evaluate\n",
    "# -------------------------------\n",
    "\n",
    "y_pred = clf.predict(X_val)\n",
    "\n",
    "labels_order = list(label2id.values())\n",
    "label_names_ordered = [id2label[i] for i in labels_order]\n",
    "\n",
    "print(\"\\n=== Relationship Classifier Report ===\")\n",
    "print(classification_report(\n",
    "    y_val,\n",
    "    y_pred,\n",
    "    labels=labels_order,\n",
    "    target_names=label_names_ordered,\n",
    "    zero_division=0\n",
    "))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_val, y_pred, labels=labels_order))\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# 9. Save model + label mapping\n",
    "# -------------------------------\n",
    "\n",
    "relationship_model_dir = os.path.join(output_path, \"relationship_classifier\")\n",
    "os.makedirs(relationship_model_dir, exist_ok=True)\n",
    "\n",
    "clf_path = os.path.join(relationship_model_dir, \"relationship_classifier.joblib\")\n",
    "label_path = os.path.join(relationship_model_dir, \"label_mapping.json\")\n",
    "\n",
    "joblib.dump(clf, clf_path)\n",
    "\n",
    "with open(label_path, \"w\") as f:\n",
    "    json.dump({\"label2id\": label2id, \"id2label\": id2label}, f, indent=4)\n",
    "\n",
    "print(\"Saved classifier to:\", clf_path)\n",
    "print(\"Saved label mapping to:\", label_path)\n",
    "\n",
    "# -------------------------------\n",
    "# 10. Inference helper\n",
    "# -------------------------------\n",
    "\n",
    "def predict_relationship(text_a, text_b):\n",
    "    \"\"\"\n",
    "    Predict relationship between two ticket texts.\n",
    "    Returns (label, probability_dict)\n",
    "    \"\"\"\n",
    "    embA = relationship_embedder.encode(\n",
    "        [text_a],\n",
    "        convert_to_numpy=True,\n",
    "        normalize_embeddings=True,\n",
    "        show_progress_bar=False\n",
    "    )\n",
    "    embB = relationship_embedder.encode(\n",
    "        [text_b],\n",
    "        convert_to_numpy=True,\n",
    "        normalize_embeddings=True,\n",
    "        show_progress_bar=False\n",
    "    )\n",
    "\n",
    "    feats = build_pair_features(embA, embB)\n",
    "    probs = clf.predict_proba(feats)[0]\n",
    "    pred_id = int(np.argmax(probs))\n",
    "    pred_label = id2label[pred_id]\n",
    "\n",
    "    return pred_label, {id2label[i]: float(p) for i, p in enumerate(probs)}\n",
    "\n",
    "# -------------------------------\n",
    "# 11. Quick test\n",
    "# -------------------------------\n",
    "\n",
    "example_a = \"Unable to log in after SAP server restart.\"\n",
    "example_b = \"SAP authentication error following system reboot.\"\n",
    "\n",
    "pred, proba = predict_relationship(example_a, example_b)\n",
    "\n",
    "print(\"\\nExample Prediction:\")\n",
    "print(\"Prediction:\", pred)\n",
    "print(\"Probabilities:\", proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534728d9",
   "metadata": {
    "id": "534728d9"
   },
   "source": [
    "## 4. Create Training Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4af7e5dc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4af7e5dc",
    "outputId": "83eee53a-a5ac-40df-f326-820d3a582d05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 409 training examples\n",
      "üìä Data Split:\n",
      "  Training: 327 examples\n",
      "  Evaluation: 82 examples\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import json\n",
    "from sentence_transformers import InputExample\n",
    "# Ensure training pairs are available (load from disk if cell 8 was skipped)\n",
    "if \"positive_pairs\" not in globals() or \"negative_pairs\" not in globals():\n",
    "    pairs_path = os.path.join(os.getcwd(), \"data\", \"training_pairs.json\")\n",
    "    if os.path.exists(pairs_path):\n",
    "        with open(pairs_path, \"r\") as f:\n",
    "            loaded = json.load(f)\n",
    "        positive_pairs = loaded.get(\"positive_pairs\", [])\n",
    "        negative_pairs = loaded.get(\"negative_pairs\", [])\n",
    "        print(f\"Loaded pairs from {pairs_path}: {len(positive_pairs)} positive, {len(negative_pairs)} negative\")\n",
    "    else:\n",
    "        raise RuntimeError(\"Training pairs not found. Run the pair-generation cell first or place training_pairs.json under data/.\")\n",
    "\n",
    "# Convert to InputExample objects\n",
    "train_examples = []\n",
    "\n",
    "from sentence_transformers import InputExample\n",
    "\n",
    "# Add positive pairs (label=1.0 for similar)\n",
    "for pair in positive_pairs:\n",
    "    train_examples.append(InputExample(\n",
    "        texts=[pair['text1'], pair['text2']],\n",
    "        label=1.0\n",
    "    ))\n",
    "\n",
    "# Add negative pairs (label=0.0 for dissimilar)\n",
    "for pair in negative_pairs:\n",
    "    train_examples.append(InputExample(\n",
    "        texts=[pair['text1'], pair['text2']],\n",
    "        label=0.0\n",
    "    ))\n",
    "\n",
    "\n",
    "print(f\"Created {len(train_examples)} training examples\")\n",
    "\n",
    "import os\n",
    "if \"train_examples\" not in globals():\n",
    "    raise RuntimeError(\"Run the 'Create Training Examples' cell first so train_examples is defined.\")\n",
    "\n",
    "\n",
    "CONFIG = {\"eval_split\": 0.2}\n",
    "\n",
    "# Split into train/eval\n",
    "import random\n",
    "random.shuffle(train_examples)\n",
    "split_idx = int(len(train_examples) * (1 - CONFIG['eval_split']))\n",
    "eval_examples = train_examples[split_idx:]\n",
    "train_examples = train_examples[:split_idx]\n",
    "\n",
    "print(f\"üìä Data Split:\")\n",
    "print(f\"  Training: {len(train_examples)} examples\")\n",
    "print(f\"  Evaluation: {len(eval_examples)} examples\")\n",
    "if len(eval_examples) < 25:\n",
    "    print(\"‚ö†Ô∏è  Eval set is small; metrics may be noisy. Add more labeled incidents or increase eval_split.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b8aa7b",
   "metadata": {
    "id": "c6b8aa7b"
   },
   "source": [
    "## 5. Load Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9bf8ae49",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9bf8ae49",
    "outputId": "023eda80-0c69-46bc-abb3-c8acbce8b197"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: CONFIG base_model missing; defaulting to sentence-transformers/all-mpnet-base-v2\n",
      "Loading base model: sentence-transformers/all-mpnet-base-v2\n",
      "This may take a minute...\n",
      "\n",
      "‚úÖ Model loaded successfully\n",
      "\n",
      "Model details:\n",
      "  Max sequence length: 384\n",
      "  Embedding dimension: 768\n"
     ]
    }
   ],
   "source": [
    "# Ensure CONFIG has base_model defined\n",
    "if \"CONFIG\" not in globals():\n",
    "    CONFIG = {}\n",
    "if \"base_model\" not in CONFIG:\n",
    "    CONFIG[\"base_model\"] = \"sentence-transformers/all-mpnet-base-v2\"\n",
    "    print(\"Warning: CONFIG base_model missing; defaulting to sentence-transformers/all-mpnet-base-v2\")\n",
    "\n",
    "\n",
    "# Ensure SentenceTransformer is available in this cell's globals (avoid NameError if import cell wasn't run)\n",
    "if 'SentenceTransformer' not in globals():\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "\n",
    "print(f\"Loading base model: {CONFIG['base_model']}\")\n",
    "print(\"This may take a minute...\\n\")\n",
    "\n",
    "model = SentenceTransformer(CONFIG['base_model'])\n",
    "\n",
    "print(\"‚úÖ Model loaded successfully\")\n",
    "print(f\"\\nModel details:\")\n",
    "print(f\"  Max sequence length: {model.max_seq_length}\")\n",
    "print(f\"  Embedding dimension: {model.get_sentence_embedding_dimension()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9c977e",
   "metadata": {
    "id": "5f9c977e"
   },
   "source": [
    "## 6. Setup Training Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b44b15dd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b44b15dd",
    "outputId": "7921d5f6-8a63-4832-e3ec-2494f5f4d56b"
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'batch_size'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DataLoader\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Create DataLoader\u001b[39;00m\n\u001b[32m      5\u001b[39m train_dataloader = DataLoader(\n\u001b[32m      6\u001b[39m     train_examples,\n\u001b[32m      7\u001b[39m     shuffle=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m     batch_size=\u001b[43mCONFIG\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mbatch_size\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m      9\u001b[39m )\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Define loss function (Cosine Similarity Loss for contrastive learning)\u001b[39;00m\n\u001b[32m     12\u001b[39m train_loss = losses.CosineSimilarityLoss(model)\n",
      "\u001b[31mKeyError\u001b[39m: 'batch_size'"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "# Create DataLoader\n",
    "train_dataloader = DataLoader(\n",
    "    train_examples,\n",
    "    shuffle=True,\n",
    "    batch_size=CONFIG['batch_size']\n",
    ")\n",
    "\n",
    "# Define loss function (Cosine Similarity Loss for contrastive learning)\n",
    "train_loss = losses.CosineSimilarityLoss(model)\n",
    "\n",
    "# Create evaluator\n",
    "eval_sentences1 = [ex.texts[0] for ex in eval_examples]\n",
    "eval_sentences2 = [ex.texts[1] for ex in eval_examples]\n",
    "eval_scores = [ex.label for ex in eval_examples]\n",
    "\n",
    "evaluator = EmbeddingSimilarityEvaluator(\n",
    "    eval_sentences1,\n",
    "    eval_sentences2,\n",
    "    eval_scores,\n",
    "    name='itsm-eval'\n",
    ")\n",
    "\n",
    "# Output directory\n",
    "output_path = os.path.join(os.getcwd(), CONFIG['output_dir'])\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "print(\"‚úÖ Training components ready\")\n",
    "print(f\"\\nTotal training batches: {len(train_dataloader)}\")\n",
    "print(f\"Evaluation samples: {len(eval_examples)}\")\n",
    "print(f\"Output path: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62f938b",
   "metadata": {
    "id": "f62f938b"
   },
   "source": [
    "## 7. Train the Model\n",
    "\n",
    "‚ö†Ô∏è **Note**: Training on CPU will take 5-15 minutes per epoch. GPU is recommended for faster training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f865682",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9f865682",
    "outputId": "ef36ce6e-14f1-402a-bb38-076581217c72"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "print(\"Wandb integration disabled.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3803e950",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 330
    },
    "id": "3803e950",
    "outputId": "ceb40bf9-ef23-4350-b50a-59cbe0b6334f"
   },
   "outputs": [],
   "source": [
    "print(\"üöÄ Starting training...\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Epochs: {CONFIG['epochs']}\")\n",
    "print(f\"Batch size: {CONFIG['batch_size']}\")\n",
    "print(f\"Learning rate: {CONFIG['learning_rate']}\")\n",
    "print(f\"Device: {'CUDA' if torch.cuda.is_available() else 'CPU'}\")\n",
    "print(\"=\" * 60)\n",
    "print()\n",
    "\n",
    "# Train\n",
    "model.fit(\n",
    "    train_objectives=[(train_dataloader, train_loss)],\n",
    "    epochs=CONFIG['epochs'],\n",
    "    evaluator=evaluator,\n",
    "    evaluation_steps=len(train_dataloader) // 2,  # Evaluate twice per epoch\n",
    "    warmup_steps=CONFIG['warmup_steps'],\n",
    "    output_path=output_path,\n",
    "    optimizer_params={'lr': CONFIG['learning_rate']},\n",
    "    save_best_model=True,\n",
    "    show_progress_bar=True\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"‚úÖ Training complete!\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f76005",
   "metadata": {
    "id": "a8f76005"
   },
   "source": [
    "## 8. Save Training Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac5f9f9",
   "metadata": {
    "id": "8ac5f9f9"
   },
   "outputs": [],
   "source": [
    "# Save metadata\n",
    "metadata = {\n",
    "    \"base_model\": CONFIG['base_model'],\n",
    "    \"training_date\": datetime.now().isoformat(),\n",
    "    \"epochs\": CONFIG['epochs'],\n",
    "    \"batch_size\": CONFIG['batch_size'],\n",
    "    \"learning_rate\": CONFIG['learning_rate'],\n",
    "    \"num_train_examples\": len(train_examples),\n",
    "    \"num_eval_examples\": len(eval_examples),\n",
    "    \"num_positive_pairs\": len(positive_pairs),\n",
    "    \"num_negative_pairs\": len(negative_pairs),\n",
    "    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "}\n",
    "\n",
    "metadata_path = os.path.join(output_path, 'training_metadata.json')\n",
    "with open(metadata_path, 'w') as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "\n",
    "print(f\"üíæ Model saved to: {output_path}\")\n",
    "print(f\"üìù Metadata saved to: {metadata_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d356be64",
   "metadata": {
    "id": "d356be64"
   },
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 8. Relationship Classification (Duplicate / Related / Causal / None)\n",
    "# ============================================\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import joblib\n",
    "\n",
    "# --------------------------------------------\n",
    "# 8.1 Load fine-tuned embedding model\n",
    "# --------------------------------------------\n",
    "\n",
    "# If not already loaded earlier in the notebook:\n",
    "# Guard against missing `output_path` (cells may be executed out of order)\n",
    "output_path = globals().get('output_path', None)\n",
    "if output_path is None:\n",
    "    default_dir = 'models/all-mpnet-finetuned'\n",
    "    if 'CONFIG' in globals() and isinstance(CONFIG, dict):\n",
    "        output_path = os.path.join(os.getcwd(), CONFIG.get('output_dir', default_dir))\n",
    "    else:\n",
    "        output_path = os.path.join(os.getcwd(), default_dir)\n",
    "    print(f\"Warning: `output_path` was not defined. Using fallback: {output_path}\")\n",
    "else:\n",
    "    print(f\"Loading fine-tuned SentenceTransformer model from: {output_path}\")\n",
    "relationship_embedder = SentenceTransformer(output_path)\n",
    "\n",
    "# --------------------------------------------\n",
    "# 8.2 Load labelled ticket-pair dataset\n",
    "# --------------------------------------------\n",
    "\n",
    "# EXPECTED COLUMNS in the CSV:\n",
    "#   text_a : string - ticket A text (e.g., short_description + description)\n",
    "#   text_b : string - ticket B text\n",
    "#   label  : string - one of {\"duplicate\", \"related\", \"causal\", \"none\"}\n",
    "pairs_csv_path = \"data/relationship_pairs.csv\"  # TODO: adjust path\n",
    "\n",
    "print(\"Loading relationship training data from:\", pairs_csv_path)\n",
    "df_pairs = pd.read_csv(pairs_csv_path)\n",
    "\n",
    "# Basic sanity check\n",
    "print(\"Sample of relationship dataset:\")\n",
    "display(df_pairs.head())\n",
    "\n",
    "# Filter to supported labels (in case there is noise)\n",
    "valid_labels = [\"duplicate\", \"related\", \"causal\", \"none\"]\n",
    "df_pairs = df_pairs[df_pairs[\"label\"].isin(valid_labels)].reset_index(drop=True)\n",
    "\n",
    "# --------------------------------------------\n",
    "# 8.3 Encode ticket texts into embeddings\n",
    "# --------------------------------------------\n",
    "\n",
    "texts_a = df_pairs[\"text_a\"].astype(str).tolist()\n",
    "texts_b = df_pairs[\"text_b\"].astype(str).tolist()\n",
    "y_labels = df_pairs[\"label\"].tolist()\n",
    "\n",
    "print(\"Encoding ticket pairs with fine-tuned model...\")\n",
    "emb_a = relationship_embedder.encode(\n",
    "    texts_a,\n",
    "    batch_size=32,\n",
    "    show_progress_bar=True,\n",
    "    convert_to_numpy=True,\n",
    "    normalize_embeddings=True,\n",
    ")\n",
    "\n",
    "emb_b = relationship_embedder.encode(\n",
    "    texts_b,\n",
    "    batch_size=32,\n",
    "    show_progress_bar=True,\n",
    "    convert_to_numpy=True,\n",
    "    normalize_embeddings=True,\n",
    ")\n",
    "\n",
    "# --------------------------------------------\n",
    "# 8.4 Build pairwise feature vectors\n",
    "# --------------------------------------------\n",
    "# Common trick: combine embeddings using multiple operations:\n",
    "#   - [emb_a, emb_b, |emb_a - emb_b|, emb_a * emb_b]\n",
    "# You can tune this later if needed.\n",
    "\n",
    "def build_pair_features(emb_a: np.ndarray, emb_b: np.ndarray) -> np.ndarray:\n",
    "    diff = np.abs(emb_a - emb_b)\n",
    "    prod = emb_a * emb_b\n",
    "    return np.hstack([emb_a, emb_b, diff, prod])\n",
    "\n",
    "X = build_pair_features(emb_a, emb_b)\n",
    "\n",
    "# Map string labels to integers\n",
    "label2id = {label: idx for idx, label in enumerate(valid_labels)}\n",
    "id2label = {idx: label for label, idx in label2id.items()}\n",
    "y = np.array([label2id[label] for label in y_labels])\n",
    "\n",
    "print(\"Feature matrix shape:\", X.shape)\n",
    "print(\"Number of samples:\", len(y))\n",
    "\n",
    "# --------------------------------------------\n",
    "# 8.5 Train / validation split\n",
    "# --------------------------------------------\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"Train size:\", X_train.shape[0])\n",
    "print(\"Validation size:\", X_val.shape[0])\n",
    "\n",
    "# --------------------------------------------\n",
    "# 8.6 Train a simple classifier (Logistic Regression)\n",
    "# --------------------------------------------\n",
    "\n",
    "# You can swap this for RandomForest, XGBoost, or MLPClassifier later if desired.\n",
    "clf = LogisticRegression(\n",
    "    max_iter=200,\n",
    "    multi_class=\"multinomial\",\n",
    "    solver=\"lbfgs\",\n",
    "    n_jobs=-1,\n",
    "    class_weight=\"balanced\"\n",
    ")\n",
    "\n",
    "print(\"Training relationship classifier...\")\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# --------------------------------------------\n",
    "# 8.7 Evaluation\n",
    "# --------------------------------------------\n",
    "\n",
    "y_pred = clf.predict(X_val)\n",
    "\n",
    "labels_order = list(label2id.values())\n",
    "label_names_ordered = [id2label[i] for i in labels_order]\n",
    "\n",
    "print(\"\\nClassification report (validation set):\")\n",
    "print(classification_report(\n",
    "    y_val,\n",
    "    y_pred,\n",
    "    labels=labels_order,\n",
    "    target_names=label_names_ordered,\n",
    "    zero_division=0\n",
    "))\n",
    "\n",
    "print(\"Confusion matrix:\")\n",
    "print(confusion_matrix(y_val, y_pred, labels=labels_order))\n",
    "\n",
    "\n",
    "# --------------------------------------------\n",
    "# 8.8 Save classifier + label mapping\n",
    "# --------------------------------------------\n",
    "\n",
    "relationship_model_dir = os.path.join(output_path, \"relationship_classifier\")\n",
    "os.makedirs(relationship_model_dir, exist_ok=True)\n",
    "\n",
    "clf_path = os.path.join(relationship_model_dir, \"relationship_classifier.joblib\")\n",
    "labels_path = os.path.join(relationship_model_dir, \"label_mapping.json\")\n",
    "\n",
    "joblib.dump(clf, clf_path)\n",
    "\n",
    "import json\n",
    "with open(labels_path, \"w\") as f:\n",
    "    json.dump({\"label2id\": label2id, \"id2label\": id2label}, f)\n",
    "\n",
    "print(\"Saved relationship classifier to:\", clf_path)\n",
    "print(\"Saved label mapping to:\", labels_path)\n",
    "\n",
    "# --------------------------------------------\n",
    "# 8.9 Inference helper: predict relationship for a single pair\n",
    "# --------------------------------------------\n",
    "\n",
    "def predict_relationship(ticket_a_text: str, ticket_b_text: str):\n",
    "    \"\"\"\n",
    "    Predict relationship type between two ticket texts.\n",
    "    Returns (label, probs_dict).\n",
    "    \"\"\"\n",
    "    # Encode\n",
    "    emb_a = relationship_embedder.encode(\n",
    "        [ticket_a_text],\n",
    "        convert_to_numpy=True,\n",
    "        normalize_embeddings=True,\n",
    "        show_progress_bar=False,\n",
    "    )\n",
    "    emb_b = relationship_embedder.encode(\n",
    "        [ticket_b_text],\n",
    "        convert_to_numpy=True,\n",
    "        normalize_embeddings=True,\n",
    "        show_progress_bar=False,\n",
    "    )\n",
    "    # Build features\n",
    "    feats = build_pair_features(emb_a, emb_b)\n",
    "    # Predict proba\n",
    "    probs = clf.predict_proba(feats)[0]\n",
    "    pred_id = int(np.argmax(probs))\n",
    "    pred_label = id2label[pred_id]\n",
    "    probs_dict = {id2label[i]: float(p) for i, p in enumerate(probs)}\n",
    "    return pred_label, probs_dict\n",
    "\n",
    "# Quick smoke test (replace with real ticket texts)\n",
    "example_a = \"User cannot log into SAP after the weekend maintenance.\"\n",
    "example_b = \"SAP login fails with authentication error since Sunday night.\"\n",
    "\n",
    "pred_label, probs = predict_relationship(example_a, example_b)\n",
    "print(\"\\nExample prediction:\")\n",
    "print(\"Ticket A:\", example_a)\n",
    "print(\"Ticket B:\", example_b)\n",
    "print(\"Predicted relationship:\", pred_label)\n",
    "print(\"Class probabilities:\", probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cadcd14",
   "metadata": {
    "id": "4cadcd14"
   },
   "source": [
    "## 9. Quick Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c608f7b",
   "metadata": {
    "id": "6c608f7b"
   },
   "outputs": [],
   "source": [
    "# Load the fine-tuned model\n",
    "finetuned_model = SentenceTransformer(output_path)\n",
    "\n",
    "# Test with example tickets\n",
    "if positive_pairs:\n",
    "    test_pair = positive_pairs[0]\n",
    "\n",
    "    # Generate embeddings\n",
    "    emb1 = finetuned_model.encode(test_pair['text1'])\n",
    "    emb2 = finetuned_model.encode(test_pair['text2'])\n",
    "\n",
    "    # Calculate similarity\n",
    "    from sklearn.metrics.pairwise import cosine_similarity\n",
    "    similarity = cosine_similarity([emb1], [emb2])[0][0]\n",
    "\n",
    "    print(\"\\nüìä Quick Test:\")\n",
    "    print(f\"Category: {test_pair['category1']}\")\n",
    "    print(f\"Ticket 1: {test_pair['ticket1_id']}\")\n",
    "    print(f\"Ticket 2: {test_pair['ticket2_id']}\")\n",
    "    print(f\"\\nSimilarity Score: {similarity:.4f}\")\n",
    "    print(f\"Expected: High (same category)\")\n",
    "\n",
    "    if similarity > 0.7:\n",
    "        print(\"‚úÖ Good! Model correctly identifies similar tickets\")\n",
    "    elif similarity > 0.5:\n",
    "        print(\"‚ö†Ô∏è  Moderate similarity - model needs more training\")\n",
    "    else:\n",
    "        print(\"‚ùå Low similarity - model may need different approach\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bad7f36",
   "metadata": {
    "id": "4bad7f36"
   },
   "source": [
    "## 10. Next Steps\n",
    "\n",
    "Now that you have fine-tuned the all-mpnet-base-v2 model, you can:\n",
    "\n",
    "1. **Use the model locally**:\n",
    "   ```python\n",
    "   from sentence_transformers import SentenceTransformer\n",
    "   model = SentenceTransformer('scripts/finetuning/models/all-mpnet-finetuned')\n",
    "   embeddings = model.encode([\"ticket text here\"])\n",
    "   ```\n",
    "\n",
    "2. **Update your embedding service** (`app/services/embedding_service.py`) to use this fine-tuned model instead of LM Studio\n",
    "\n",
    "3. **Run full evaluation** to compare fine-tuned model with LM Studio models:\n",
    "   ```bash\n",
    "   python scripts/performance_eval/compare_models.py\n",
    "   ```\n",
    "\n",
    "4. **Regenerate embeddings** for all tickets using the fine-tuned model:\n",
    "   ```bash\n",
    "   python scripts/populate_embeddings.py\n",
    "   ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8531fb20",
   "metadata": {
    "id": "8531fb20"
   },
   "source": [
    "## 11. Load and Test Fine-tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d612db6",
   "metadata": {
    "id": "0d612db6"
   },
   "outputs": [],
   "source": [
    "# You can reload the model anytime with:\n",
    "print(\"Loading fine-tuned model...\")\n",
    "finetuned = SentenceTransformer(output_path)\n",
    "print(f\"‚úÖ Fine-tuned model loaded from: {output_path}\")\n",
    "print(f\"Embedding dimension: {finetuned.get_sentence_embedding_dimension()}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "itsm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0be5334754174fc09c62b11e5276ef8a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0de5202e75df4fafa0abf487e3df4907": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0ecc021e7dd74acea508dae1db3ab898": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d16fa1eb7ccc4b3888327c86b28a8e4f",
       "IPY_MODEL_13e58dde4ab948e78122de8088b43900",
       "IPY_MODEL_d4d7517accf74f4d88207e13b11b65ec"
      ],
      "layout": "IPY_MODEL_0be5334754174fc09c62b11e5276ef8a"
     }
    },
    "13b121e738ce448ab0cb9502dff5035f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "13e58dde4ab948e78122de8088b43900": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_259df11505db4c71b755e17180d7b13a",
      "max": 6,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a4bea1d0b70e42b9b943e83d97e5f275",
      "value": 6
     }
    },
    "199de119dadb44f7be8a7431a1b2e709": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_85ba094b1185451d9bebc742adbb5bc6",
      "max": 6,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c197f198c52649159fe566ebad95539b",
      "value": 6
     }
    },
    "19b1bc33795a4a1e8ae597fd670292ae": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d7cf42dcbeed4008ac0bbef80f29d114",
      "max": 3,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ce73740c718640f69fbc5ab01c26b6eb",
      "value": 3
     }
    },
    "2312932583a945d8a29cdc2cc046f8a6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "259df11505db4c71b755e17180d7b13a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2977bc6f50cb4a55915a5c0d347f3891": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2b3b283caeb1470bb9cc1633a0d05b23": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3080c85f9fec4fd3ab3aa7c45003b44d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3c9b771af6484c15a99b486946e4defb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "42529c8e544b49f798376868fd73572d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b8517535cc884703afa13218be917b3f",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_87b2196551b74795bbd9049298368d3f",
      "value": "‚Äá6/6‚Äá[00:27&lt;00:00,‚Äá‚Äá2.89s/it]"
     }
    },
    "4de4b6870e044f04b64470e4c9493fcb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4e6b2e86a5a8444794cc5d9a1d9c5018": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4de4b6870e044f04b64470e4c9493fcb",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_2b3b283caeb1470bb9cc1633a0d05b23",
      "value": "Batches:‚Äá100%"
     }
    },
    "794cded4974f4d0aa6c7508dbf21a2c9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2312932583a945d8a29cdc2cc046f8a6",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_0de5202e75df4fafa0abf487e3df4907",
      "value": "Batches:‚Äá100%"
     }
    },
    "8586a1871c0c40c2b1da318574caac32": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3c9b771af6484c15a99b486946e4defb",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_2977bc6f50cb4a55915a5c0d347f3891",
      "value": "‚Äá3/3‚Äá[00:33&lt;00:00,‚Äá‚Äá9.36s/it]"
     }
    },
    "85ba094b1185451d9bebc742adbb5bc6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "87b2196551b74795bbd9049298368d3f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8b3d7b24b087432682b44ae6cef3a3ce": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4e6b2e86a5a8444794cc5d9a1d9c5018",
       "IPY_MODEL_199de119dadb44f7be8a7431a1b2e709",
       "IPY_MODEL_42529c8e544b49f798376868fd73572d"
      ],
      "layout": "IPY_MODEL_c77fca65e3544eb7b5869f736beac15a"
     }
    },
    "8ecc8622888b457fb4d4381b6e17de1c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a4bea1d0b70e42b9b943e83d97e5f275": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b8517535cc884703afa13218be917b3f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c197f198c52649159fe566ebad95539b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c77fca65e3544eb7b5869f736beac15a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ce73740c718640f69fbc5ab01c26b6eb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d16fa1eb7ccc4b3888327c86b28a8e4f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d2c6b19cc77e4e78828568054179a04d",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_13b121e738ce448ab0cb9502dff5035f",
      "value": "Batches:‚Äá100%"
     }
    },
    "d2c6b19cc77e4e78828568054179a04d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d4d7517accf74f4d88207e13b11b65ec": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3080c85f9fec4fd3ab3aa7c45003b44d",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_8ecc8622888b457fb4d4381b6e17de1c",
      "value": "‚Äá6/6‚Äá[00:24&lt;00:00,‚Äá‚Äá2.67s/it]"
     }
    },
    "d7cf42dcbeed4008ac0bbef80f29d114": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e40feb21ae2c4871b9875dc156391a5d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ea3e52cd528849f8bebc78c404347b8d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_794cded4974f4d0aa6c7508dbf21a2c9",
       "IPY_MODEL_19b1bc33795a4a1e8ae597fd670292ae",
       "IPY_MODEL_8586a1871c0c40c2b1da318574caac32"
      ],
      "layout": "IPY_MODEL_e40feb21ae2c4871b9875dc156391a5d"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
