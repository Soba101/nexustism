{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ITSM Ticket Similarity - Model Fine-tuning (v6 Refactored)\n",
    "\n",
    "**Version 6 Refactored** improves upon the original v6 by:\n",
    "1. **Robust Environment Setup:** Automatically handles NLTK data and library dependencies (Kaggle/Local).\n",
    "2. **Improved Pipeline:** Cleaner data loading and preprocessing.\n",
    "3. **Contextual Embeddings:** Retains the structured input format `[Service] [Category] Description`.\n",
    "4. **Reliable Logging:** Auto-detects the best location for logs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_127/3089992347.py:1: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n",
      "  import os, sys, subprocess, pkg_resources\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚¨áÔ∏è Downloading NLTK: wordnet\n",
      "‚¨áÔ∏è Downloading NLTK: omw-1.4\n"
     ]
    }
   ],
   "source": [
    "import os, sys, subprocess, pkg_resources\n",
    "from pathlib import Path\n",
    "\n",
    "def ensure_packages(pkgs):\n",
    "    missing = []\n",
    "    for name, spec in pkgs.items():\n",
    "        try:\n",
    "            pkg_resources.get_distribution(name)\n",
    "        except pkg_resources.DistributionNotFound:\n",
    "            missing.append(spec)\n",
    "    if missing:\n",
    "        print(\"üì¶ Installing:\", \", \".join(missing))\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"--quiet\", *missing])\n",
    "\n",
    "def ensure_nltk(resources=(\"wordnet\",\"omw-1.4\",\"stopwords\",\"punkt\")):\n",
    "    import nltk\n",
    "    nltk_data = Path.home() / \"nltk_data\"\n",
    "    nltk_data.mkdir(exist_ok=True)\n",
    "    if str(nltk_data) not in nltk.data.path:\n",
    "        nltk.data.path.append(str(nltk_data))\n",
    "    for res in resources:\n",
    "        try:\n",
    "            nltk.data.find(f\"corpora/{res}\")\n",
    "        except LookupError:\n",
    "            try:\n",
    "                nltk.data.find(f\"tokenizers/{res}\")\n",
    "            except LookupError:\n",
    "                print(f\"‚¨áÔ∏è Downloading NLTK: {res}\")\n",
    "                nltk.download(res, quiet=True, download_dir=str(nltk_data))\n",
    "\n",
    "def run_setup():\n",
    "    os.environ[\"TF_ENABLE_ONEDNN_OPTS\"] = \"0\"\n",
    "    os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "\n",
    "    pkgs = {\n",
    "        \"sentence-transformers\": \"sentence-transformers\",\n",
    "        \"transformers\": \"transformers\",\n",
    "        \"torch\": \"torch\",               # use Kaggle‚Äôs unless missing\n",
    "        \"torchvision\": \"torchvision\",\n",
    "        \"torchaudio\": \"torchaudio\",\n",
    "        \"scikit-learn\": \"scikit-learn\",\n",
    "        \"scipy\": \"scipy\",\n",
    "        \"numpy\": \"numpy\",\n",
    "        \"pandas\": \"pandas\",\n",
    "        \"tqdm\": \"tqdm\",\n",
    "        \"imbalanced-learn\": \"imbalanced-learn\",\n",
    "        \"datasets\": \"datasets\",\n",
    "        \"joblib\": \"joblib\",\n",
    "        \"protobuf\": \"protobuf<=3.20.1\",\n",
    "        \"requests\": \"requests\",\n",
    "        \"python-dotenv\": \"python-dotenv\",\n",
    "        \"openai\": \"openai\",\n",
    "        \"seaborn\": \"seaborn\",\n",
    "        \"matplotlib\": \"matplotlib\",\n",
    "        \"pytorch-lightning\": \"pytorch-lightning\",\n",
    "    }\n",
    "    ensure_packages(pkgs)\n",
    "    ensure_nltk()\n",
    "\n",
    "run_setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚öôÔ∏è Checking environment...\n",
      "üì¶ Installing missing packages: imbalanced-learn...\n",
      "üìö Checking NLTK data...\n",
      "‚¨áÔ∏è Downloading NLTK resource: wordnet...\n",
      "‚¨áÔ∏è Downloading NLTK resource: omw-1.4...\n",
      "‚úÖ All NLTK Data Check Complete.\n"
     ]
    }
   ],
   "source": [
    "# [SETUP] Run this cell FIRST to ensure environment stability.\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "import pkg_resources\n",
    "from pathlib import Path\n",
    "\n",
    "def run_setup():\n",
    "    print(\"‚öôÔ∏è Checking environment...\")\n",
    "    \n",
    "    # 1. Fix Protobuf/TensorFlow conflict (common in Kaggle)\n",
    "    os.environ[\"TF_ENABLE_ONEDNN_OPTS\"] = \"0\"\n",
    "    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "    \n",
    "    # 2. Install critical missing packages\n",
    "    required_packages = {\n",
    "        'sentence-transformers': 'sentence-transformers', \n",
    "        'imblearn': 'imbalanced-learn',\n",
    "        'protobuf': 'protobuf<=3.20.1', # Specific version for compatibility\n",
    "        'scipy': 'scipy' # Added as it's a core dependency for many things\n",
    "    }\n",
    "    \n",
    "    # Helper to check if a package is installed\n",
    "    def is_installed(package_name):\n",
    "        try:\n",
    "            pkg_resources.get_distribution(package_name)\n",
    "            return True\n",
    "        except pkg_resources.DistributionNotFound:\n",
    "            return False\n",
    "\n",
    "    to_install = []\n",
    "    for key, install_name in required_packages.items():\n",
    "        if not is_installed(key): # Check if the base package name is installed\n",
    "            to_install.append(install_name)\n",
    "            \n",
    "    if to_install:\n",
    "        print(f\"üì¶ Installing missing packages: {', '.join(to_install)}...\")\n",
    "        try:\n",
    "            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\"] + to_install + [\"--quiet\"])\n",
    "            # Re-initialize pkg_resources to reflect new installs\n",
    "            import importlib\n",
    "            importlib.reload(pkg_resources)\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"‚ùå Failed to install packages: {e}\")\n",
    "            print(\"Please try installing manually or check network connection.\")\n",
    "            sys.exit(1)\n",
    "    else:\n",
    "        print(\"‚úÖ All required Python packages are installed.\")\n",
    "        \n",
    "    # 3. Download NLTK Data\n",
    "    print(\"üìö Checking NLTK data...\")\n",
    "    import nltk\n",
    "    # Ensure NLTK data directory exists and is discoverable\n",
    "    nltk_data_path = Path.home() / 'nltk_data'\n",
    "    if not nltk_data_path.exists():\n",
    "        nltk_data_path.mkdir(parents=True, exist_ok=True)\n",
    "    if str(nltk_data_path) not in nltk.data.path:\n",
    "        nltk.data.path.append(str(nltk_data_path))\n",
    "        \n",
    "    resources = ['wordnet', 'omw-1.4', 'stopwords', 'punkt'] # omw-1.4 for wordnet, punkt for tokenizers\n",
    "    downloaded_all_nltk = True\n",
    "    for res in resources:\n",
    "        try:\n",
    "            nltk.data.find(f\"corpora/{res}\") # Check for corporas\n",
    "        except LookupError:\n",
    "            try:\n",
    "                nltk.data.find(f\"tokenizers/{res}\") # Check for tokenizers\n",
    "            except LookupError:\n",
    "                print(f\"‚¨áÔ∏è Downloading NLTK resource: {res}...\")\n",
    "                try:\n",
    "                    nltk.download(res, quiet=True, download_dir=str(nltk_data_path)) # Download to user's home dir\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ùå Failed to download NLTK resource '{res}': {e}\")\n",
    "                    downloaded_all_nltk = False\n",
    "                 \n",
    "    if downloaded_all_nltk:\n",
    "        print(\"‚úÖ All NLTK Data Check Complete.\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Some NLTK data could not be downloaded. This might affect text processing.\")\n",
    "\n",
    "run_setup()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1764528396.894900     127 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1764528396.901188     127 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-30 18:46:41,951 - INFO - üìù Logging to: /kaggle/working/training_v6_refactored.log\n"
     ]
    }
   ],
   "source": [
    "# Core Python\n",
    "import os\n",
    "import random\n",
    "import logging\n",
    "import re\n",
    "import json\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "\n",
    "# Data Handling\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Progress Bar\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# ML Frameworks\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# NLP & Metrics\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, ENGLISH_STOP_WORDS\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "from imblearn.over_sampling import SMOTE # Ensure SMOTE is imported for classifier\n",
    "\n",
    "# Sentence Transformers\n",
    "from sentence_transformers import SentenceTransformer, InputExample, losses, models\n",
    "from sentence_transformers.evaluation import SentenceEvaluator\n",
    "\n",
    "# Filter warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\" # Suppress tokenizers warning\n",
    "\n",
    "# --- Logging Setup ---\n",
    "def setup_logger():\n",
    "    # Determine log path: Prefer local current dir, allow agent override\n",
    "    log_filename = \"training_v6_refactored.log\"\n",
    "    log_path = Path.cwd() / log_filename\n",
    "    \n",
    "    # If running in Agent env, use agent's temp dir\n",
    "    if os.environ.get(\"GEMINI_TEMP_DIR\"):\n",
    "        log_path = Path(os.environ.get(\"GEMINI_TEMP_DIR\")) / log_filename\n",
    "\n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO,\n",
    "        format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "        handlers=[\n",
    "            logging.FileHandler(log_path, mode='w'), # Overwrite for fresh run\n",
    "            logging.StreamHandler()\n",
    "        ],\n",
    "        force=True\n",
    "    )\n",
    "    return logging.getLogger(__name__), log_path\n",
    "\n",
    "logger, LOG_FILE = setup_logger()\n",
    "\n",
    "def log(msg, level=logging.INFO):\n",
    "    if level == logging.INFO:\n",
    "        logger.info(msg)\n",
    "    elif level == logging.WARNING:\n",
    "        logger.warning(msg)\n",
    "    else:\n",
    "        logger.debug(msg)\n",
    "\n",
    "log(f\"üìù Logging to: {LOG_FILE}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-30 18:46:42,028 - INFO - üöÄ CUDA Detected: Tesla P100-PCIE-16GB\n"
     ]
    }
   ],
   "source": [
    "# --- CONFIGURATION ---\n",
    "CONFIG = {\n",
    "    'model_name': 'sentence-transformers/all-mpnet-base-v2',\n",
    "    'output_dir': 'models/v6_refactored_finetuned', # New output directory\n",
    "    'source_data': 'data/dummy_data_promax.csv', # Will try to resolve this\n",
    "    'relationship_data': 'data/relationship_pairs.json', # For relationship classifier\n",
    "    \n",
    "    # Hyperparameters\n",
    "    'epochs': 15,\n",
    "    'batch_size': 32, # Lower batch size for stability\n",
    "    'lr': 2e-5,\n",
    "    'max_seq_length': 384,\n",
    "    \n",
    "    # Data Strategy\n",
    "    'num_pairs': 50000, # Number of pairs for training/validation\n",
    "    'pos_ratio': 0.4,   # 40% Positive, 60% Negative\n",
    "    'neg_mining_range': (0.2, 0.5), # TF-IDF score range for \"Hard Negatives\"\n",
    "    'eval_split': 0.15, # % of data for validation\n",
    "    \n",
    "    # Seed\n",
    "    'seed': 42\n",
    "}\n",
    "\n",
    "# Set Seeds\n",
    "random.seed(CONFIG['seed'])\n",
    "np.random.seed(CONFIG['seed'])\n",
    "torch.manual_seed(CONFIG['seed'])\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(CONFIG['seed'])\n",
    "    log(f\"üöÄ CUDA Detected: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    log(\"‚ö†Ô∏è CUDA Not Detected. Running on CPU.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-30 18:46:42,113 - INFO - üìÇ Loading incident data from: /kaggle/input/itsm-dataset/dummy_data_promax.csv\n",
      "2025-11-30 18:46:42,791 - INFO - ‚úÖ Preprocessed 10000 incidents.\n",
      "2025-11-30 18:46:42,792 - INFO - Sample preprocessed text: '[crm (d365, salesforce, genesis, pcube, hussmann services) | bc - basis] [configuration | program bug] Group: piscap l2 workflow. Request: Adjust Configuration/Program bug configuration in CRM (D365, SalesForce, Genesis, PCube, HussMann Services). I encountered an issue where Request: Adjust Configuration/Program bug configuration in CRM (D365, SalesForce, Genesis, PCube, HussMann Services). I'd like assistance to investigate and resolve it.'\n",
      "2025-11-30 18:46:42,796 - INFO - ‚úÖ Index reset. Range: 0 to 9999\n"
     ]
    }
   ],
   "source": [
    "def resolve_data_path(path_str):\n",
    "    \"\"\"Smart path resolver for Local/Kaggle/Colab/Agent envs.\"\"\"\n",
    "    # 1. As-is\n",
    "    p = Path(path_str)\n",
    "    if p.exists(): return p.resolve()\n",
    "    \n",
    "    # 2. Relative to current script location (for agent or local execution)\n",
    "    # Using Path.cwd() as a robust base for notebooks\n",
    "    script_dir = Path.cwd() \n",
    "    if (script_dir / path_str).exists(): return (script_dir / path_str).resolve()\n",
    "\n",
    "    # 3. Common Kaggle/Colab input paths\n",
    "    # Assuming path_str might be like 'data/file.csv'\n",
    "    base_filename = Path(path_str).name\n",
    "    \n",
    "    kaggle_input_dir = Path(\"/kaggle/input\")\n",
    "    if kaggle_input_dir.exists():\n",
    "        for dataset_dir in kaggle_input_dir.iterdir():\n",
    "            if (dataset_dir / base_filename).exists():\n",
    "                return (dataset_dir / base_filename).resolve()\n",
    "            if (dataset_dir / path_str).exists(): # if path_str includes subdir like 'data/'\n",
    "                return (dataset_dir / path_str).resolve()\n",
    "                \n",
    "    colab_dir = Path(\"/content\")\n",
    "    if (colab_dir / path_str).exists(): return (colab_dir / path_str).resolve()\n",
    "\n",
    "    raise FileNotFoundError(f\"Could not find {path_str} in any common locations (cwd, relative, Kaggle, Colab).\")\n",
    "\n",
    "def load_and_preprocess_data(config):\n",
    "    source_path = resolve_data_path(config['source_data'])\n",
    "    log(f\"üìÇ Loading incident data from: {source_path}\")\n",
    "    df = pd.read_csv(source_path)\n",
    "    \n",
    "    # Required columns for contextual embedding\n",
    "    required_cols = [\"Number\", \"Short Description\", \"Description\", \"Category\", \"Subcategory\", \n",
    "                     \"Service\", \"Service offering\", \"Assignment group\"]\n",
    "    for col in required_cols:\n",
    "        if col not in df.columns:\n",
    "            raise ValueError(f\"Missing required column: {col}\")\n",
    "\n",
    "    # Fill NA and Clean Text\n",
    "    # We ensure all context fields are strings\n",
    "    placeholders = {\"\", \"nan\", \"none\", \"null\", \"unknown\", \"n/a\", \"na\"}\n",
    "\n",
    "    def normalize_field(val: str) -> str:\n",
    "        s = str(val).strip()\n",
    "        s = re.sub(r\"\\s+\", \" \", s) # Replace multiple spaces with single\n",
    "        if s.lower() in placeholders:\n",
    "            return \"\"\n",
    "        return s\n",
    "\n",
    "    for col in [c for c in required_cols if c != \"Number\"]:\n",
    "        df[col] = df[col].fillna(\"\").apply(normalize_field)\n",
    "\n",
    "    # Normalize casing for structured context fields to reduce duplicates\n",
    "    context_cols = [\"Service\", \"Service offering\", \"Category\", \"Subcategory\", \"Assignment group\"]\n",
    "    for col in context_cols:\n",
    "        df[col] = df[col].str.lower()\n",
    "\n",
    "    # Construct Rich Text Representation (Contextual Prefixing)\n",
    "    # Format: [Service | Service offering] [Category | Subcategory] Group: Assignment group. Short Description. Description\n",
    "    def build_bracketed(parts):\n",
    "        clean_parts = [p for p in parts if p]\n",
    "        return f\"[{ ' | '.join(clean_parts) }] \" if clean_parts else \"\" \n",
    "\n",
    "    df['context_service'] = df.apply(lambda row: build_bracketed([row['Service'], row['Service offering']]), axis=1)\n",
    "    df['context_category'] = df.apply(lambda row: build_bracketed([row['Category'], row['Subcategory']]), axis=1)\n",
    "    df['context_group'] = df.apply(lambda row: f\"Group: {row['Assignment group']}. \" if row['Assignment group'] else \"\", axis=1)\n",
    "\n",
    "    df['text'] = (\n",
    "        df['context_service'] +\n",
    "        df['context_category'] +\n",
    "        df['context_group'] +\n",
    "        df['Short Description'].str.strip() + \". \" +\n",
    "        df['Description'].str.strip()\n",
    "    ).str.replace(r\"\\\\s+\\\\.\", \".\", regex=True) # Remove space before period\n",
    "    df['text'] = df['text'].str.replace(r\"\\\\s+\", \" \", regex=True).str.strip() # Clean up excess spaces\n",
    "\n",
    "    # Filter empty or too short\n",
    "    initial_count = len(df)\n",
    "    min_length = 10 # Configurable if needed\n",
    "    df = df[df['text'].str.len() >= min_length].copy()\n",
    "    dropped = initial_count - len(df)\n",
    "    if dropped > 0:\n",
    "        log(f\"‚ö†Ô∏è Dropped {dropped} incidents due to short/empty text after preprocessing.\")\n",
    "    \n",
    "    # Create unique group ID for stratified splitting (Category-Subcategory)\n",
    "    df['category_id'] = df.groupby(['Category', 'Subcategory']).ngroup()\n",
    "    \n",
    "    log(f\"‚úÖ Preprocessed {len(df)} incidents.\")\n",
    "    log(f\"Sample preprocessed text: '{df['text'].iloc[0]}'\")\n",
    "    df = df.reset_index(drop=True)\n",
    "    log(f'‚úÖ Index reset. Range: {df.index.min()} to {df.index.max()}')\n",
    "    return df\n",
    "\n",
    "df_incidents = load_and_preprocess_data(CONFIG)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-30 18:46:42,888 - INFO - Split Incidents: Train=8500, Eval=1500\n",
      "2025-11-30 18:46:42,892 - INFO - ‚è≥ Fitting TF-IDF for similarity mining...\n",
      "2025-11-30 18:46:43,209 - INFO - ‚úÖ TF-IDF fit complete. Matrix shape: (8500, 110)\n",
      "2025-11-30 18:46:43,212 - INFO - üîé Generating 17000 positive and 25500 hard negative pairs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0c0b7bf2ebb4781801d0ee7de2b95fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Positives:   0%|          | 0/17000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e2399e5302a49b085a7159b6c5c23df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Negatives:   0%|          | 0/25500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class TextSimilarityCalculator:\n",
    "    def __init__(self, texts):\n",
    "        self.lemmatizer = WordNetLemmatizer() if 'wordnet' in nltk.data.path else None\n",
    "        self.stop_words = set(stopwords.words('english')) if 'stopwords' in nltk.data.path else ENGLISH_STOP_WORDS\n",
    "        self.vectorizer = TfidfVectorizer(stop_words=list(self.stop_words), max_features=10000)\n",
    "        \n",
    "        log(\"‚è≥ Fitting TF-IDF for similarity mining...\")\n",
    "        self.tfidf = self.vectorizer.fit_transform(texts)\n",
    "        log(f\"‚úÖ TF-IDF fit complete. Matrix shape: {self.tfidf.shape}\")\n",
    "\n",
    "    def get_tfidf_similarity(self, idx1, idx2):\n",
    "        if idx1 >= self.tfidf.shape[0] or idx2 >= self.tfidf.shape[0]:\n",
    "            return 0.0 \n",
    "        return (self.tfidf[idx1] @ self.tfidf[idx2].T).toarray()[0][0]\n",
    "\n",
    "def generate_smart_pairs(df, target_count, config):\n",
    "    \"\"\"Generates positive and hard negative pairs based on TF-IDF similarity.\"\"\"\n",
    "    # Ensure index is reset for direct iloc/loc correspondence\n",
    "    df = df.reset_index(drop=True)\n",
    "    \n",
    "    sim_calculator = TextSimilarityCalculator(df['text'].tolist())\n",
    "\n",
    "    positive_target = int(target_count * config['pos_ratio'])\n",
    "    negative_target = target_count - positive_target\n",
    "\n",
    "    pairs = []\n",
    "    \n",
    "    # Group by Category/Subcategory\n",
    "    # groups indices are now reliable 0..N integers because of reset_index\n",
    "    groups = df.groupby('category_id').indices \n",
    "    valid_groups = {k: list(v) for k, v in groups.items() if len(v) >= 2}\n",
    "    all_indices = list(df.index)\n",
    "\n",
    "    log(f\"üîé Generating {positive_target} positive and {negative_target} hard negative pairs...\")\n",
    "\n",
    "    # --- 1. Positive Pairs ---\n",
    "    pbar_pos = tqdm(total=positive_target, desc=\"Generating Positives\")\n",
    "    attempts = 0\n",
    "    while len(pairs) < positive_target and attempts < positive_target * 5:\n",
    "        attempts += 1\n",
    "        if not valid_groups: break\n",
    "        \n",
    "        gid = random.choice(list(valid_groups.keys()))\n",
    "        g_idxs = valid_groups[gid] # already a list\n",
    "        \n",
    "        if len(g_idxs) < 2: continue\n",
    "        \n",
    "        i1, i2 = random.sample(g_idxs, 2)\n",
    "        \n",
    "        # i1, i2 are integer positions. Since we reset index, they are also labels.\n",
    "        # Using iloc is safest for 'text' column access if we mix things up, \n",
    "        # but here loc==iloc. We use simple integer indexing for tfidf.\n",
    "        \n",
    "        sim = sim_calculator.get_tfidf_similarity(i1, i2)\n",
    "        \n",
    "        if sim > 0.3:\n",
    "            pairs.append(InputExample(texts=[df.at[i1, 'text'], df.at[i2, 'text']], label=1.0))\n",
    "            pbar_pos.update(1)\n",
    "            \n",
    "    # Fill remaining positives\n",
    "    if len(pairs) < positive_target:\n",
    "        log(f\"‚ö†Ô∏è Filling {positive_target - len(pairs)} remaining positives with random in-group pairs.\")\n",
    "        while len(pairs) < positive_target:\n",
    "            if not valid_groups: break\n",
    "            gid = random.choice(list(valid_groups.keys()))\n",
    "            g_idxs = valid_groups[gid]\n",
    "            if len(g_idxs) < 2: continue\n",
    "            i1, i2 = random.sample(g_idxs, 2)\n",
    "            pairs.append(InputExample(texts=[df.at[i1, 'text'], df.at[i2, 'text']], label=1.0))\n",
    "            pbar_pos.update(1)\n",
    "            \n",
    "    pbar_pos.close()\n",
    "\n",
    "    # --- 2. Hard Negative Pairs ---\n",
    "    current_pos_count = len(pairs)\n",
    "    pbar_neg = tqdm(total=negative_target, desc=\"Generating Negatives\")\n",
    "    attempts = 0\n",
    "    max_attempts = negative_target * 10 \n",
    "    \n",
    "    while (len(pairs) - current_pos_count) < negative_target and attempts < max_attempts:\n",
    "        attempts += 1\n",
    "        \n",
    "        i1, i2 = random.sample(all_indices, 2)\n",
    "        \n",
    "        if df.at[i1, 'category_id'] == df.at[i2, 'category_id']:\n",
    "            continue\n",
    "            \n",
    "        sim = sim_calculator.get_tfidf_similarity(i1, i2)\n",
    "        \n",
    "        min_sim, max_sim = config['neg_mining_range']\n",
    "        if min_sim <= sim <= max_sim:\n",
    "            pairs.append(InputExample(texts=[df.at[i1, 'text'], df.at[i2, 'text']], label=0.0))\n",
    "            pbar_neg.update(1)\n",
    "            \n",
    "    # Fill remaining negatives\n",
    "    neg_generated = len(pairs) - current_pos_count\n",
    "    if neg_generated < negative_target:\n",
    "         log(f\"‚ö†Ô∏è Filling {negative_target - neg_generated} remaining negatives with random cross-category pairs.\")\n",
    "         while (len(pairs) - current_pos_count) < negative_target:\n",
    "            i1, i2 = random.sample(all_indices, 2)\n",
    "            if df.at[i1, 'category_id'] != df.at[i2, 'category_id']:\n",
    "                pairs.append(InputExample(texts=[df.at[i1, 'text'], df.at[i2, 'text']], label=0.0))\n",
    "                pbar_neg.update(1)\n",
    "                \n",
    "    pbar_neg.close()\n",
    "    \n",
    "    log(f\"‚úÖ Generated {len(pairs)} training pairs.\")\n",
    "    return pairs\n",
    "\n",
    "# Split incidents into train/eval sets for pair generation\n",
    "# Note: we split BEFORE pair generation, so we must reset index on the splits individually\n",
    "train_incidents_df, eval_incidents_df = train_test_split(\n",
    "    df_incidents,\n",
    "    test_size=CONFIG['eval_split'],\n",
    "    stratify=df_incidents['category_id'],\n",
    "    random_state=CONFIG['seed']\n",
    ")\n",
    "\n",
    "log(f\"Split Incidents: Train={len(train_incidents_df)}, Eval={len(eval_incidents_df)}\")\n",
    "\n",
    "# Calculate target pairs for each split\n",
    "train_num_pairs = int(CONFIG['num_pairs'] * (1 - CONFIG['eval_split']))\n",
    "eval_num_pairs = CONFIG['num_pairs'] - train_num_pairs\n",
    "\n",
    "train_examples = generate_smart_pairs(train_incidents_df, train_num_pairs, CONFIG)\n",
    "eval_examples = generate_smart_pairs(eval_incidents_df, eval_num_pairs, CONFIG)\n",
    "\n",
    "log(f\"Final Samples: Training={len(train_examples)}, Evaluation={len(eval_examples)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Model Evaluation Class ---\n",
    "class ITSMEvaluator(SentenceEvaluator):\n",
    "    def __init__(self, examples: list[InputExample], batch_size: int = 16, name: str = ''):\n",
    "        self.examples = examples\n",
    "        self.batch_size = batch_size\n",
    "        self.name = name\n",
    "\n",
    "        self.texts1 = [ex.texts[0] for ex in examples]\n",
    "        self.texts2 = [ex.texts[1] for ex in examples]\n",
    "        self.labels = np.array([ex.label for ex in examples])\n",
    "\n",
    "        self.csv_file = f\"{name}_eval_results.csv\"\n",
    "        self.csv_headers = [\"epoch\", \"steps\", \"spearman\", \"pearson\", \"roc_auc\", \"pr_auc\"]\n",
    "\n",
    "    def __call__(self, model, output_path: str = None, epoch: int = -1, steps: int = -1) -> float:\n",
    "        model.eval()\n",
    "        log(f\"üìä Running evaluation at epoch={epoch}, step={steps}...\", level=logging.DEBUG)\n",
    "\n",
    "        # Encode all texts\n",
    "        embeddings1 = model.encode(self.texts1, batch_size=self.batch_size, show_progress_bar=False, convert_to_numpy=True)\n",
    "        embeddings2 = model.encode(self.texts2, batch_size=self.batch_size, show_progress_bar=False, convert_to_numpy=True)\n",
    "\n",
    "        # Calculate cosine similarities\n",
    "        cosine_scores = np.sum(embeddings1 * embeddings2, axis=1) / (np.linalg.norm(embeddings1, axis=1) * np.linalg.norm(embeddings2, axis=1))\n",
    "\n",
    "        # Calculate metrics\n",
    "        eval_pearson, _ = pearsonr(self.labels, cosine_scores)\n",
    "        eval_spearman, _ = spearmanr(self.labels, cosine_scores)\n",
    "        \n",
    "        try:\n",
    "            roc_auc = roc_auc_score(self.labels, cosine_scores)\n",
    "            pr_auc = average_precision_score(self.labels, cosine_scores)\n",
    "        except ValueError: # Happens if only one class is present in labels\n",
    "            roc_auc = 0.0\n",
    "            pr_auc = 0.0\n",
    "            log(\"‚ö†Ô∏è ROC/PR AUC cannot be calculated due to single class in evaluation labels.\", level=logging.WARNING)\n",
    "\n",
    "\n",
    "        log_msg = (\n",
    "                   f\"Epoch {epoch if epoch != -1 else 'N/A'} Steps {steps if steps != -1 else 'N/A'}: \"\n",
    "                   f\"Spearman={eval_spearman:.4f}, Pearson={eval_pearson:.4f}, \"\n",
    "                   f\"ROC_AUC={roc_auc:.4f}, PR_AUC={pr_auc:.4f}\")\n",
    "        log(log_msg)\n",
    "\n",
    "        if output_path is not None:\n",
    "            csv_path = Path(output_path) / self.csv_file\n",
    "            output_data = [epoch, steps, eval_spearman, eval_pearson, roc_auc, pr_auc]\n",
    "            \n",
    "            if not csv_path.is_file():\n",
    "                with open(csv_path, 'w', encoding='utf-8') as f:\n",
    "                    f.write(\",\".join(self.csv_headers) + \"\\n\")\n",
    "            \n",
    "            with open(csv_path, 'a', encoding='utf-8') as f:\n",
    "                f.write(\",\".join(map(str, output_data)) + \"\\n\")\n",
    "\n",
    "        return eval_spearman # Return spearman as the main score for model selection\n",
    "\n",
    "# --- Model Setup ---\n",
    "model = SentenceTransformer(CONFIG['model_name'])\n",
    "model.max_seq_length = CONFIG['max_seq_length']\n",
    "\n",
    "train_loss = losses.CosineSimilarityLoss(model)\n",
    "train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=CONFIG['batch_size'])\n",
    "\n",
    "evaluator = ITSMEvaluator(eval_examples, batch_size=CONFIG['batch_size'], name='validation')\n",
    "\n",
    "# --- Training Execution ---\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
    "save_path = Path(CONFIG['output_dir']) / f\"{Path(CONFIG['output_dir']).name}_{timestamp}\"\n",
    "save_path.mkdir(parents=True, exist_ok=True) # Ensure output directory exists\n",
    "\n",
    "log(f\"üöÄ Starting training... Model will be saved to: {save_path}\")\n",
    "\n",
    "model.fit(\n",
    "    train_objectives=[(train_dataloader, train_loss)],\n",
    "    evaluator=evaluator,\n",
    "    epochs=CONFIG['epochs'],\n",
    "    warmup_steps=int(len(train_dataloader) * CONFIG['epochs'] * 0.1), # 10% warmup\n",
    "    optimizer_params={'lr': CONFIG['lr']},\n",
    "    output_path=str(save_path), # SentenceTransformer expects string path\n",
    "    evaluation_steps=int(len(train_dataloader) * 0.1), # Evaluate every 10% of an epoch\n",
    "    save_best_model=True,\n",
    "    show_progress_bar=True\n",
    ")\n",
    "\n",
    "log(\"‚úÖ Training complete.\")\n",
    "\n",
    "# --- Final Evaluation ---\n",
    "log(\"‚ú® Reloading best model for final evaluation...\")\n",
    "best_model = SentenceTransformer(str(save_path)) # Reload the best saved model\n",
    "\n",
    "final_evaluator = ITSMEvaluator(eval_examples, batch_size=CONFIG['batch_size'], name='final_evaluation')\n",
    "final_spearman = final_evaluator(best_model, output_path=str(save_path), epoch='final', steps='final')\n",
    "\n",
    "log(f\"Final Model (best) saved to: {save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Relationship Classifier (Optional) ---\n",
    "# This part is optional and only runs if imbalanced-learn is available and data exists.\n",
    "\n",
    "try:\n",
    "    from imblearn.over_sampling import SMOTE\n",
    "    IMBLEARN_AVAILABLE = True\n",
    "except ImportError:\n",
    "    IMBLEARN_AVAILABLE = False\n",
    "\n",
    "if IMBLEARN_AVAILABLE:\n",
    "    rel_data_path = None\n",
    "    try:\n",
    "        rel_data_path = resolve_data_path(CONFIG['relationship_data'])\n",
    "    except FileNotFoundError:\n",
    "        log(f\"‚ö†Ô∏è Relationship data not found at {CONFIG['relationship_data']}. Skipping classifier training.\", level=logging.WARNING)\n",
    "\n",
    "    if rel_data_path and rel_data_path.exists():\n",
    "        log('üß† Training Relationship Classifier...')\n",
    "        with open(rel_data_path, 'r') as f:\n",
    "            rel_data = json.load(f)\n",
    "\n",
    "        rel_df = pd.DataFrame(rel_data)\n",
    "        # Filter valid labels (adjust as per your dataset)\n",
    "        valid_labels = ['duplicate', 'causal', 'related', 'none']\n",
    "        rel_df = rel_df[rel_df['label'].isin(valid_labels)]\n",
    "        log(f\"Relationship samples after filtering: {len(rel_df)}\")\n",
    "\n",
    "        if len(rel_df) > 0:\n",
    "            # Encode features using fine-tuned model\n",
    "            text_a = rel_df['text_a'].tolist()\n",
    "            text_b = rel_df['text_b'].tolist()\n",
    "\n",
    "            log(\"‚è≥ Encoding relationship data with the best model...\")\n",
    "            emb_a = best_model.encode(text_a, batch_size=CONFIG['batch_size'], show_progress_bar=False)\n",
    "            emb_b = best_model.encode(text_b, batch_size=CONFIG['batch_size'], show_progress_bar=False)\n",
    "\n",
    "            # Feature Engineering: (u, v, |u-v|, u*v)\n",
    "            X = np.hstack([emb_a, emb_b, np.abs(emb_a - emb_b), emb_a * emb_b])\n",
    "            y = rel_df['label']\n",
    "\n",
    "            from sklearn.linear_model import LogisticRegression\n",
    "            from sklearn.model_selection import train_test_split\n",
    "            from sklearn.metrics import classification_report\n",
    "            \n",
    "            # Only apply SMOTE if there are enough samples and multiple classes\n",
    "            if len(np.unique(y)) > 1 and len(X) > 1 and len(np.unique(y)) < len(X): # Ensure SMOTE doesn't crash\n",
    "                smote = SMOTE(k_neighbors=min(2, len(X) - 1), random_state=CONFIG['seed']) # k_neighbors must be <= n_samples-1\n",
    "                X_res, y_res = smote.fit_resample(X, y)\n",
    "                log(f\"After SMOTE: {len(X_res)} samples\")\n",
    "            else:\n",
    "                X_res, y_res = X, y\n",
    "                log(\"‚ö†Ô∏è Skipping SMOTE due to insufficient samples or single class after filtering.\", level=logging.WARNING)\n",
    "\n",
    "            # Train Classifier\n",
    "            clf = LogisticRegression(max_iter=1000, multi_class='multinomial', random_state=CONFIG['seed'], solver='lbfgs')\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.2, random_state=CONFIG['seed'], stratify=y_res)\n",
    "\n",
    "            log(\"‚è≥ Training Logistic Regression classifier...\")\n",
    "            clf.fit(X_train, y_train)\n",
    "\n",
    "            # Evaluation\n",
    "            y_pred = clf.predict(X_test)\n",
    "            log(\"‚úÖ Relationship Classifier Report:\")\n",
    "            log(f\"\\n{classification_report(y_test, y_pred)}\")\n",
    "\n",
    "            # Save Classifier\n",
    "            import joblib\n",
    "            classifier_save_path = save_path / \"relationship_classifier.joblib\"\n",
    "            joblib.dump(clf, classifier_save_path)\n",
    "            log(f\"‚úÖ Relationship classifier saved to: {classifier_save_path}\")\n",
    "        else:\n",
    "            log(\"‚ö†Ô∏è No valid relationship samples to train classifier. Skipping.\", level=logging.WARNING)\n",
    "    else:\n",
    "        log(f\"‚ö†Ô∏è Relationship data not found at resolved path '{rel_data_path}'. Skipping classifier training.\", level=logging.WARNING)\n",
    "else:\n",
    "    log('‚ö†Ô∏è imbalanced-learn not installed. Skipping relationship classifier.', level=logging.WARNING)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "itsm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
