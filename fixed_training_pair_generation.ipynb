{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f293b44",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c7d8285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Imports complete\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from typing import List, Tuple\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "print(\"✓ Imports complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f58f8db4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n",
      "\n",
      "Configuration:\n",
      "  Batch size: 16\n",
      "  Positive pairs target: 3000\n",
      "  Negative pairs target: 3000\n",
      "  Positive similarity threshold: ≥0.3\n",
      "  Negative similarity threshold: <0.5\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "if device == 'cuda':\n",
    "    BATCH_SIZE = 64\n",
    "else:\n",
    "    BATCH_SIZE = 16\n",
    "\n",
    "# Paths\n",
    "DATA_DIR = Path('data_new')\n",
    "DATA_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Training pair parameters\n",
    "NUM_POSITIVE_PAIRS = 3000  # Increased for better training\n",
    "NUM_NEGATIVE_PAIRS = 3000\n",
    "POSITIVE_SIMILARITY_THRESHOLD = 0.3  # Minimum similarity for positive pairs\n",
    "NEGATIVE_SIMILARITY_THRESHOLD = 0.5  # Maximum similarity for negative pairs\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "print(f\"\\nConfiguration:\")\n",
    "print(f\"  Batch size: {BATCH_SIZE}\")\n",
    "print(f\"  Positive pairs target: {NUM_POSITIVE_PAIRS}\")\n",
    "print(f\"  Negative pairs target: {NUM_NEGATIVE_PAIRS}\")\n",
    "print(f\"  Positive similarity threshold: ≥{POSITIVE_SIMILARITY_THRESHOLD}\")\n",
    "print(f\"  Negative similarity threshold: <{NEGATIVE_SIMILARITY_THRESHOLD}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e49201d",
   "metadata": {},
   "source": [
    "## 2. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bcedc418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 10633 ServiceNow incidents\n",
      "\n",
      "Columns: ['Number', 'Description', 'Opened by', 'Company', 'ITSM Department', 'Created', 'Urgency', 'Impact', 'Priority', 'Assignment group', 'Assigned to', 'State', 'Service', 'Service offering', 'Closed', 'Closed by', 'Category', 'Subcategory', 'Resolution code', 'Resolution notes', 'User input', 'Comments and Work notes', 'Manday Effort (hrs)', 'Ticket Type', 'AMS Domain', 'AMS System Type', 'AMS Category Type', 'AMS Service Type', 'AMS Business Related', 'AMS IT Related']\n"
     ]
    }
   ],
   "source": [
    "# Load ServiceNow incident data\n",
    "data_path = DATA_DIR / 'SNow_incident_ticket_data.csv'\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "print(f\"Loaded {len(df)} ServiceNow incidents\")\n",
    "print(f\"\\nColumns: {df.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61c93718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After filtering: 10633 valid incidents\n",
      "\n",
      "Sample text: INC0010171 GRPT not working as expected. ZMMM_PO_REV is not generating correct dates as per maintained in GRPT table. \n",
      "E.g. P/O# 100024066\n",
      "Vendor Ship mode is 03. \n",
      "As per GRPT route days are 12 day...\n"
     ]
    }
   ],
   "source": [
    "# Combine text fields\n",
    "def create_combined_text(row):\n",
    "    \"\"\"Combine available text fields with proper handling of NaN\"\"\"\n",
    "    text_parts = []\n",
    "    \n",
    "    for col in ['Number', 'Description', 'User input', 'Resolution notes']:\n",
    "        if col in row.index:\n",
    "            value = str(row.get(col, '')).strip() if pd.notna(row.get(col)) else ''\n",
    "            if value and value.lower() != 'nan':\n",
    "                text_parts.append(value)\n",
    "    \n",
    "    return ' '.join(text_parts) if text_parts else ''\n",
    "\n",
    "df['combined_text'] = df.apply(create_combined_text, axis=1)\n",
    "df['combined_text'] = df['combined_text'].astype(str)\n",
    "df = df[df['combined_text'].str.len() > 10].reset_index(drop=True)\n",
    "\n",
    "print(f\"After filtering: {len(df)} valid incidents\")\n",
    "print(f\"\\nSample text: {df['combined_text'].iloc[0][:200]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca46a35",
   "metadata": {},
   "source": [
    "## 3. Load Baseline Model for Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "374fd75d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading baseline model: sentence-transformers/all-mpnet-base-v2\n",
      "✓ Baseline model loaded\n"
     ]
    }
   ],
   "source": [
    "# Load baseline model for semantic validation\n",
    "print(\"Loading baseline model: sentence-transformers/all-mpnet-base-v2\")\n",
    "baseline_model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2', device=device)\n",
    "print(\"✓ Baseline model loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ee51fa",
   "metadata": {},
   "source": [
    "## 4. Generate Candidate Pairs (Category-Based)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a8f01c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No category column found - using random pairs\n",
      "\n",
      "✓ Generated 12000 candidate pairs\n",
      "  Positive: 6000\n",
      "  Negative: 6000\n"
     ]
    }
   ],
   "source": [
    "def generate_candidate_pairs(df: pd.DataFrame, \n",
    "                            num_positives: int,\n",
    "                            num_negatives: int,\n",
    "                            random_state: int = 42) -> Tuple[List[str], List[str], List[int]]:\n",
    "    \"\"\"\n",
    "    Generate candidate pairs based on categories.\n",
    "    These will be filtered with semantic validation.\n",
    "    \n",
    "    Generate MORE than needed since filtering will remove noisy pairs.\n",
    "    \"\"\"\n",
    "    np.random.seed(random_state)\n",
    "    \n",
    "    texts1, texts2, labels = [], [], []\n",
    "    \n",
    "    # Check if we have category information\n",
    "    has_categories = 'category' in df.columns\n",
    "    \n",
    "    if has_categories:\n",
    "        categories = df['category'].dropna().unique()\n",
    "        print(f\"Found {len(categories)} categories\")\n",
    "        \n",
    "        # Generate 2x more candidates than needed (will filter later)\n",
    "        target_pos = num_positives * 2\n",
    "        target_neg = num_negatives * 2\n",
    "        \n",
    "        print(f\"\\nGenerating {target_pos} candidate positive pairs...\")\n",
    "        # Positive pairs - same category\n",
    "        for _ in tqdm(range(target_pos)):\n",
    "            cat = np.random.choice(categories)\n",
    "            cat_incidents = df[df['category'] == cat]\n",
    "            if len(cat_incidents) >= 2:\n",
    "                idx1, idx2 = np.random.choice(cat_incidents.index, size=2, replace=False)\n",
    "                texts1.append(df.loc[idx1, 'combined_text'])\n",
    "                texts2.append(df.loc[idx2, 'combined_text'])\n",
    "                labels.append(1)\n",
    "        \n",
    "        print(f\"\\nGenerating {target_neg} candidate negative pairs...\")\n",
    "        # Negative pairs - different categories\n",
    "        for _ in tqdm(range(target_neg)):\n",
    "            cat1, cat2 = np.random.choice(categories, size=2, replace=False)\n",
    "            incidents1 = df[df['category'] == cat1]\n",
    "            incidents2 = df[df['category'] == cat2]\n",
    "            if len(incidents1) > 0 and len(incidents2) > 0:\n",
    "                idx1 = np.random.choice(incidents1.index)\n",
    "                idx2 = np.random.choice(incidents2.index)\n",
    "                texts1.append(df.loc[idx1, 'combined_text'])\n",
    "                texts2.append(df.loc[idx2, 'combined_text'])\n",
    "                labels.append(0)\n",
    "    else:\n",
    "        print(\"No category column found - using random pairs\")\n",
    "        # Random pairs as fallback\n",
    "        for _ in range(num_positives * 2):\n",
    "            idx1, idx2 = np.random.choice(len(df), size=2, replace=False)\n",
    "            texts1.append(df.loc[idx1, 'combined_text'])\n",
    "            texts2.append(df.loc[idx2, 'combined_text'])\n",
    "            labels.append(1)\n",
    "        \n",
    "        for _ in range(num_negatives * 2):\n",
    "            idx1, idx2 = np.random.choice(len(df), size=2, replace=False)\n",
    "            texts1.append(df.loc[idx1, 'combined_text'])\n",
    "            texts2.append(df.loc[idx2, 'combined_text'])\n",
    "            labels.append(0)\n",
    "    \n",
    "    print(f\"\\n✓ Generated {len(labels)} candidate pairs\")\n",
    "    print(f\"  Positive: {sum(labels)}\")\n",
    "    print(f\"  Negative: {len(labels) - sum(labels)}\")\n",
    "    \n",
    "    return texts1, texts2, labels\n",
    "\n",
    "# Generate candidates\n",
    "candidate_texts1, candidate_texts2, candidate_labels = generate_candidate_pairs(\n",
    "    df,\n",
    "    num_positives=NUM_POSITIVE_PAIRS,\n",
    "    num_negatives=NUM_NEGATIVE_PAIRS,\n",
    "    random_state=RANDOM_STATE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c0f56b",
   "metadata": {},
   "source": [
    "## 5. Semantic Validation with Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe3c1dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing embeddings for 12000 text pairs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3af37310a8bd4f509d243e4ae50b9c51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def compute_similarities(texts1: List[str], \n",
    "                        texts2: List[str],\n",
    "                        model: SentenceTransformer,\n",
    "                        batch_size: int = 16) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Compute cosine similarities between text pairs.\n",
    "    \"\"\"\n",
    "    print(f\"\\nComputing embeddings for {len(texts1)} text pairs...\")\n",
    "    \n",
    "    # Encode texts\n",
    "    embeddings1 = model.encode(\n",
    "        texts1,\n",
    "        batch_size=batch_size,\n",
    "        show_progress_bar=True,\n",
    "        convert_to_numpy=True\n",
    "    )\n",
    "    \n",
    "    embeddings2 = model.encode(\n",
    "        texts2,\n",
    "        batch_size=batch_size,\n",
    "        show_progress_bar=True,\n",
    "        convert_to_numpy=True\n",
    "    )\n",
    "    \n",
    "    # Compute cosine similarity\n",
    "    similarities = np.sum(embeddings1 * embeddings2, axis=1) / (\n",
    "        np.linalg.norm(embeddings1, axis=1) * np.linalg.norm(embeddings2, axis=1)\n",
    "    )\n",
    "    \n",
    "    return similarities\n",
    "\n",
    "# Compute similarities for all candidate pairs\n",
    "similarities = compute_similarities(\n",
    "    candidate_texts1,\n",
    "    candidate_texts2,\n",
    "    baseline_model,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "print(f\"\\n✓ Computed {len(similarities)} similarities\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c9c04c",
   "metadata": {},
   "source": [
    "## 6. Filter Pairs with Semantic Thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e677d533",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_validated_pairs(texts1: List[str],\n",
    "                          texts2: List[str],\n",
    "                          labels: List[int],\n",
    "                          similarities: np.ndarray,\n",
    "                          positive_threshold: float,\n",
    "                          negative_threshold: float,\n",
    "                          target_positives: int,\n",
    "                          target_negatives: int) -> Tuple[List[str], List[str], List[int], np.ndarray]:\n",
    "    \"\"\"\n",
    "    Filter pairs based on semantic similarity thresholds.\n",
    "    \n",
    "    Positive pairs: similarity >= positive_threshold\n",
    "    Negative pairs: similarity < negative_threshold\n",
    "    \"\"\"\n",
    "    labels_array = np.array(labels)\n",
    "    \n",
    "    # Filter positive pairs\n",
    "    positive_mask = (labels_array == 1) & (similarities >= positive_threshold)\n",
    "    valid_positive_indices = np.where(positive_mask)[0]\n",
    "    \n",
    "    print(f\"\\nPositive pairs:\")\n",
    "    print(f\"  Candidates: {sum(labels_array == 1)}\")\n",
    "    print(f\"  Valid (similarity ≥{positive_threshold}): {len(valid_positive_indices)}\")\n",
    "    print(f\"  Rejection rate: {(1 - len(valid_positive_indices)/sum(labels_array == 1))*100:.1f}%\")\n",
    "    \n",
    "    # Filter negative pairs\n",
    "    negative_mask = (labels_array == 0) & (similarities < negative_threshold)\n",
    "    valid_negative_indices = np.where(negative_mask)[0]\n",
    "    \n",
    "    print(f\"\\nNegative pairs:\")\n",
    "    print(f\"  Candidates: {sum(labels_array == 0)}\")\n",
    "    print(f\"  Valid (similarity <{negative_threshold}): {len(valid_negative_indices)}\")\n",
    "    print(f\"  Rejection rate: {(1 - len(valid_negative_indices)/sum(labels_array == 0))*100:.1f}%\")\n",
    "    \n",
    "    # Sample to target sizes (if we have enough)\n",
    "    if len(valid_positive_indices) >= target_positives:\n",
    "        selected_positive_indices = np.random.choice(\n",
    "            valid_positive_indices,\n",
    "            size=target_positives,\n",
    "            replace=False\n",
    "        )\n",
    "    else:\n",
    "        selected_positive_indices = valid_positive_indices\n",
    "        print(f\"\\n⚠️  Warning: Only {len(selected_positive_indices)} valid positive pairs (target: {target_positives})\")\n",
    "    \n",
    "    if len(valid_negative_indices) >= target_negatives:\n",
    "        selected_negative_indices = np.random.choice(\n",
    "            valid_negative_indices,\n",
    "            size=target_negatives,\n",
    "            replace=False\n",
    "        )\n",
    "    else:\n",
    "        selected_negative_indices = valid_negative_indices\n",
    "        print(f\"\\n⚠️  Warning: Only {len(selected_negative_indices)} valid negative pairs (target: {target_negatives})\")\n",
    "    \n",
    "    # Combine selected indices\n",
    "    selected_indices = np.concatenate([selected_positive_indices, selected_negative_indices])\n",
    "    \n",
    "    # Extract selected pairs\n",
    "    validated_texts1 = [texts1[i] for i in selected_indices]\n",
    "    validated_texts2 = [texts2[i] for i in selected_indices]\n",
    "    validated_labels = [labels[i] for i in selected_indices]\n",
    "    validated_similarities = similarities[selected_indices]\n",
    "    \n",
    "    return validated_texts1, validated_texts2, validated_labels, validated_similarities\n",
    "\n",
    "# Filter pairs\n",
    "train_texts1, train_texts2, train_labels, train_similarities = filter_validated_pairs(\n",
    "    candidate_texts1,\n",
    "    candidate_texts2,\n",
    "    candidate_labels,\n",
    "    similarities,\n",
    "    positive_threshold=POSITIVE_SIMILARITY_THRESHOLD,\n",
    "    negative_threshold=NEGATIVE_SIMILARITY_THRESHOLD,\n",
    "    target_positives=NUM_POSITIVE_PAIRS,\n",
    "    target_negatives=NUM_NEGATIVE_PAIRS\n",
    ")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"FINAL TRAINING SET\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"Total pairs: {len(train_labels)}\")\n",
    "print(f\"  Positive: {sum(train_labels)} ({sum(train_labels)/len(train_labels)*100:.1f}%)\")\n",
    "print(f\"  Negative: {len(train_labels)-sum(train_labels)} ({(len(train_labels)-sum(train_labels))/len(train_labels)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae3355f",
   "metadata": {},
   "source": [
    "## 7. Quality Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0169faed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze quality metrics\n",
    "train_labels_array = np.array(train_labels)\n",
    "pos_similarities = train_similarities[train_labels_array == 1]\n",
    "neg_similarities = train_similarities[train_labels_array == 0]\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"QUALITY METRICS\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "print(f\"\\nPositive Pairs (label=1):\")\n",
    "print(f\"  Mean similarity: {pos_similarities.mean():.4f}\")\n",
    "print(f\"  Median similarity: {np.median(pos_similarities):.4f}\")\n",
    "print(f\"  Range: [{pos_similarities.min():.4f}, {pos_similarities.max():.4f}]\")\n",
    "\n",
    "print(f\"\\nNegative Pairs (label=0):\")\n",
    "print(f\"  Mean similarity: {neg_similarities.mean():.4f}\")\n",
    "print(f\"  Median similarity: {np.median(neg_similarities):.4f}\")\n",
    "print(f\"  Range: [{neg_similarities.min():.4f}, {neg_similarities.max():.4f}]\")\n",
    "\n",
    "separability = pos_similarities.mean() - neg_similarities.mean()\n",
    "print(f\"\\nSeparability (Pos - Neg): {separability:.4f}\")\n",
    "\n",
    "if separability > 0.15:\n",
    "    print(\"  ✓ EXCELLENT: Clear separation\")\n",
    "elif separability > 0.1:\n",
    "    print(\"  ✓ GOOD: Reasonable separation\")\n",
    "elif separability > 0.05:\n",
    "    print(\"  ⚠️  OK: Moderate separation\")\n",
    "else:\n",
    "    print(\"  ✗ POOR: Weak separation (increase thresholds)\")\n",
    "\n",
    "# Check overlap\n",
    "overlap_count = np.sum(\n",
    "    (pos_similarities[:, None] <= neg_similarities[None, :]).any(axis=1)\n",
    ")\n",
    "overlap_pct = overlap_count / len(pos_similarities) * 100\n",
    "\n",
    "print(f\"\\nScore Overlap: {overlap_pct:.1f}%\")\n",
    "if overlap_pct < 30:\n",
    "    print(\"  ✓ GOOD: Low overlap\")\n",
    "elif overlap_pct < 50:\n",
    "    print(\"  ⚠️  OK: Moderate overlap\")\n",
    "else:\n",
    "    print(\"  ✗ POOR: High overlap (adjust thresholds)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f21a76",
   "metadata": {},
   "source": [
    "## 8. Visualize Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517b28b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.hist(neg_similarities, bins=50, alpha=0.6, label='Negative (label=0)', color='red', edgecolor='black')\n",
    "plt.hist(pos_similarities, bins=50, alpha=0.6, label='Positive (label=1)', color='green', edgecolor='black')\n",
    "\n",
    "plt.axvline(POSITIVE_SIMILARITY_THRESHOLD, color='green', linestyle='--', linewidth=2, label=f'Pos threshold={POSITIVE_SIMILARITY_THRESHOLD}')\n",
    "plt.axvline(NEGATIVE_SIMILARITY_THRESHOLD, color='red', linestyle='--', linewidth=2, label=f'Neg threshold={NEGATIVE_SIMILARITY_THRESHOLD}')\n",
    "\n",
    "plt.xlabel('Cosine Similarity', fontsize=12)\n",
    "plt.ylabel('Frequency', fontsize=12)\n",
    "plt.title('Training Pair Similarity Distribution (Validated)', fontsize=14, fontweight='bold')\n",
    "plt.legend(fontsize=10)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n✓ Distribution looks {'GOOD' if separability > 0.1 else 'NEEDS IMPROVEMENT'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9357f4",
   "metadata": {},
   "source": [
    "## 9. Save Validated Training Pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803229ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to JSON\n",
    "output_file = DATA_DIR / 'fixed_training_pairs.json'\n",
    "\n",
    "training_data = {\n",
    "    'texts1': train_texts1,\n",
    "    'texts2': train_texts2,\n",
    "    'labels': train_labels,\n",
    "    'metadata': {\n",
    "        'generated_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "        'num_pairs': len(train_labels),\n",
    "        'num_positive': sum(train_labels),\n",
    "        'num_negative': len(train_labels) - sum(train_labels),\n",
    "        'positive_similarity_threshold': POSITIVE_SIMILARITY_THRESHOLD,\n",
    "        'negative_similarity_threshold': NEGATIVE_SIMILARITY_THRESHOLD,\n",
    "        'baseline_model': 'sentence-transformers/all-mpnet-base-v2',\n",
    "        'baseline_separability': float(separability),\n",
    "        'baseline_overlap': float(overlap_pct / 100),\n",
    "        'positive_mean_similarity': float(pos_similarities.mean()),\n",
    "        'negative_mean_similarity': float(neg_similarities.mean()),\n",
    "        'quality_status': 'GOOD' if separability > 0.1 else 'NEEDS_IMPROVEMENT'\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(output_file, 'w') as f:\n",
    "    json.dump(training_data, f, indent=2)\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"✓ TRAINING PAIRS SAVED\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"File: {output_file}\")\n",
    "print(f\"Size: {output_file.stat().st_size / 1024 / 1024:.2f} MB\")\n",
    "print(f\"\\nYou can now use these validated pairs to train your models!\")\n",
    "print(f\"\\nNext steps:\")\n",
    "print(f\"  1. Use these pairs in your training notebook\")\n",
    "print(f\"  2. Retrain all models with clean data\")\n",
    "print(f\"  3. Re-evaluate with fixed test pairs\")\n",
    "print(f\"  4. Expect significant performance improvements!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ca0a15",
   "metadata": {},
   "source": [
    "## 10. Sample Pairs for Manual Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca992228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show sample positive pairs\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SAMPLE POSITIVE PAIRS (should be semantically similar)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "pos_indices = np.where(train_labels_array == 1)[0]\n",
    "sample_pos = np.random.choice(pos_indices, size=min(3, len(pos_indices)), replace=False)\n",
    "\n",
    "for i, idx in enumerate(sample_pos, 1):\n",
    "    print(f\"\\nPair {i} (similarity: {train_similarities[idx]:.3f}):\")\n",
    "    print(f\"  Text 1: {train_texts1[idx][:150]}...\")\n",
    "    print(f\"  Text 2: {train_texts2[idx][:150]}...\")\n",
    "\n",
    "# Show sample negative pairs\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SAMPLE NEGATIVE PAIRS (should be semantically different)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "neg_indices = np.where(train_labels_array == 0)[0]\n",
    "sample_neg = np.random.choice(neg_indices, size=min(3, len(neg_indices)), replace=False)\n",
    "\n",
    "for i, idx in enumerate(sample_neg, 1):\n",
    "    print(f\"\\nPair {i} (similarity: {train_similarities[idx]:.3f}):\")\n",
    "    print(f\"  Text 1: {train_texts1[idx][:150]}...\")\n",
    "    print(f\"  Text 2: {train_texts2[idx][:150]}...\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "itsm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
