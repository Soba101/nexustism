{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5460abfd",
   "metadata": {},
   "source": [
    "# ðŸ”— Causal Relationship Classifier (CrossEncoder)\n",
    "\n",
    "**Purpose**: Detect causal relationships between ITSM tickets\n",
    "- Input: Two ticket texts\n",
    "- Output: Probability that Ticket A **caused** Ticket B\n",
    "\n",
    "**Two-Stage Pipeline:**\n",
    "1. **Stage 1** (your similarity model): Find top-K similar tickets\n",
    "2. **Stage 2** (this model): Determine if relationship is causal\n",
    "\n",
    "**Why CrossEncoder?**\n",
    "- Designed for pair classification (NLI-style)\n",
    "- Much better at subtle relationships than embedding similarity\n",
    "- Separate from similarity model (no interference)\n",
    "\n",
    "**Expected Performance:** F1 ~0.65-0.80 for causal detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d19ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Environment Setup ---\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "# Suppress warnings\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'false'\n",
    "os.environ['WANDB_DISABLED'] = 'true'\n",
    "\n",
    "# Install required packages\n",
    "subprocess.check_call([sys.executable, '-m', 'pip', 'install', '-q', \n",
    "                       'sentence-transformers', 'torch', 'scikit-learn', 'tqdm'])\n",
    "\n",
    "print(\"âœ… Environment ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995758c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration ---\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "CONFIG = {\n",
    "    'relationship_data': 'data/relationship_pairs.json',\n",
    "    'output_dir': 'models/causal_classifier',\n",
    "    'base_model': 'cross-encoder/ms-marco-MiniLM-L-6-v2',  # Good balance of speed/accuracy\n",
    "    'epochs': 5,\n",
    "    'batch_size': 16,\n",
    "    'warmup_ratio': 0.1,\n",
    "    'seed': 42,\n",
    "    'max_pairs': 10000,  # Limit to prevent memory issues\n",
    "}\n",
    "\n",
    "# Set seeds\n",
    "random.seed(CONFIG['seed'])\n",
    "np.random.seed(CONFIG['seed'])\n",
    "torch.manual_seed(CONFIG['seed'])\n",
    "\n",
    "# Device detection\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "    print(f\"ðŸš€ CUDA: {torch.cuda.get_device_name(0)}\")\n",
    "elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "    device = 'mps'\n",
    "    print(\"ðŸŽ MPS (Apple Silicon)\")\n",
    "else:\n",
    "    device = 'cpu'\n",
    "    print(\"âš ï¸ CPU only\")\n",
    "\n",
    "print(f\"ðŸ“ Output: {CONFIG['output_dir']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c14319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load and Prepare Data ---\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "def resolve_data_path(path_str):\n",
    "    \"\"\"Smart path resolver for Local/Kaggle/Colab.\"\"\"\n",
    "    p = Path(path_str)\n",
    "    if p.exists():\n",
    "        return p.resolve()\n",
    "    script_dir = Path.cwd()\n",
    "    if (script_dir / path_str).exists():\n",
    "        return (script_dir / path_str).resolve()\n",
    "    raise FileNotFoundError(f\"Could not find {path_str}\")\n",
    "\n",
    "# Load relationship data\n",
    "rel_data_path = resolve_data_path(CONFIG['relationship_data'])\n",
    "print(f\"ðŸ“‚ Loading: {rel_data_path}\")\n",
    "\n",
    "with open(rel_data_path, 'r') as f:\n",
    "    rel_data = json.load(f)\n",
    "\n",
    "print(f\"ðŸ“Š Total pairs: {len(rel_data)}\")\n",
    "\n",
    "# Count by label\n",
    "from collections import Counter\n",
    "label_counts = Counter(item['label'] for item in rel_data)\n",
    "print(f\"ðŸ“ˆ Label distribution:\")\n",
    "for label, count in sorted(label_counts.items()):\n",
    "    print(f\"   {label}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d45f66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Create Binary Causal Dataset ---\n",
    "# Convert to binary: causal (1) vs non-causal (0)\n",
    "\n",
    "causal_pairs = []\n",
    "non_causal_pairs = []\n",
    "\n",
    "for item in rel_data:\n",
    "    pair_data = {\n",
    "        'text_a': item['text_a'],\n",
    "        'text_b': item['text_b'],\n",
    "        'label': item['label']\n",
    "    }\n",
    "    \n",
    "    if item['label'] == 'causal':\n",
    "        causal_pairs.append(pair_data)\n",
    "    elif item['label'] in ['none', 'related', 'duplicate']:\n",
    "        non_causal_pairs.append(pair_data)\n",
    "\n",
    "print(f\"âœ… Causal pairs: {len(causal_pairs)}\")\n",
    "print(f\"âœ… Non-causal pairs: {len(non_causal_pairs)}\")\n",
    "\n",
    "# Balance dataset (undersample majority class)\n",
    "# Use 1:3 ratio (causal:non-causal) for better learning\n",
    "max_non_causal = min(len(non_causal_pairs), len(causal_pairs) * 3)\n",
    "random.shuffle(non_causal_pairs)\n",
    "non_causal_sample = non_causal_pairs[:max_non_causal]\n",
    "\n",
    "print(f\"ðŸ“Š After balancing: {len(causal_pairs)} causal, {len(non_causal_sample)} non-causal\")\n",
    "\n",
    "# Combine and shuffle\n",
    "all_pairs = causal_pairs + non_causal_sample\n",
    "random.shuffle(all_pairs)\n",
    "\n",
    "# Limit total pairs if needed (memory safety)\n",
    "if len(all_pairs) > CONFIG['max_pairs']:\n",
    "    all_pairs = all_pairs[:CONFIG['max_pairs']]\n",
    "    print(f\"âš ï¸ Limited to {CONFIG['max_pairs']} pairs\")\n",
    "\n",
    "print(f\"ðŸŽ¯ Final dataset: {len(all_pairs)} pairs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f78a1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Prepare Training Data for CrossEncoder ---\n",
    "from sentence_transformers import InputExample\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Create InputExamples for CrossEncoder\n",
    "examples = []\n",
    "for pair in all_pairs:\n",
    "    label = 1.0 if pair['label'] == 'causal' else 0.0\n",
    "    examples.append(InputExample(\n",
    "        texts=[pair['text_a'], pair['text_b']],\n",
    "        label=label\n",
    "    ))\n",
    "\n",
    "# Split into train/eval\n",
    "train_examples, eval_examples = train_test_split(\n",
    "    examples,\n",
    "    test_size=0.2,\n",
    "    random_state=CONFIG['seed'],\n",
    "    stratify=[ex.label for ex in examples]\n",
    ")\n",
    "\n",
    "print(f\"ðŸ“Š Train: {len(train_examples)} pairs\")\n",
    "print(f\"ðŸ“Š Eval: {len(eval_examples)} pairs\")\n",
    "\n",
    "# Check label balance in splits\n",
    "train_pos = sum(1 for ex in train_examples if ex.label == 1.0)\n",
    "eval_pos = sum(1 for ex in eval_examples if ex.label == 1.0)\n",
    "print(f\"   Train: {train_pos} causal, {len(train_examples) - train_pos} non-causal\")\n",
    "print(f\"   Eval: {eval_pos} causal, {len(eval_examples) - eval_pos} non-causal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838da815",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Initialize CrossEncoder ---\n",
    "from sentence_transformers.cross_encoder import CrossEncoder\n",
    "from sentence_transformers.cross_encoder.evaluation import CEBinaryClassificationEvaluator\n",
    "from torch.utils.data import DataLoader\n",
    "import gc\n",
    "\n",
    "# Clear memory before loading model\n",
    "gc.collect()\n",
    "if device == 'mps':\n",
    "    torch.mps.empty_cache()\n",
    "elif device == 'cuda':\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "print(f\"ðŸ”„ Loading CrossEncoder: {CONFIG['base_model']}\")\n",
    "\n",
    "# Initialize model\n",
    "# Note: CrossEncoder uses its own device management\n",
    "model = CrossEncoder(\n",
    "    CONFIG['base_model'],\n",
    "    num_labels=1,  # Binary classification (sigmoid output)\n",
    "    max_length=512,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "print(f\"âœ… Model loaded on {device}\")\n",
    "print(f\"   Max sequence length: 512\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48f282a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Setup Evaluator ---\n",
    "# Prepare eval data for CEBinaryClassificationEvaluator\n",
    "eval_sentence_pairs = [(ex.texts[0], ex.texts[1]) for ex in eval_examples]\n",
    "eval_labels = [int(ex.label) for ex in eval_examples]\n",
    "\n",
    "evaluator = CEBinaryClassificationEvaluator(\n",
    "    sentence_pairs=eval_sentence_pairs,\n",
    "    labels=eval_labels,\n",
    "    name='causal_eval'\n",
    ")\n",
    "\n",
    "print(f\"âœ… Evaluator ready with {len(eval_labels)} pairs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ccdeeec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Train CrossEncoder ---\n",
    "from datetime import datetime\n",
    "\n",
    "# Create output directory\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
    "save_path = Path(CONFIG['output_dir']) / f\"causal_{timestamp}\"\n",
    "save_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Prepare DataLoader\n",
    "train_dataloader = DataLoader(\n",
    "    train_examples,\n",
    "    shuffle=True,\n",
    "    batch_size=CONFIG['batch_size']\n",
    ")\n",
    "\n",
    "# Calculate warmup steps\n",
    "total_steps = len(train_dataloader) * CONFIG['epochs']\n",
    "warmup_steps = int(total_steps * CONFIG['warmup_ratio'])\n",
    "\n",
    "print(f\"ðŸš€ Starting training...\")\n",
    "print(f\"   Epochs: {CONFIG['epochs']}\")\n",
    "print(f\"   Batch size: {CONFIG['batch_size']}\")\n",
    "print(f\"   Total steps: {total_steps}\")\n",
    "print(f\"   Warmup steps: {warmup_steps}\")\n",
    "print(f\"   Output: {save_path}\")\n",
    "\n",
    "# Train\n",
    "model.fit(\n",
    "    train_dataloader=train_dataloader,\n",
    "    evaluator=evaluator,\n",
    "    epochs=CONFIG['epochs'],\n",
    "    warmup_steps=warmup_steps,\n",
    "    output_path=str(save_path),\n",
    "    save_best_model=True,\n",
    "    show_progress_bar=True\n",
    ")\n",
    "\n",
    "print(\"âœ… Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b84f1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Evaluate Final Model ---\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load best model\n",
    "best_model = CrossEncoder(str(save_path), device=device)\n",
    "\n",
    "# Predict on eval set\n",
    "predictions = best_model.predict(eval_sentence_pairs)\n",
    "\n",
    "# Convert to binary predictions (threshold = 0.5)\n",
    "binary_preds = (predictions > 0.5).astype(int)\n",
    "\n",
    "# Metrics\n",
    "print(\"=\"*60)\n",
    "print(\"ðŸ“Š FINAL EVALUATION RESULTS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nðŸ“‹ Classification Report:\")\n",
    "print(classification_report(eval_labels, binary_preds, target_names=['Non-Causal', 'Causal']))\n",
    "\n",
    "# ROC-AUC\n",
    "roc_auc = roc_auc_score(eval_labels, predictions)\n",
    "print(f\"ðŸŽ¯ ROC-AUC: {roc_auc:.4f}\")\n",
    "\n",
    "# Find optimal threshold using PR curve\n",
    "precision, recall, thresholds = precision_recall_curve(eval_labels, predictions)\n",
    "f1_scores = 2 * (precision * recall) / (precision + recall + 1e-10)\n",
    "best_idx = np.argmax(f1_scores)\n",
    "best_threshold = thresholds[best_idx] if best_idx < len(thresholds) else 0.5\n",
    "best_f1 = f1_scores[best_idx]\n",
    "\n",
    "print(f\"ðŸŽ¯ Best F1: {best_f1:.4f} @ threshold={best_threshold:.3f}\")\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(eval_labels, binary_preds)\n",
    "print(f\"\\nðŸ“Š Confusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2426362b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Visualization ---\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "# 1. Confusion Matrix Heatmap\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[0],\n",
    "            xticklabels=['Non-Causal', 'Causal'],\n",
    "            yticklabels=['Non-Causal', 'Causal'])\n",
    "axes[0].set_title('Confusion Matrix')\n",
    "axes[0].set_xlabel('Predicted')\n",
    "axes[0].set_ylabel('Actual')\n",
    "\n",
    "# 2. Score Distribution\n",
    "causal_scores = [predictions[i] for i in range(len(predictions)) if eval_labels[i] == 1]\n",
    "non_causal_scores = [predictions[i] for i in range(len(predictions)) if eval_labels[i] == 0]\n",
    "\n",
    "axes[1].hist(non_causal_scores, bins=30, alpha=0.7, label='Non-Causal', color='blue')\n",
    "axes[1].hist(causal_scores, bins=30, alpha=0.7, label='Causal', color='red')\n",
    "axes[1].axvline(x=0.5, color='black', linestyle='--', label='Threshold (0.5)')\n",
    "axes[1].axvline(x=best_threshold, color='green', linestyle='--', label=f'Best ({best_threshold:.2f})')\n",
    "axes[1].set_title('Score Distribution')\n",
    "axes[1].set_xlabel('Prediction Score')\n",
    "axes[1].set_ylabel('Count')\n",
    "axes[1].legend()\n",
    "\n",
    "# 3. Precision-Recall Curve\n",
    "axes[2].plot(recall, precision, 'b-', linewidth=2)\n",
    "axes[2].scatter([recall[best_idx]], [precision[best_idx]], color='red', s=100, \n",
    "                label=f'Best F1={best_f1:.3f}', zorder=5)\n",
    "axes[2].set_title('Precision-Recall Curve')\n",
    "axes[2].set_xlabel('Recall')\n",
    "axes[2].set_ylabel('Precision')\n",
    "axes[2].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(save_path / 'evaluation_plots.png', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nâœ… Plots saved to: {save_path / 'evaluation_plots.png'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3280c67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Save Metadata ---\n",
    "import json\n",
    "\n",
    "metadata = {\n",
    "    'training_date': datetime.now().isoformat(),\n",
    "    'base_model': CONFIG['base_model'],\n",
    "    'task': 'binary_causal_classification',\n",
    "    'config': CONFIG,\n",
    "    'device': device,\n",
    "    'metrics': {\n",
    "        'roc_auc': float(roc_auc),\n",
    "        'best_f1': float(best_f1),\n",
    "        'best_threshold': float(best_threshold),\n",
    "    },\n",
    "    'data_stats': {\n",
    "        'total_pairs': len(all_pairs),\n",
    "        'train_pairs': len(train_examples),\n",
    "        'eval_pairs': len(eval_examples),\n",
    "        'causal_pairs': len(causal_pairs),\n",
    "        'non_causal_pairs': len(non_causal_sample),\n",
    "    }\n",
    "}\n",
    "\n",
    "metadata_path = save_path / 'training_metadata.json'\n",
    "with open(metadata_path, 'w') as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "\n",
    "print(f\"âœ… Metadata saved to: {metadata_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38cbcd5",
   "metadata": {},
   "source": [
    "# ðŸš€ Usage: How to Use This Model\n",
    "\n",
    "After training, use the causal classifier in your inference pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9daace1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Example Usage ---\n",
    "# This shows how to use the trained causal classifier in your inference pipeline\n",
    "\n",
    "def detect_causal_relationship(ticket_a: str, ticket_b: str, threshold: float = None) -> dict:\n",
    "    \"\"\"\n",
    "    Detect if ticket_a caused ticket_b.\n",
    "    \n",
    "    Args:\n",
    "        ticket_a: Text of the potential cause ticket\n",
    "        ticket_b: Text of the potential effect ticket\n",
    "        threshold: Classification threshold (default: best_threshold from training)\n",
    "    \n",
    "    Returns:\n",
    "        dict with 'is_causal' (bool), 'confidence' (float), 'threshold' (float)\n",
    "    \"\"\"\n",
    "    if threshold is None:\n",
    "        threshold = best_threshold\n",
    "    \n",
    "    # Get prediction score\n",
    "    score = best_model.predict([(ticket_a, ticket_b)])[0]\n",
    "    \n",
    "    return {\n",
    "        'is_causal': bool(score > threshold),\n",
    "        'confidence': float(score),\n",
    "        'threshold': threshold\n",
    "    }\n",
    "\n",
    "# Test examples\n",
    "print(\"=\"*60)\n",
    "print(\"ðŸ§ª EXAMPLE PREDICTIONS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "test_pairs = [\n",
    "    (\"Server database crashed due to disk full\", \n",
    "     \"Multiple users reporting application timeout errors\"),\n",
    "    \n",
    "    (\"User requested password reset\", \n",
    "     \"Network switch firmware upgrade completed\"),\n",
    "    \n",
    "    (\"DNS server configuration changed\", \n",
    "     \"Website not loading for external users\"),\n",
    "]\n",
    "\n",
    "for ticket_a, ticket_b in test_pairs:\n",
    "    result = detect_causal_relationship(ticket_a, ticket_b)\n",
    "    status = \"âœ… CAUSAL\" if result['is_causal'] else \"âŒ Not causal\"\n",
    "    print(f\"\\n{status} (confidence: {result['confidence']:.3f})\")\n",
    "    print(f\"   A: {ticket_a[:60]}...\")\n",
    "    print(f\"   B: {ticket_b[:60]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2586513",
   "metadata": {},
   "source": [
    "# ðŸ“‹ Two-Stage Pipeline Integration\n",
    "\n",
    "Use this causal classifier with your similarity model:\n",
    "\n",
    "```python\n",
    "# Stage 1: Find similar tickets using your similarity model\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "similarity_model = SentenceTransformer('models/v6_refactored_finetuned/...')\n",
    "query_embedding = similarity_model.encode(new_ticket)\n",
    "\n",
    "# Get top-K similar tickets\n",
    "similarities = cosine_similarity([query_embedding], all_embeddings)[0]\n",
    "top_k_indices = similarities.argsort()[-10:][::-1]\n",
    "\n",
    "# Stage 2: Check for causal relationships\n",
    "from sentence_transformers.cross_encoder import CrossEncoder\n",
    "\n",
    "causal_model = CrossEncoder('models/causal_classifier/causal_YYYYMMDD_HHMM')\n",
    "\n",
    "for idx in top_k_indices:\n",
    "    candidate_ticket = tickets[idx]\n",
    "    \n",
    "    # Check both directions (Aâ†’B and Bâ†’A)\n",
    "    score_ab = causal_model.predict([(new_ticket, candidate_ticket)])[0]\n",
    "    score_ba = causal_model.predict([(candidate_ticket, new_ticket)])[0]\n",
    "    \n",
    "    if score_ab > 0.5:\n",
    "        print(f\"New ticket may have CAUSED ticket {idx}\")\n",
    "    elif score_ba > 0.5:\n",
    "        print(f\"Ticket {idx} may have CAUSED new ticket\")\n",
    "    else:\n",
    "        print(f\"Ticket {idx} is similar but not causally related\")\n",
    "```\n",
    "\n",
    "**Note**: CrossEncoders are slower than bi-encoders but more accurate for pair classification. Only use on your top-K candidates, not the entire database."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
